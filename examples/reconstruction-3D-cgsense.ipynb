{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aab6b8f3-e983-448f-af6d-a218be5c8fd2",
   "metadata": {},
   "source": [
    "This notebook shows the reconstruction of a 3D GRE with two almost identical echotimes sampled with 3D Lissajous variable density shell trajectories.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3bddadca-7d64-4f9e-8cee-cd184f7467e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.insert(0, \"../src\")\n",
    "\n",
    "import h5py\n",
    "import torch\n",
    "import numpy\n",
    "\n",
    "from juart.conopt.tfs.fourier import nonuniform_transfer_function\n",
    "from juart.conopt.functional.fourier import nonuniform_fourier_transform_adjoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0669749c-c770-4067-b87f-b59bf7f4ff09",
   "metadata": {},
   "source": [
    "# Load preprocessed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "969c7c2c-dfd0-403c-aa29-4d4154da7bbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset holds following data: <KeysViewHDF5 ['coilsens', 'd', 'k']>\n",
      "Coilsensitivity info: Shape (Channels, Nx, Ny, Nz).\n",
      "Trajectory info: Shape (Dimensions, Samples, Echotimes). Scaled in units of cycle/fov\n",
      "Signal info: Shape (Channels, Samples, Echotimes).\n",
      "Coilsensitivity shape (8, 156, 156, 156)\n",
      "Trajectory shape (3, 2001191, 2)\n",
      "Signal shape (8, 2001191, 2)\n"
     ]
    }
   ],
   "source": [
    "data_path = \"data/3DLiss_vd_preproc.h5\"\n",
    "with h5py.File(data_path, \"r\") as f:\n",
    "    print(f\"Dataset holds following data: {f.keys()}\")\n",
    "\n",
    "    print(f\"Coilsensitivity info: {f['coilsens'].attrs['info']}\")\n",
    "    print(f\"Trajectory info: {f['k'].attrs['info']}\")\n",
    "    print(f\"Signal info: {f['d'].attrs['info']}\")\n",
    "\n",
    "    ktraj = f['k'][:]\n",
    "    coilsens = f['coilsens'][:]\n",
    "    d = f['d'][:]\n",
    "\n",
    "    print(f\"Coilsensitivity shape {coilsens.shape}\")\n",
    "    print(f\"Trajectory shape {ktraj.shape}\")\n",
    "    print(f\"Signal shape {d.shape}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2667a5e3-5929-42b4-90f1-4284546b62e8",
   "metadata": {},
   "source": [
    "# Convert data to JUART format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2959cb00-895a-4d92-8e6b-5da1065ff12b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min/Max of trajectory: -78.62955474853516 / 78.626708984375\n",
      "Min/Max of trajectory: -0.5000181198120117 / 0.5\n"
     ]
    }
   ],
   "source": [
    "# Scale trajectory to [-0.5, 0.5]\n",
    "print(f\"Min/Max of trajectory: {ktraj.min()} / {ktraj.max()}\")\n",
    "ktraj = ktraj / (2*ktraj.max())\n",
    "print(f\"Min/Max of trajectory: {ktraj.min()} / {ktraj.max()}\")\n",
    "\n",
    "ktraj = torch.from_numpy(ktraj)\n",
    "coilsens = torch.from_numpy(coilsens)\n",
    "d = torch.from_numpy(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d7173a-ff1f-4938-bf18-e41bd6a04023",
   "metadata": {},
   "source": [
    "# Perform 3D CG-SENSE reconstruction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a172c1-0326-44e9-ba3a-d569bf667456",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a9dba386-dd41-42bf-a9f3-6123df9546d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([156, 156, 156, 2])\n"
     ]
    }
   ],
   "source": [
    "AHd = nonuniform_fourier_transform_adjoint(ktraj,d,(156,156,156))\n",
    "AHd = torch.sum(torch.conj(coilsens[...,None]) * AHd, dim=0)\n",
    "print(AHd.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b5b60941-985e-4f16-9493-c8eb9ef4c4c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 312, 312, 312, 2])\n"
     ]
    }
   ],
   "source": [
    "H = nonuniform_transfer_function(ktraj,(1,156,156,156,2),oversampling=(2,2,2))\n",
    "print(H.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7ed43d6c-9dc7-48df-8c87-143022d7f5be",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The expanded size of the tensor (2) must match the existing size (156) at non-singleton dimension 4.  Target sizes: [8, 156, 156, 156, 2].  Tensor sizes: [8, 156, 156, 156]",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[75]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m cg_solver = \u001b[43mSENSE\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcoilsens\u001b[49m\u001b[43m,\u001b[49m\u001b[43mAHd\u001b[49m\u001b[43m,\u001b[49m\u001b[43mH\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<string>:30\u001b[39m, in \u001b[36m__init__\u001b[39m\u001b[34m(self, coil_sensitivities, regridded_data, transfer_function, channel_normalize, maxiter, verbose, callback, device)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/juart/examples/../src/juart/conopt/linops/channel.py:58\u001b[39m, in \u001b[36mChannelOperator.__init__\u001b[39m\u001b[34m(self, coil_sensitivities, data_shape, normalize, device)\u001b[39m\n\u001b[32m     55\u001b[39m coil_sensitivities = coil_sensitivities.to(device)\n\u001b[32m     57\u001b[39m \u001b[38;5;66;03m# Store coil sensitivities, ensuring correct dimensions and device\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m58\u001b[39m \u001b[38;5;28mself\u001b[39m.coil_sensitivities = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbroadcast_to\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     59\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcoil_sensitivities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     60\u001b[39m \u001b[43m    \u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcoil_sensitivities\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[32;43m4\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43madd_axes\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     61\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     63\u001b[39m \u001b[38;5;66;03m# Normalize to unit spectral norm if required\u001b[39;00m\n\u001b[32m     64\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m normalize:\n",
      "\u001b[31mRuntimeError\u001b[39m: The expanded size of the tensor (2) must match the existing size (156) at non-singleton dimension 4.  Target sizes: [8, 156, 156, 156, 2].  Tensor sizes: [8, 156, 156, 156]"
     ]
    }
   ],
   "source": [
    "cg_solver = SENSE(coilsens,AHd,H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d25cb57-7beb-4d48-a54f-f70989337a37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
