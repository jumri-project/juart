{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "376ad082-4e9a-401e-9a7c-88f0a6f25b3f",
   "metadata": {},
   "source": [
    "# Training Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b52213f-77ba-4b82-aca7-78800499c2d4",
   "metadata": {},
   "source": [
    "## Import of all needed scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f49c1f36-daa3-450f-9d98-e1a96bd7281f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib widget\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, \"../../src\")\n",
    "\n",
    "import gc\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.distributed as dist\n",
    "\n",
    "from juart.dl.checkpoint.manager import CheckpointManager\n",
    "from juart.dl.data.training import DatasetTraining\n",
    "from juart.dl.loss.loss import JointLoss\n",
    "from juart.dl.model.unrollnet import (\n",
    "    LookaheadModel,\n",
    "    UnrolledNet,\n",
    ")\n",
    "from juart.dl.operation.modules import training, validation\n",
    "from juart.dl.utils.dist import GradientAccumulator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a280b4ee-1de8-481c-93a8-882b45e2fea4",
   "metadata": {},
   "source": [
    "## Defining shuffle function\n",
    "When training a model the slices and subjects of the datasets should not be in order. Therefore this function creates a random order for every single epoch, granting that every slice is used once and only once in every epoch. It is possible to give the function a seed so that the random order is the same order in every training. This is used for better comparability of the models, because the accuracy of the models can slightly variate with the order of the slices and subjects in the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "617f4bce-3c55-40e9-b128-ae4986c86f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffled_indices(num_samples, num_epochs, rng):\n",
    "    indices = np.repeat(np.arange(num_samples), num_epochs)\n",
    "    indices = indices.reshape((num_samples, num_epochs))\n",
    "    indices = rng.permuted(indices, axis=0)\n",
    "    indices = indices.T.ravel()\n",
    "\n",
    "    # Check if each sample is used once and only once in every epoch\n",
    "    assert indices.size == num_samples * num_epochs\n",
    "    for i in np.split(indices, num_epochs):\n",
    "        assert np.unique(i).size == num_samples\n",
    "\n",
    "    return indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021c2169-2a1d-4683-8a63-a763f4058c7e",
   "metadata": {},
   "source": [
    "## Define important variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "abb11e6e-88ae-41db-9d3a-8a243df736d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset options\n",
    "nX, nY, nZ = 256, 256, 1  # Number of pixels in x-/y-/z-direction\n",
    "nTI, nTE = 2, 2  # Number of measurements during the T1/T2 decay\n",
    "shape = (nX, nY, nZ, nTI, nTE)  # Defining the shape later used for the model\n",
    "num_spokes = 64  # number of spokes that should be used for training\n",
    "nD = 1  # Number of subjects\n",
    "nS = 160  # Number of slices per subject\n",
    "\n",
    "# device options\n",
    "device = \"cpu\"  # defines whether the model should be trained on the cpu or gpu\n",
    "group = None\n",
    "group_rank = 0\n",
    "group_index = 0\n",
    "num_groups = 1\n",
    "\n",
    "# CheckpointManager Options\n",
    "load_model_state = True  # Load the last saved model state\n",
    "load_averaged_model_state = True  # Load the last saved averaged model state\n",
    "load_optim_state = True  # Load the las saved optimizer state\n",
    "load_metrics = True  # Load the last saved metrics (iterations and loss)\n",
    "directory = \"model_test\"  # Name that is used for the save directory of the model\n",
    "root_dir = \"/home/jovyan/models\"  # path of the model directory\n",
    "backend = \"local\"  # backend of the model directory\n",
    "\n",
    "# Training loop options\n",
    "num_epochs = 1  # Number of epochs of the training\n",
    "model_training = True  # Activate Training mode\n",
    "model_validation = False  # Activate validation mode\n",
    "save_checkpoint = (\n",
    "    True  # Create save files that contain the current state of the training\n",
    ")\n",
    "checkpoint_frequency = 10  # Sets the number of iterations between creating save files\n",
    "single_epoch = True  # Create a seperate save file after every single epoch\n",
    "batch_size = 1  # Number of slices that should be used for training per batch\n",
    "\n",
    "batch_size_local = batch_size // num_groups\n",
    "num_iterations = nD * nS * num_epochs  # complete number of iterations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d5bdcb-b12a-4998-b790-454186ccc305",
   "metadata": {},
   "source": [
    "## Randomize indices\n",
    "The shuffle function gets used to shuffle the indices of the training and validation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17d203d9-c38d-4171-afb6-bf9109a744a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(seed=0)\n",
    "\n",
    "training_indices = shuffled_indices(nD * nS, num_epochs, rng)\n",
    "training_indices_batched = training_indices.reshape((-1, batch_size_local, num_groups))\n",
    "\n",
    "validation_indices = shuffled_indices(nD * nS, num_epochs, rng)\n",
    "validation_indices_batched = validation_indices.reshape(\n",
    "    (-1, batch_size_local, num_groups)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f29f6e48-096f-41a5-97fb-1a85e9743c18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n"
     ]
    }
   ],
   "source": [
    "dist.init_process_group(\n",
    "    backend=\"gloo\", init_method=\"tcp://127.0.0.1:23456\", world_size=1, rank=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edfdd93f-269a-4b81-82e2-ab084e908058",
   "metadata": {},
   "source": [
    "## Initializing the model\n",
    "In this cell the model gets initialized and set up for the specific dataset, that is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b313da1-7a4e-46ec-8215-1fa999ab102c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UnrolledNet(\n",
    "    shape,\n",
    "    features=64,\n",
    "    CG_Iter=10,\n",
    "    num_unroll_blocks=10,\n",
    "    activation=\"ReLU\",\n",
    "    disable_progress_bar=True,\n",
    "    timing_level=0,\n",
    "    validation_level=0,\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbfe7a61-9573-4013-b511-f472db2afb1a",
   "metadata": {},
   "source": [
    "## Defining the loss function\n",
    "The loss function takes the prediction of the model and the correct result to compute the resulting loss. The loss will be separated in different parts (kspace, ispace, wavelet,...) and then be weighted with the matching weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ac1e029-5ce2-457a-853b-54545625aab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = JointLoss(\n",
    "    shape,\n",
    "    (3, 3),\n",
    "    weights_kspace_loss=(0.5, 0.5),\n",
    "    weights_ispace_loss=(0.0, 0.0),\n",
    "    weights_wavelet_loss=(0.0, 0.0),\n",
    "    weights_hankel_loss=(0.0, 0.0),\n",
    "    weights_casorati_loss=(0.0, 0.0),\n",
    "    normalized_loss=True,\n",
    "    timing_level=0,\n",
    "    validation_level=0,\n",
    "    group=group,\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9f82bf-0b53-422d-8d26-96a8813f0781",
   "metadata": {},
   "source": [
    "## Setting up the optimizer\n",
    "The optimizer is used for adapting the model parameters so that the prediction of the model will get closer to the correct result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "406e2d52-dcbe-4783-bf8f-170c0c1fd728",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=0.0001,\n",
    "    betas=[0.9, 0.999],\n",
    "    eps=1.0e-8,\n",
    "    weight_decay=0.0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60b74295-cab2-480d-9433-f2fea449277f",
   "metadata": {},
   "outputs": [],
   "source": [
    "accumulator = GradientAccumulator(\n",
    "    model,\n",
    "    accumulation_steps=batch_size_local,\n",
    "    max_norm=1.0,\n",
    "    normalized_gradient=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa72d410-53aa-4cc5-ad4d-7f11779e3652",
   "metadata": {},
   "source": [
    "## The average model\n",
    "The average model uses the floating average of the original model. This approach is more robust then using the original model directly for the reconstruction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb368c3e-b524-4fb3-8ed6-389e876a7662",
   "metadata": {},
   "outputs": [],
   "source": [
    "averaged_model = LookaheadModel(\n",
    "    model,\n",
    "    alpha=0.5,\n",
    "    k=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad0e1a80-a277-4975-996a-679bc499cf99",
   "metadata": {},
   "source": [
    "## Initializing the CheckpointManager\n",
    "The CheckpointManager allows to save the model in a specific location or load a model from a specific location. Here the location is defined in which the CheckpointManager is operating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b64a1b7-d2d2-4578-8f26-ebf1dc5b6b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_manager = CheckpointManager(\n",
    "    directory=directory,\n",
    "    root_dir=root_dir,\n",
    "    backend=backend,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "714e51d2-898e-4255-9f55-d7fffe26e07b",
   "metadata": {},
   "source": [
    "## Loading save files with the CheckpointManager if available\n",
    "### Load saved model\n",
    "The following cell will test if theres a saved model_state already. It will load the current state and will provide that the training process will continue at the same point where it was saved the last time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "65999c4b-92d0-4433-a8bc-074e707f390f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model state ...\n",
      "Could not load model state.\n"
     ]
    }
   ],
   "source": [
    "if load_model_state:\n",
    "    print(\"Loading model state ...\")\n",
    "    checkpoint = checkpoint_manager.load([\"model_state\"], map_location=device)\n",
    "    if all(checkpoint.values()):\n",
    "        model.load_state_dict(checkpoint[\"model_state\"])\n",
    "    else:\n",
    "        print(\"Could not load model state.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3108467-4c90-4fdc-ab57-ec25ce7802e1",
   "metadata": {},
   "source": [
    "### Load saved averaged model\n",
    "The next cell will do the same thing but just for the averaged model and not for the original model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "821761fa-be45-4635-957a-4165a6ef573e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading averaged model state ...\n",
      "Could not load averaged model state.\n"
     ]
    }
   ],
   "source": [
    "if load_averaged_model_state:\n",
    "    print(\"Loading averaged model state ...\")\n",
    "    checkpoint = checkpoint_manager.load([\"averaged_model_state\"], map_location=device)\n",
    "    if all(checkpoint.values()):\n",
    "        averaged_model.load_state_dict(checkpoint[\"averaged_model_state\"])\n",
    "    else:\n",
    "        print(\"Could not load averaged model state.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31bc42d9-b62c-4e77-9384-2f3d94e7a8b2",
   "metadata": {},
   "source": [
    "### Load saved optimizer\n",
    "This cell will load the last saved state of the optimizer of the saved model, so that the optimizer parameters, which where achieved through previous iterations, still have their impact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "23c48de6-e87a-4a90-ba43-0aef7df8664e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading optim state ...\n",
      "Could not load optim state.\n"
     ]
    }
   ],
   "source": [
    "if load_optim_state:\n",
    "    print(\"Loading optim state ...\")\n",
    "    checkpoint = checkpoint_manager.load([\"optim_state\"], map_location=device)\n",
    "    if all(checkpoint.values()):\n",
    "        optimizer.load_state_dict(checkpoint[\"optim_state\"])\n",
    "    else:\n",
    "        print(\"Could not load optim state.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3333df6d-18e3-4a15-85e9-3d0deaa5a8af",
   "metadata": {},
   "source": [
    "### Load saved metrics\n",
    "In the following cells the last saved loss and the last saved iteration of the saved model will be loaded from the save files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "424ede94-dc37-4db4-9c3a-a24773169f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_trn_loss = list()\n",
    "total_val_loss = list()\n",
    "iteration = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7724ebad-0b3a-4d80-8d33-754b42db55ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading metrics ...\n",
      "Could not load metrics.\n"
     ]
    }
   ],
   "source": [
    "if load_metrics:\n",
    "    print(\"Loading metrics ...\")\n",
    "    checkpoint = checkpoint_manager.load([\"trn_loss\", \"val_loss\", \"iteration\"])\n",
    "    if all(checkpoint.values()):\n",
    "        total_trn_loss = list(checkpoint[\"trn_loss\"])\n",
    "        total_val_loss = list(checkpoint[\"val_loss\"])\n",
    "        iteration = checkpoint[\"iteration\"]\n",
    "    else:\n",
    "        print(\"Could not load metrics.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11d6e67-7b85-407d-8e53-358499d0c5a8",
   "metadata": {},
   "source": [
    "This cells gives an output which will have the information about the last saved iteration from the model. The training will continue at this iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2937b104-b42d-4c58-bb2b-722705a0e39a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continue with iteration 0 ...\n"
     ]
    }
   ],
   "source": [
    "print(f\"Continue with iteration {iteration} ...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0f7966-6707-4ced-9211-2da011c6a095",
   "metadata": {},
   "source": [
    "## Loading Dataset for Training and Validation\n",
    "The dataset can be varied in the number of slices, number of spokes, split_fractions and mode (training/validation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "10cb5fd6-2278-4477-b8ed-58450a041abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = DatasetTraining(\n",
    "    \"qrage/sessions/%s/preproc.zarr/preproc.zarr\",\n",
    "    [\"7T1566\"],\n",
    "    np.arange(0, 160),\n",
    "    num_spokes,\n",
    "    [0.0, 0.5, 0.5],\n",
    "    mode=\"training\",\n",
    "    group_rank=group_rank,\n",
    "    endpoint_url=\"https://s3.fz-juelich.de\",\n",
    "    backend=\"s3\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "390ac877-4988-492e-9da6-91836d624fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data = DatasetTraining(\n",
    "    \"qrage/sessions/%s/preproc.zarr/preproc.zarr\",\n",
    "    [\"7T1566\"],\n",
    "    np.arange(0, 160),\n",
    "    num_spokes,\n",
    "    [0.0, 0.5, 0.5],\n",
    "    mode=\"validation\",\n",
    "    group_rank=group_rank,\n",
    "    endpoint_url=\"https://s3.fz-juelich.de\",\n",
    "    backend=\"s3\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a0cfd4-9abd-46f3-82e0-2f27b1a011fb",
   "metadata": {},
   "source": [
    "## Main training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "32731745-4018-40e5-851d-41e44cdc10ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training index [10] ...\n",
      "Data - Started loading Dataset 7T1566 - Slice 10 ...\n",
      "Data - Completed loading dataset in 3.7 seconds.\n",
      "Rank 0 - Data - Started creating masks [0.0, 0.5, 0.5] ...\n",
      "Rank 0 - Data - Source fractions 0.5.\n",
      "Rank 0 - Data - Target fractions 0.5.\n",
      "Rank 0 - Data - Completed creating mask torch.Size([3, 1, 16384, 2, 2]) in 0.1 seconds.\n",
      "Rank 0 - Data - Started regridding dataset ...\n",
      "Rank 0 - Data - Completed regridding dataset torch.Size([256, 256, 1, 2, 2]) in 0.3 seconds.\n",
      "Layer 0 done\n",
      "Layer 1 done\n",
      "Layer 2 done\n",
      "Layer 3 done\n",
      "Layer 4 done\n",
      "Layer 5 done\n",
      "Layer 6 done\n",
      "Layer 7 done\n",
      "Layer 8 done\n",
      "Layer 9 done\n",
      "Layer 10 done\n",
      "Layer 11 done\n",
      "Layer 12 done\n",
      "Layer 13 done\n",
      "Layer 14 done\n",
      "Layer 0 done\n",
      "Layer 1 done\n",
      "Layer 2 done\n",
      "Layer 3 done\n",
      "Layer 4 done\n",
      "Layer 5 done\n",
      "Layer 6 done\n",
      "Layer 7 done\n",
      "Layer 8 done\n",
      "Layer 9 done\n",
      "Layer 10 done\n",
      "Layer 11 done\n",
      "Layer 12 done\n",
      "Layer 13 done\n",
      "Layer 14 done\n",
      "Layer 0 done\n",
      "Layer 1 done\n",
      "Layer 2 done\n",
      "Layer 3 done\n",
      "Layer 4 done\n",
      "Layer 5 done\n",
      "Layer 6 done\n",
      "Layer 7 done\n",
      "Layer 8 done\n",
      "Layer 9 done\n",
      "Layer 10 done\n",
      "Layer 11 done\n",
      "Layer 12 done\n",
      "Layer 13 done\n",
      "Layer 14 done\n",
      "Layer 0 done\n",
      "Layer 1 done\n",
      "Layer 2 done\n",
      "Layer 3 done\n",
      "Layer 4 done\n",
      "Layer 5 done\n",
      "Layer 6 done\n",
      "Layer 7 done\n",
      "Layer 8 done\n",
      "Layer 9 done\n",
      "Layer 10 done\n",
      "Layer 11 done\n",
      "Layer 12 done\n",
      "Layer 13 done\n",
      "Layer 14 done\n",
      "Layer 0 done\n",
      "Layer 1 done\n",
      "Layer 2 done\n",
      "Layer 3 done\n",
      "Layer 4 done\n",
      "Layer 5 done\n",
      "Layer 6 done\n",
      "Layer 7 done\n",
      "Layer 8 done\n",
      "Layer 9 done\n",
      "Layer 10 done\n",
      "Layer 11 done\n",
      "Layer 12 done\n",
      "Layer 13 done\n",
      "Layer 14 done\n",
      "Layer 0 done\n",
      "Layer 1 done\n",
      "Layer 2 done\n",
      "Layer 3 done\n",
      "Layer 4 done\n",
      "Layer 5 done\n",
      "Layer 6 done\n",
      "Layer 7 done\n",
      "Layer 8 done\n",
      "Layer 9 done\n",
      "Layer 10 done\n",
      "Layer 11 done\n",
      "Layer 12 done\n",
      "Layer 13 done\n",
      "Layer 14 done\n",
      "Layer 0 done\n",
      "Layer 1 done\n",
      "Layer 2 done\n",
      "Layer 3 done\n",
      "Layer 4 done\n",
      "Layer 5 done\n",
      "Layer 6 done\n",
      "Layer 7 done\n",
      "Layer 8 done\n",
      "Layer 9 done\n",
      "Layer 10 done\n",
      "Layer 11 done\n",
      "Layer 12 done\n",
      "Layer 13 done\n",
      "Layer 14 done\n",
      "Layer 0 done\n",
      "Layer 1 done\n",
      "Layer 2 done\n",
      "Layer 3 done\n",
      "Layer 4 done\n",
      "Layer 5 done\n",
      "Layer 6 done\n",
      "Layer 7 done\n",
      "Layer 8 done\n",
      "Layer 9 done\n",
      "Layer 10 done\n",
      "Layer 11 done\n",
      "Layer 12 done\n",
      "Layer 13 done\n",
      "Layer 14 done\n",
      "Layer 0 done\n",
      "Layer 1 done\n",
      "Layer 2 done\n",
      "Layer 3 done\n",
      "Layer 4 done\n",
      "Layer 5 done\n",
      "Layer 6 done\n",
      "Layer 7 done\n",
      "Layer 8 done\n",
      "Layer 9 done\n",
      "Layer 10 done\n",
      "Layer 11 done\n",
      "Layer 12 done\n",
      "Layer 13 done\n",
      "Layer 14 done\n",
      "Layer 0 done\n",
      "Layer 1 done\n",
      "Layer 2 done\n",
      "Layer 3 done\n",
      "Layer 4 done\n",
      "Layer 5 done\n",
      "Layer 6 done\n",
      "Layer 7 done\n",
      "Layer 8 done\n",
      "Layer 9 done\n",
      "Layer 10 done\n",
      "Layer 11 done\n",
      "Layer 12 done\n",
      "Layer 13 done\n",
      "Layer 14 done\n",
      "torch.Size([8, 16384, 2, 2]) torch.Size([1, 16384, 2, 2])\n",
      "[KSpaceLoss] torch.Size([8, 16384, 2, 2]) torch.Size([8, 16384, 2, 2]) None\n",
      "Rank 0 - Loss k-space: 0.432 - Loss image space: 0.000 - Loss Wavelet 0.000 - Loss Hankel 0.000 - Loss Casorati 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process SpawnProcess-1:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.13/multiprocessing/process.py\", line 313, in _bootstrap\n",
      "    self.run()\n",
      "    ~~~~~~~~^^\n",
      "  File \"/opt/conda/lib/python3.13/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/juart/examples/dl/../../src/juart/dl/checkpoint/manager.py\", line 89, in save_checkpoint_process\n",
      "    self.save_buffer_to_filesystem(*self.save_queue.get())\n",
      "                                    ~~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"/opt/conda/lib/python3.13/multiprocessing/queues.py\", line 101, in get\n",
      "    res = self._recv_bytes()\n",
      "  File \"/opt/conda/lib/python3.13/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/opt/conda/lib/python3.13/multiprocessing/connection.py\", line 430, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/opt/conda/lib/python3.13/multiprocessing/connection.py\", line 395, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 21\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m model_training:\n\u001b[32m     19\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTraining index \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtraining_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m ...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m     trn_loss = \u001b[43mtraining\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtraining_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtraining_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[43m        \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[43m        \u001b[49m\u001b[43maccumulator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     30\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     32\u001b[39m     averaged_model.update_parameters(\n\u001b[32m     33\u001b[39m         model,\n\u001b[32m     34\u001b[39m     )\n\u001b[32m     36\u001b[39m     torch.cuda.empty_cache()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/juart/examples/dl/../../src/juart/dl/operation/modules.py:52\u001b[39m, in \u001b[36mtraining\u001b[39m\u001b[34m(indices, dataset, model, loss_fn, optimizer, accumulator, group, device)\u001b[39m\n\u001b[32m     42\u001b[39m loss = loss_fn(\n\u001b[32m     43\u001b[39m     images_reconstructed,\n\u001b[32m     44\u001b[39m     images_regridded,\n\u001b[32m   (...)\u001b[39m\u001b[32m     48\u001b[39m     sensitivity_maps,\n\u001b[32m     49\u001b[39m )\n\u001b[32m     51\u001b[39m \u001b[38;5;66;03m# Backpropagation\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[38;5;66;03m# Accumulate gradients\u001b[39;00m\n\u001b[32m     55\u001b[39m accumulator.accumulate()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.13/site-packages/torch/_tensor.py:647\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    637\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    638\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    639\u001b[39m         Tensor.backward,\n\u001b[32m    640\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    645\u001b[39m         inputs=inputs,\n\u001b[32m    646\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m647\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    648\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    649\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.13/site-packages/torch/autograd/__init__.py:354\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    349\u001b[39m     retain_graph = create_graph\n\u001b[32m    351\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    352\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    353\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m354\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_tuple\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    362\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.13/site-packages/torch/autograd/graph.py:829\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    827\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    828\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m829\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    830\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    831\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    832\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    833\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.13/site-packages/torch/utils/checkpoint.py:1131\u001b[39m, in \u001b[36m_checkpoint_hook.__init__.<locals>.unpack_hook\u001b[39m\u001b[34m(holder)\u001b[39m\n\u001b[32m   1128\u001b[39m             frame.x_metadatas.append(frame.metadata_fn(x))\n\u001b[32m   1129\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m holder\n\u001b[32m-> \u001b[39m\u001b[32m1131\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34munpack_hook\u001b[39m(holder):\n\u001b[32m   1132\u001b[39m     gid = torch._C._current_graph_task_id()\n\u001b[32m   1133\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m gid == -\u001b[32m1\u001b[39m:\n\u001b[32m   1134\u001b[39m         \u001b[38;5;66;03m# generate a temporary id if we trigger unpack outside of a backward call\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "while iteration < num_iterations:\n",
    "    tic = time.time()\n",
    "\n",
    "    # Reset the seed so that training can be resumed\n",
    "    np.random.seed(iteration)\n",
    "    torch.manual_seed(iteration)\n",
    "\n",
    "    training_index = training_indices_batched[\n",
    "        iteration // batch_size,\n",
    "        :,\n",
    "        group_index,\n",
    "    ].tolist()\n",
    "    validation_index = validation_indices_batched[\n",
    "        iteration // batch_size, :, group_index\n",
    "    ].tolist()\n",
    "\n",
    "    # TRAINING\n",
    "    if model_training:\n",
    "        print(f\"Training index {training_index} ...\")\n",
    "\n",
    "        trn_loss = training(\n",
    "            training_index,\n",
    "            training_data,\n",
    "            model,\n",
    "            loss_fn,\n",
    "            optimizer,\n",
    "            accumulator,\n",
    "            group=group,\n",
    "            device=device,\n",
    "        )\n",
    "\n",
    "        averaged_model.update_parameters(\n",
    "            model,\n",
    "        )\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "\n",
    "    else:\n",
    "        trn_loss = [0] * batch_size\n",
    "\n",
    "    # VALIDATION\n",
    "    if model_validation:\n",
    "        print(f\"Validation index {validation_index} ...\")\n",
    "\n",
    "        val_loss = validation(\n",
    "            validation_index,\n",
    "            validation_data,\n",
    "            averaged_model,\n",
    "            loss_fn,\n",
    "            group=group,\n",
    "            device=device,\n",
    "        )\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "\n",
    "    else:\n",
    "        val_loss = [0] * batch_size\n",
    "\n",
    "    total_trn_loss += trn_loss\n",
    "    total_val_loss += val_loss\n",
    "\n",
    "    # SAVING\n",
    "    # Completed epoch\n",
    "    if save_checkpoint and np.mod(iteration + batch_size, nD * nS) == 0:\n",
    "        print(\"Creating tagged checkpoint ...\")\n",
    "\n",
    "        checkpoint = {\n",
    "            \"iteration\": iteration + batch_size,\n",
    "            \"model_state\": model.state_dict(),\n",
    "            \"averaged_model_state\": averaged_model.state_dict(),\n",
    "            \"optim_state\": optimizer.state_dict(),\n",
    "            \"trn_loss\": total_trn_loss,\n",
    "            \"val_loss\": total_val_loss,\n",
    "        }\n",
    "\n",
    "        epoch = (iteration + batch_size) // (nD * nS)\n",
    "        checkpoint_manager.save(checkpoint, tag=f\"_epoch_{epoch}\")\n",
    "\n",
    "        if single_epoch:\n",
    "            # Also save the checkpoint as untagged checkpoint\n",
    "            # Otherwise, training will be stuck in endless loop\n",
    "            checkpoint_manager.save(checkpoint)\n",
    "            checkpoint_manager.release()\n",
    "            break\n",
    "\n",
    "    # Intermediate checkpoint\n",
    "    elif save_checkpoint and np.mod(iteration + batch_size, checkpoint_frequency) == 0:\n",
    "        print(\"Creating untagged checkpoint ...\")\n",
    "\n",
    "        checkpoint = {\n",
    "            \"iteration\": iteration + batch_size,\n",
    "            \"model_state\": model.state_dict(),\n",
    "            \"averaged_model_state\": averaged_model.state_dict(),\n",
    "            \"optim_state\": optimizer.state_dict(),\n",
    "            \"trn_loss\": total_trn_loss,\n",
    "            \"val_loss\": total_val_loss,\n",
    "        }\n",
    "\n",
    "        checkpoint_manager.save(checkpoint, block=False)\n",
    "\n",
    "    toc = time.time() - tic\n",
    "\n",
    "    print(\n",
    "        (\n",
    "            f\"Iteration: {iteration} - \"\n",
    "            + f\"Elapsed time: {toc:.0f} - \"\n",
    "            + f\"Training loss: {[f'{loss:.3f}' for loss in trn_loss]} - \"\n",
    "            + f\"Validation loss: {[f'{loss:.3f}' for loss in val_loss]}\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "    iteration += batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f33a07d-a000-4045-89db-dad07ba5e894",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
