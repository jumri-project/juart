{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8543efe-dbcc-4077-ae4f-1040b6f8654d",
   "metadata": {},
   "source": [
    "# Training script for 3D reconstruction models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7863bb8b-04e4-4d77-9d10-918e2c3b8148",
   "metadata": {},
   "source": [
    "## Import of needed classes and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f803bad-2391-4716-8bef-76c70261ae46",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib widget\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, \"../../src\")\n",
    "\n",
    "import gc\n",
    "import time\n",
    "\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.distributed as dist\n",
    "import zarr as z\n",
    "\n",
    "from juart.conopt.functional.fourier import (\n",
    "    fourier_transform_adjoint,\n",
    "    fourier_transform_forward,\n",
    "    nonuniform_fourier_transform_adjoint,\n",
    ")\n",
    "from juart.conopt.tfs.fourier import nonuniform_transfer_function\n",
    "from juart.dl.checkpoint.manager import CheckpointManager\n",
    "from juart.dl.loss.loss import JointLoss\n",
    "from juart.dl.model.unrollnet import (\n",
    "    LookaheadModel,\n",
    "    UnrolledNet,\n",
    ")\n",
    "from juart.dl.operation.modules import training, validation\n",
    "from juart.dl.utils.dist import GradientAccumulator\n",
    "from juart.vis.interactive import InteractiveFigure3D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e490d5-b2ee-43db-9f46-b34a89e987a5",
   "metadata": {},
   "source": [
    "## Definition of the most important variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "090603f7-cab4-40eb-b91b-1c2dd46c1739",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset options\n",
    "nX, nY, nZ = 156,156,156  # Number of pixels in x-/y-/z-direction\n",
    "kspace_cutoff = False  # defines if nX,... should be reduced\n",
    "nX_cutoff, nY_cutoff, nZ_cutoff = 64, 64, 64  # defines nX,... for the cutoff state\n",
    "nTI, nTE = 2, 1  # Number of measurements during the T1/T2 decay\n",
    "shape = (nX, nY, nZ, nTI, nTE)  # Defining the shape later used for the model\n",
    "nD = 1  # Number of subjects\n",
    "nP = 2  # Number of slices per subject\n",
    "\n",
    "# device options\n",
    "device = \"cuda:2\"  # defines whether the model should be trained on the cpu or gpu\n",
    "group = None\n",
    "group_rank = 0\n",
    "group_index = 0\n",
    "num_groups = 1\n",
    "\n",
    "# Training loop options\n",
    "num_epochs = 2  # Number of epochs of the training\n",
    "model_training = True  # Activate Training mode\n",
    "model_validation = False  # Activate validation mode\n",
    "save_checkpoint = (\n",
    "    True  # Create save files that contain the current state of the training\n",
    ")\n",
    "checkpoint_frequency = 5  # Sets the number of iterations between creating save files\n",
    "single_epoch = False  # Create a seperate save file after every single epoch\n",
    "batch_size = 1  # Number of slices that should be used for training per batch\n",
    "\n",
    "# model options\n",
    "cgiter = 2\n",
    "num_unroll_blocks = 10\n",
    "activation = \"ReLU\"\n",
    "features = 16\n",
    "disable_progress_bar = False\n",
    "kernel_size = (3, 3, 3)\n",
    "Checkpoints = True\n",
    "\n",
    "# CheckpointManager Options\n",
    "load_model_state = True  # Load the last saved model state\n",
    "load_averaged_model_state = True  # Load the last saved averaged model state\n",
    "load_optim_state = True  # Load the las saved optimizer state\n",
    "load_metrics = True  # Load the last saved metrics (iterations and loss)\n",
    "directory = (\n",
    "    f\"model_test\"  # Name that is used for the save directory of the model\n",
    ")\n",
    "root_dir = \"/home/jovyan/models\"  # path of the model directory\n",
    "backend = \"local\"  # backend of the model directory\n",
    "\n",
    "batch_size_local = batch_size // num_groups\n",
    "num_iterations = nD * nP * num_epochs  # complete number of iterations\n",
    "iteration = 0  # current iteration number\n",
    "\n",
    "dtype = torch.complex64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ccc7b515-c6c4-4e80-843b-087e2192a551",
   "metadata": {},
   "outputs": [],
   "source": [
    "if kspace_cutoff:\n",
    "    nX, nY, nZ = nX_cutoff, nY_cutoff, nZ_cutoff\n",
    "    shape = (nX, nY, nZ, nTI, nTE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1acb39ca-f71a-42fa-a816-97248b3ed566",
   "metadata": {},
   "source": [
    "## Initializing worker groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8a92c6a-3c4a-4c54-9fb3-4a0ca7e9ea72",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist.init_process_group(\n",
    "    backend=\"gloo\", init_method=\"tcp://127.0.0.1:12345\", world_size=1, rank=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2ef423-a3b1-45ca-8454-d23d36ac923a",
   "metadata": {},
   "source": [
    "## Initializing the neural network\n",
    "### Initializing the model\n",
    "The model is the core of the neural network. Its forward pass describes the main steps of the neural network and the models features property describes the number of hidden features of the neural network and therefore its complexity. Furthermore the activation function and the number of iterations in dataconsistency term and regularization term is defined here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89917955-b31b-4f77-8787-91f4322b1c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UnrolledNet(\n",
    "    shape,\n",
    "    features=features,\n",
    "    CG_Iter=cgiter,\n",
    "    num_unroll_blocks=num_unroll_blocks,\n",
    "    num_of_resblocks = 10,\n",
    "    activation=activation,\n",
    "    disable_progress_bar=disable_progress_bar,\n",
    "    timing_level=0,\n",
    "    validation_level=0,\n",
    "    kernel_size=kernel_size,\n",
    "    regularizer=\"ResNet\",\n",
    "    Checkpoints = Checkpoints,\n",
    "    device=device,\n",
    "    dtype = dtype\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51918402-199d-4397-a631-b944aeb1f6f1",
   "metadata": {},
   "source": [
    "### Initializing the loss function\n",
    "The loss function defines how the difference between model prediction and correct result is calculated and it divides the loss into separate kinds of losses:\n",
    "- kspace\n",
    "- ispace\n",
    "- wavelet\n",
    "- hankel\n",
    "- casorati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b7c7e72-6ade-4bdb-b829-3fbd0f813f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = JointLoss(\n",
    "    shape,\n",
    "    3,\n",
    "    weights_kspace_loss=(0.5, 0.5),\n",
    "    weights_ispace_loss=(0.0, 0.0),\n",
    "    weights_wavelet_loss=(0.0, 0.0),\n",
    "    weights_hankel_loss=(0.0, 0.0),\n",
    "    weights_casorati_loss=(0.0, 0.0),\n",
    "    normalized_loss=True,\n",
    "    timing_level=0,\n",
    "    validation_level=0,\n",
    "    group=group,\n",
    "    device=device,\n",
    "    dtype = dtype\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65220517-26bf-44c5-8098-caa2e6afe2c1",
   "metadata": {},
   "source": [
    "### Initializing the optimizer\n",
    "The optimizer determines which impact the calculated loss has on the models parameters. The impact can be variated via the learning rate lr."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "815fcdd7-49cb-45b2-b6ce-337532c98117",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=0.0001,\n",
    "    betas=[0.9, 0.999],\n",
    "    eps=1.0e-8,\n",
    "    weight_decay=0.0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0af70828-ab59-4afa-b00c-9abd5b7a5b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "accumulator = GradientAccumulator(\n",
    "    model,\n",
    "    accumulation_steps=batch_size_local,\n",
    "    max_norm=1.0,\n",
    "    normalized_gradient=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb6f03a-b145-444f-9ac9-69c7ea42343f",
   "metadata": {},
   "source": [
    "### Initializing the averaged model\n",
    "The averaged model does not use the models parameters directly it uses the floating average of the model over the last n iterations. Its more robust than using the current average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e0ad0e2-b2fb-4f49-a728-1ebc352ca7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "averaged_model = LookaheadModel(\n",
    "    model,\n",
    "    alpha=0.5,\n",
    "    k=5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b38ece-47dc-4620-854a-4b63e5c7d699",
   "metadata": {},
   "source": [
    "## Checkpoint Manager\n",
    "### Initializing the CheckpointManager\n",
    "The CheckpointManager is useful for saving and/or loading models. In this case here it either creates a new directory for the model or it loads data from an already existing directory to continue the training at the point where it lastly stopped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a7ee50c-4c82-4f70-b4ac-1679327b75fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_manager = CheckpointManager(\n",
    "    directory=directory,\n",
    "    root_dir=root_dir,\n",
    "    backend=backend,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c9ea11-0729-4999-84fa-d7d55e6dc14d",
   "metadata": {},
   "source": [
    "#### Check if the model is already existing and load its last saved state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "20075413-eaf6-4b59-8d81-45989230fb49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model state ...\n",
      "Could not load model state.\n"
     ]
    }
   ],
   "source": [
    "if load_model_state:\n",
    "    print(\"Loading model state ...\")\n",
    "    checkpoint = checkpoint_manager.load([\"model_state\"], map_location=device)\n",
    "    if all(checkpoint.values()):\n",
    "        model.load_state_dict(checkpoint[\"model_state\"])\n",
    "    else:\n",
    "        print(\"Could not load model state.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c54eb6d6-b697-4635-b2ed-e26468cc349d",
   "metadata": {},
   "source": [
    "#### Check if the averaged model is already existing and load its last saved state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e3bfce16-23aa-4bd8-9996-f9e9a0961bd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading averaged model state ...\n",
      "Could not load averaged model state.\n"
     ]
    }
   ],
   "source": [
    "if load_averaged_model_state:\n",
    "    print(f\"Loading averaged model state ...\")\n",
    "    checkpoint = checkpoint_manager.load([\"averaged_model_state\"], map_location=device)\n",
    "    if all(checkpoint.values()):\n",
    "        averaged_model.load_state_dict(checkpoint[\"averaged_model_state\"])\n",
    "    else:\n",
    "        print(\"Could not load averaged model state.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee214f54-60a2-4979-b4b6-b5aa8f708965",
   "metadata": {},
   "source": [
    "#### Check if the optimizer is already existing and load its last saved state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "845b5fcb-d981-46a5-a630-c163cccc3ba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading optim state ...\n",
      "Could not load optim state.\n"
     ]
    }
   ],
   "source": [
    "if load_optim_state:\n",
    "    print(\"Loading optim state ...\")\n",
    "    checkpoint = checkpoint_manager.load([\"optim_state\"], map_location=device)\n",
    "    if all(checkpoint.values()):\n",
    "        optimizer.load_state_dict(checkpoint[\"optim_state\"])\n",
    "    else:\n",
    "        print(\"Could not load optim state.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "00f06beb-1fae-4f46-b18f-c315adcaa3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_trn_loss = list()\n",
    "total_val_loss = list()\n",
    "iteration = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19fbc05-8e30-4ba8-a508-a7e5304b204b",
   "metadata": {},
   "source": [
    "#### Load the last saved state of the loss and the current iteration if existing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3fb75752-08b0-4828-9927-56ccd2ff3c41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading metrics ...\n",
      "Could not load metrics.\n"
     ]
    }
   ],
   "source": [
    "if load_metrics:\n",
    "    print(\"Loading metrics ...\")\n",
    "    checkpoint = checkpoint_manager.load([\"trn_loss\", \"val_loss\", \"iteration\"])\n",
    "    if all(checkpoint.values()):\n",
    "        total_trn_loss = list(checkpoint[\"trn_loss\"])\n",
    "        total_val_loss = list(checkpoint[\"val_loss\"])\n",
    "        iteration = checkpoint[\"iteration\"]\n",
    "    else:\n",
    "        print(\"Could not load metrics.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f2e53759-ad14-4265-b6c6-e1f987af6756",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continue with iteration 0 ...\n"
     ]
    }
   ],
   "source": [
    "print(f\"Continue with iteration {iteration} ...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10fdc4b1-6130-4c9f-89c2-91821530f280",
   "metadata": {},
   "source": [
    "## Import the data that should be used for the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8204bc32-f2cf-4c2d-9f38-24cb037993ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coilsensitivity shape torch.Size([8, 156, 156, 156])\n",
      "Trajectory shape torch.Size([3, 2001191, 2, 1])\n",
      "Signal shape torch.Size([8, 2001191, 2, 1])\n"
     ]
    }
   ],
   "source": [
    "data_path = \"/home/jovyan/juart/examples/data/3DLiss_vd_preproc.h5\"\n",
    "with h5py.File(data_path, \"r\") as f:\n",
    "    \n",
    "    k = torch.from_numpy(f['k'][:])[...,None]\n",
    "    C = torch.from_numpy(f['coilsens'][:])\n",
    "    d = torch.from_numpy(f['d'][:])[...,None]\n",
    "\n",
    "    print(f\"Coilsensitivity shape {C.shape}\")\n",
    "    print(f\"Trajectory shape {k.shape}\")\n",
    "    print(f\"Signal shape {d.shape}\")\n",
    "\n",
    "k /= (2*k.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8b3f14f1-7d55-4bc0-8025-a5c3dd49977f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if kspace_cutoff == True:\n",
    "\n",
    "    mask = torch.linalg.norm(ktraj, dim=0) <= nX_cutoff // 2\n",
    "\n",
    "    ktraj = torch.stack(\n",
    "        [ktraj[:, mask[:, echo], echo] for echo in range(ktraj.shape[2])], dim=-1\n",
    "    )\n",
    "\n",
    "    d = torch.stack([d[:, mask[:, echo], echo] for echo in range(d.shape[2])], dim=-1)\n",
    "\n",
    "    coilsens_ksp = fourier_transform_forward(C, axes=(1, 2, 3))\n",
    "    low_lim, up_lim = int(156 / 2 - nX / 2), int(156 / 2 + nX / 2)\n",
    "    coilsens_ksp = coilsens_ksp[:, low_lim:up_lim, low_lim:up_lim, low_lim:up_lim]\n",
    "    C = fourier_transform_adjoint(coilsens_ksp, axes=(1, 2, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba035c9a-52f4-4fc0-93d8-1f923ca3a931",
   "metadata": {},
   "source": [
    "### shaping the data\n",
    "#### In the next steps the data is formed into the right shape so that the training function will understand how the data is structured."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "805653c7-3aa4-4c14-a974-3fa02fe20839",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = torch.Generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c8bdddfd-4362-4f4a-8d4d-74a7a74846be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0 / 4\n",
      "Rank 0 - reading data\n",
      "Rank 0 - reading data done -> model initialization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aktuell belegt: 1746.63 MB\n",
      "Aktuell belegt: 1812.69 MB\n",
      "Aktuell belegt: 1986.76 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:03<00:30,  3.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aktuell belegt: 1754.76 MB\n",
      "Aktuell belegt: 1812.69 MB\n",
      "Aktuell belegt: 1986.76 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:04<00:15,  1.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aktuell belegt: 1754.76 MB\n",
      "Aktuell belegt: 1812.69 MB\n",
      "Aktuell belegt: 1986.76 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:05<00:10,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aktuell belegt: 1754.76 MB\n",
      "Aktuell belegt: 1812.69 MB\n",
      "Aktuell belegt: 1986.76 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [00:06<00:07,  1.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aktuell belegt: 1754.76 MB\n",
      "Aktuell belegt: 1812.69 MB\n",
      "Aktuell belegt: 1986.76 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [00:07<00:06,  1.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aktuell belegt: 1754.76 MB\n",
      "Aktuell belegt: 1812.69 MB\n",
      "Aktuell belegt: 1986.76 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [00:08<00:04,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aktuell belegt: 1754.76 MB\n",
      "Aktuell belegt: 1812.69 MB\n",
      "Aktuell belegt: 1986.76 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [00:09<00:03,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aktuell belegt: 1754.76 MB\n",
      "Aktuell belegt: 1812.69 MB\n",
      "Aktuell belegt: 1986.76 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [00:10<00:02,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aktuell belegt: 1754.76 MB\n",
      "Aktuell belegt: 1812.69 MB\n",
      "Aktuell belegt: 1986.76 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [00:11<00:01,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aktuell belegt: 1754.76 MB\n",
      "Aktuell belegt: 1812.69 MB\n",
      "Aktuell belegt: 1986.76 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:12<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank 0 - model initialization done -> loss fn initialization\n",
      "[KSpaceLoss] torch.Size([8, 2001191, 2, 1]) torch.Size([8, 2001191, 2, 1]) None\n",
      "Rank 0 - Loss k-space: 1.376 - Loss image space: 0.000 - Loss Wavelet 0.000 - Loss Hankel 0.000 - Loss Casorati 0.000\n",
      "Rank 0 - loss fn initialization done -> compute backward pass\n",
      "Aktuell belegt: 1870.90 MB\n",
      "Aktuell belegt: 1936.95 MB\n",
      "Aktuell belegt: 2168.67 MB\n",
      "Rank 0 - compute backward pass done -> compute accumulator\n",
      "Rank 0 - Index 0 - Gradient norm: 4.301\n",
      "Averaged gradient norm: 1.000\n",
      "Iteration: 0 - Elapsed time: 73 - Training loss: ['1.376'] - Validation loss: ['0.000']\n",
      "current iteration: 1\n",
      "iteration 1 / 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process SpawnProcess-1:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.13/multiprocessing/process.py\", line 313, in _bootstrap\n",
      "    self.run()\n",
      "    ~~~~~~~~^^\n",
      "  File \"/opt/conda/lib/python3.13/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/juart/examples/dl/../../src/juart/dl/checkpoint/manager.py\", line 89, in save_checkpoint_process\n",
      "    self.save_buffer_to_filesystem(*self.save_queue.get())\n",
      "                                    ~~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"/opt/conda/lib/python3.13/multiprocessing/queues.py\", line 101, in get\n",
      "    res = self._recv_bytes()\n",
      "  File \"/opt/conda/lib/python3.13/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/opt/conda/lib/python3.13/multiprocessing/connection.py\", line 430, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/opt/conda/lib/python3.13/multiprocessing/connection.py\", line 395, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     10\u001b[39m kspace_mask_target = \u001b[32m1\u001b[39m - kspace_mask_source\n\u001b[32m     12\u001b[39m d_masked = d * kspace_mask_source\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m AHd = \u001b[43mnonuniform_fourier_transform_adjoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md_masked\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m156\u001b[39;49m\u001b[43m,\u001b[49m\u001b[32;43m156\u001b[39;49m\u001b[43m,\u001b[49m\u001b[32;43m156\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m AHd = torch.sum(torch.conj(C[..., \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m]) * AHd, dim=\u001b[32m0\u001b[39m)\n\u001b[32m     16\u001b[39m data = [\n\u001b[32m     17\u001b[39m     {\n\u001b[32m     18\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mimages_regridded\u001b[39m\u001b[33m\"\u001b[39m: AHd,\n\u001b[32m   (...)\u001b[39m\u001b[32m     24\u001b[39m     }\n\u001b[32m     25\u001b[39m ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/juart/examples/dl/../../src/juart/conopt/functional/fourier.py:400\u001b[39m, in \u001b[36mnonuniform_fourier_transform_adjoint\u001b[39m\u001b[34m(k, x, n_modes, modeord, isign, device, **finufftkwargs)\u001b[39m\n\u001b[32m    397\u001b[39m x = x.permute(\u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m, \u001b[32m0\u001b[39m)\n\u001b[32m    398\u001b[39m k = k.permute(\u001b[32m2\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m400\u001b[39m y = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvmap\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    401\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    402\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfinufft_type1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    403\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_shape\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_modes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    404\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodeord\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodeord\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    405\u001b[39m \u001b[43m        \u001b[49m\u001b[43misign\u001b[49m\u001b[43m=\u001b[49m\u001b[43misign\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    406\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfinufftkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    407\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    408\u001b[39m \u001b[43m    \u001b[49m\u001b[43min_dims\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    409\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcontiguous\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcontiguous\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    411\u001b[39m y /= norm\n\u001b[32m    413\u001b[39m \u001b[38;5;66;03m# Ensure y has nx ny nz dim\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.13/site-packages/torch/_functorch/apis.py:202\u001b[39m, in \u001b[36mvmap.<locals>.wrapped\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    201\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapped\u001b[39m(*args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m202\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mvmap_impl\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    203\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_dims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_dims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandomness\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    204\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.13/site-packages/torch/_functorch/vmap.py:334\u001b[39m, in \u001b[36mvmap_impl\u001b[39m\u001b[34m(func, in_dims, out_dims, randomness, chunk_size, *args, **kwargs)\u001b[39m\n\u001b[32m    323\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _chunked_vmap(\n\u001b[32m    324\u001b[39m         func,\n\u001b[32m    325\u001b[39m         flat_in_dims,\n\u001b[32m   (...)\u001b[39m\u001b[32m    330\u001b[39m         **kwargs,\n\u001b[32m    331\u001b[39m     )\n\u001b[32m    333\u001b[39m \u001b[38;5;66;03m# If chunk_size is not specified.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m334\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_flat_vmap\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    335\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    336\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    337\u001b[39m \u001b[43m    \u001b[49m\u001b[43mflat_in_dims\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    338\u001b[39m \u001b[43m    \u001b[49m\u001b[43mflat_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    339\u001b[39m \u001b[43m    \u001b[49m\u001b[43margs_spec\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    340\u001b[39m \u001b[43m    \u001b[49m\u001b[43mout_dims\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    341\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrandomness\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    342\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    343\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.13/site-packages/torch/_functorch/vmap.py:484\u001b[39m, in \u001b[36m_flat_vmap\u001b[39m\u001b[34m(func, batch_size, flat_in_dims, flat_args, args_spec, out_dims, randomness, **kwargs)\u001b[39m\n\u001b[32m    480\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m vmap_increment_nesting(batch_size, randomness) \u001b[38;5;28;01mas\u001b[39;00m vmap_level:\n\u001b[32m    481\u001b[39m     batched_inputs = _create_batched_inputs(\n\u001b[32m    482\u001b[39m         flat_in_dims, flat_args, vmap_level, args_spec\n\u001b[32m    483\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m484\u001b[39m     batched_outputs = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mbatched_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    485\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _unwrap_batched(batched_outputs, out_dims, vmap_level, batch_size, func)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.13/site-packages/pytorch_finufft/functional.py:497\u001b[39m, in \u001b[36mfinufft_type1\u001b[39m\u001b[34m(points, values, output_shape, **finufftkwargs)\u001b[39m\n\u001b[32m    458\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfinufft_type1\u001b[39m(\n\u001b[32m    459\u001b[39m     points: torch.Tensor,\n\u001b[32m    460\u001b[39m     values: torch.Tensor,\n\u001b[32m    461\u001b[39m     output_shape: Union[\u001b[38;5;28mint\u001b[39m, Tuple[\u001b[38;5;28mint\u001b[39m], Tuple[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mint\u001b[39m], Tuple[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mint\u001b[39m]],\n\u001b[32m    462\u001b[39m     **finufftkwargs: Union[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mfloat\u001b[39m],\n\u001b[32m    463\u001b[39m ) -> torch.Tensor:\n\u001b[32m    464\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    465\u001b[39m \u001b[33;03m    Evaluates the Type 1 (nonuniform-to-uniform) NUFFT on the inputs.\u001b[39;00m\n\u001b[32m    466\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    495\u001b[39m \u001b[33;03m        transform of the values.\u001b[39;00m\n\u001b[32m    496\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m497\u001b[39m     res: torch.Tensor = \u001b[43mFinufftType1\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpoints\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfinufftkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    498\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.13/site-packages/torch/autograd/function.py:585\u001b[39m, in \u001b[36mFunction.apply\u001b[39m\u001b[34m(cls, *args, **kwargs)\u001b[39m\n\u001b[32m    577\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_setup_ctx_defined:\n\u001b[32m    578\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    579\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mIn order to use an autograd.Function with functorch transforms \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    580\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m(vmap, grad, jvp, jacrev, ...), it must override the setup_context \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    581\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mstaticmethod. For more details, please see \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    582\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mhttps://pytorch.org/docs/main/notes/extending.func.html\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    583\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m585\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcustom_function_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.13/site-packages/torch/_functorch/autograd_function.py:49\u001b[39m, in \u001b[36mCustomFunctionHigherOrderOperator.__call__\u001b[39m\u001b[34m(self, autograd_function, *args, **kwargs)\u001b[39m\n\u001b[32m     36\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, autograd_function, *args, **kwargs):\n\u001b[32m     37\u001b[39m     \u001b[38;5;66;03m# When custom_function_call is done dispatching through functorch,\u001b[39;00m\n\u001b[32m     38\u001b[39m     \u001b[38;5;66;03m# it should just invoke the autograd.Function. This is consistent\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     46\u001b[39m     \u001b[38;5;66;03m# (because autograd.Function happens before the Python dispatch key)\u001b[39;00m\n\u001b[32m     47\u001b[39m     \u001b[38;5;66;03m# and only traces the forward pass.\u001b[39;00m\n\u001b[32m     48\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m torch._C._are_functorch_transforms_active():\n\u001b[32m---> \u001b[39m\u001b[32m49\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mautograd_function\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     50\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m autograd_function.apply(*args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.13/site-packages/torch/_ops.py:471\u001b[39m, in \u001b[36mHigherOrderOperator.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    466\u001b[39m     dispatch_key_set = _compute_keyset(args, kwargs, \u001b[38;5;28mself\u001b[39m.non_fallthrough_keys)\n\u001b[32m    467\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.dispatch(\n\u001b[32m    468\u001b[39m         dispatch_key_set.highestPriorityTypeId(), *args, **kwargs\n\u001b[32m    469\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m471\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.13/site-packages/torch/_ops.py:467\u001b[39m, in \u001b[36mHigherOrderOperator.__call__.<locals>.wrapper\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    462\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m torch.overrides.handle_torch_function(\n\u001b[32m    463\u001b[39m         \u001b[38;5;28mself\u001b[39m, flat_args, *args, **kwargs\n\u001b[32m    464\u001b[39m     )\n\u001b[32m    466\u001b[39m dispatch_key_set = _compute_keyset(args, kwargs, \u001b[38;5;28mself\u001b[39m.non_fallthrough_keys)\n\u001b[32m--> \u001b[39m\u001b[32m467\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdispatch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    468\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdispatch_key_set\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhighestPriorityTypeId\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    469\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.13/site-packages/torch/_ops.py:330\u001b[39m, in \u001b[36mHigherOrderOperator.dispatch\u001b[39m\u001b[34m(self, dispatch_key, *args, **kwargs)\u001b[39m\n\u001b[32m    327\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m kernel(*args, **kwargs)\n\u001b[32m    329\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m dispatch_key == DispatchKey.FuncTorchDynamicLayerFrontMode:\n\u001b[32m--> \u001b[39m\u001b[32m330\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdispatch_functorch\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    332\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m dispatch_key == DispatchKey.Python:\n\u001b[32m    333\u001b[39m     \u001b[38;5;66;03m# Keep the following 1:1 with handle_torch_function_no_python_arg_parser\u001b[39;00m\n\u001b[32m    334\u001b[39m     \u001b[38;5;66;03m# in torch/csrc/utils/python_arg_parser.cpp\u001b[39;00m\n\u001b[32m    336\u001b[39m     overloaded_args_list = []\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.13/site-packages/torch/_functorch/pyfunctorch.py:294\u001b[39m, in \u001b[36mdispatch_functorch\u001b[39m\u001b[34m(op, args, kwargs)\u001b[39m\n\u001b[32m    286\u001b[39m \u001b[38;5;66;03m# In traditional PyTorch operators, DispatchKey::FuncTorchTensorWrapper's\u001b[39;00m\n\u001b[32m    287\u001b[39m \u001b[38;5;66;03m# unwrap_dead_tensors fallback handles unwrapping dead tensor wrappers.\u001b[39;00m\n\u001b[32m    288\u001b[39m \u001b[38;5;66;03m# PyDispatcher sidesteps the PyTorch dispatcher when dealing with functorch\u001b[39;00m\n\u001b[32m    289\u001b[39m \u001b[38;5;66;03m# transforms, so we manually unwrap the dead tensors here.\u001b[39;00m\n\u001b[32m    290\u001b[39m \u001b[38;5;66;03m# This logic won't need to exist when we have mode-only functorch.\u001b[39;00m\n\u001b[32m    291\u001b[39m args, kwargs = pytree.tree_map_only(\n\u001b[32m    292\u001b[39m     torch.Tensor, torch._C._functorch.unwrap_if_dead, (args, kwargs)\n\u001b[32m    293\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m294\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minterpreter\u001b[49m\u001b[43m.\u001b[49m\u001b[43mprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.13/site-packages/torch/_functorch/pyfunctorch.py:130\u001b[39m, in \u001b[36mVmapInterpreter.process\u001b[39m\u001b[34m(self, op, args, kwargs)\u001b[39m\n\u001b[32m    128\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mprocess\u001b[39m(\u001b[38;5;28mself\u001b[39m, op, args, kwargs):\n\u001b[32m    129\u001b[39m     kernel = op.functorch_table[TransformType.Vmap]\n\u001b[32m--> \u001b[39m\u001b[32m130\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mkernel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.13/site-packages/torch/_functorch/autograd_function.py:315\u001b[39m, in \u001b[36mcustom_function_call_vmap\u001b[39m\u001b[34m(interpreter, autograd_function, *operands, **kwargs)\u001b[39m\n\u001b[32m    304\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m has_overriden_vmap_rule(autograd_function):\n\u001b[32m    305\u001b[39m     \u001b[38;5;66;03m# TODO: Update link to stable once that's out\u001b[39;00m\n\u001b[32m    306\u001b[39m     \u001b[38;5;66;03m# https://github.com/pytorch/pytorch/issues/92029\u001b[39;00m\n\u001b[32m    307\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    308\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mYou tried to vmap over \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mautograd_function.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, but \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    309\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mit does not have vmap support. Please override and implement the \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    312\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mhttps://pytorch.org/docs/main/notes/extending.func.html\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    313\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m315\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcustom_function_call_vmap_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    316\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterpreter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mautograd_function\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvmap\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mautograd_function\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43moperands\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    317\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.13/site-packages/torch/_functorch/autograd_function.py:352\u001b[39m, in \u001b[36mcustom_function_call_vmap_helper\u001b[39m\u001b[34m(interpreter, vmap_function, op, *operands, **kwargs)\u001b[39m\n\u001b[32m    349\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m op(*operands, **kwargs)\n\u001b[32m    351\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m lower_to_next():\n\u001b[32m--> \u001b[39m\u001b[32m352\u001b[39m     result = \u001b[43mvmap_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43minfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_dims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43munwrapped_operands\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    353\u001b[39m validate_vmap_returns_tuple_of_two_elements(result)\n\u001b[32m    354\u001b[39m unwrapped_output, out_dims = result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.13/site-packages/pytorch_finufft/functional.py:180\u001b[39m, in \u001b[36mFinufftType1.vmap\u001b[39m\u001b[34m(info, in_dims, points, values, output_shape, finufftkwargs)\u001b[39m\n\u001b[32m    176\u001b[39m points = points.movedim(batch_points, \u001b[32m0\u001b[39m)\n\u001b[32m    177\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m batch_values \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    178\u001b[39m     output = torch.stack(\n\u001b[32m    179\u001b[39m         [\n\u001b[32m--> \u001b[39m\u001b[32m180\u001b[39m             \u001b[43mFinufftType1\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    181\u001b[39m \u001b[43m                \u001b[49m\u001b[43mpoints\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    182\u001b[39m \u001b[43m                \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    183\u001b[39m \u001b[43m                \u001b[49m\u001b[43moutput_shape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    184\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfinufftkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    185\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    186\u001b[39m             \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(info.batch_size)\n\u001b[32m    187\u001b[39m         ],\n\u001b[32m    188\u001b[39m         dim=\u001b[32m0\u001b[39m,\n\u001b[32m    189\u001b[39m     )\n\u001b[32m    190\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    191\u001b[39m     output = torch.stack(\n\u001b[32m    192\u001b[39m         [\n\u001b[32m    193\u001b[39m             FinufftType1.apply(\n\u001b[32m   (...)\u001b[39m\u001b[32m    201\u001b[39m         dim=\u001b[32m0\u001b[39m,\n\u001b[32m    202\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.13/site-packages/torch/autograd/function.py:575\u001b[39m, in \u001b[36mFunction.apply\u001b[39m\u001b[34m(cls, *args, **kwargs)\u001b[39m\n\u001b[32m    572\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch._C._are_functorch_transforms_active():\n\u001b[32m    573\u001b[39m     \u001b[38;5;66;03m# See NOTE: [functorch vjp and autograd interaction]\u001b[39;00m\n\u001b[32m    574\u001b[39m     args = _functorch.utils.unwrap_dead_wrappers(args)\n\u001b[32m--> \u001b[39m\u001b[32m575\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m    577\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_setup_ctx_defined:\n\u001b[32m    578\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    579\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mIn order to use an autograd.Function with functorch transforms \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    580\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m(vmap, grad, jvp, jacrev, ...), it must override the setup_context \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    581\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mstaticmethod. For more details, please see \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    582\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mhttps://pytorch.org/docs/main/notes/extending.func.html\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    583\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.13/site-packages/pytorch_finufft/functional.py:148\u001b[39m, in \u001b[36mFinufftType1.forward\u001b[39m\u001b[34m(points, values, output_shape, finufftkwargs)\u001b[39m\n\u001b[32m    145\u001b[39m nufft_func = get_nufft_func(ndim, \u001b[32m1\u001b[39m, points.device)\n\u001b[32m    147\u001b[39m batch_dims = values.shape[:-\u001b[32m1\u001b[39m]\n\u001b[32m--> \u001b[39m\u001b[32m148\u001b[39m finufft_out = \u001b[43mnufft_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    149\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43mpoints\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    150\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_shape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    152\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfinufftkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    153\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    154\u001b[39m finufft_out = finufft_out.reshape(*batch_dims, *output_shape)\n\u001b[32m    156\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m modeord:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.13/site-packages/pytorch_finufft/functional.py:62\u001b[39m, in \u001b[36mget_nufft_func.<locals>.f\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     59\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(new_args[i], torch.Tensor):\n\u001b[32m     60\u001b[39m         new_args[i] = new_args[i].data.numpy()\n\u001b[32m---> \u001b[39m\u001b[32m62\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m torch.from_numpy(\u001b[43mfinufft_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mnew_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.13/site-packages/finufft/_interfaces.py:842\u001b[39m, in \u001b[36mnufft3d1\u001b[39m\u001b[34m(x, y, z, c, n_modes, out, eps, isign, **kwargs)\u001b[39m\n\u001b[32m    841\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mnufft3d1\u001b[39m(x,y,z,c,n_modes=\u001b[38;5;28;01mNone\u001b[39;00m,out=\u001b[38;5;28;01mNone\u001b[39;00m,eps=\u001b[32m1e-6\u001b[39m,isign=\u001b[32m1\u001b[39m,**kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m842\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minvoke_guru\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43mz\u001b[49m\u001b[43m,\u001b[49m\u001b[43mc\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43misign\u001b[49m\u001b[43m,\u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\u001b[43mn_modes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.13/site-packages/finufft/_interfaces.py:566\u001b[39m, in \u001b[36minvoke_guru\u001b[39m\u001b[34m(dim, tp, x, y, z, c, s, t, u, f, isign, eps, n_modes, **kwargs)\u001b[39m\n\u001b[32m    564\u001b[39m \u001b[38;5;66;03m#excute\u001b[39;00m\n\u001b[32m    565\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m tp==\u001b[32m1\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m tp==\u001b[32m3\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m566\u001b[39m     out = \u001b[43mplan\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mc\u001b[49m\u001b[43m,\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    567\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    568\u001b[39m     out = plan.execute(f,c)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.13/site-packages/finufft/_interfaces.py:294\u001b[39m, in \u001b[36mPlan.execute\u001b[39m\u001b[34m(self, data, out)\u001b[39m\n\u001b[32m    292\u001b[39m \u001b[38;5;66;03m# call execute based on type and precision type\u001b[39;00m\n\u001b[32m    293\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m tp==\u001b[32m1\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m tp==\u001b[32m3\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m294\u001b[39m     ier = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_execute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_inner_plan\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    295\u001b[39m \u001b[43m                        \u001b[49m\u001b[43m_data\u001b[49m\u001b[43m.\u001b[49m\u001b[43mctypes\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdata_as\u001b[49m\u001b[43m(\u001b[49m\u001b[43mc_void_p\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    296\u001b[39m \u001b[43m                        \u001b[49m\u001b[43m_out\u001b[49m\u001b[43m.\u001b[49m\u001b[43mctypes\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdata_as\u001b[49m\u001b[43m(\u001b[49m\u001b[43mc_void_p\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    297\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m tp==\u001b[32m2\u001b[39m:\n\u001b[32m    298\u001b[39m     ier = \u001b[38;5;28mself\u001b[39m._execute(\u001b[38;5;28mself\u001b[39m._inner_plan,\n\u001b[32m    299\u001b[39m                         _out.ctypes.data_as(c_void_p),\n\u001b[32m    300\u001b[39m                         _data.ctypes.data_as(c_void_p))\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "while iteration < num_iterations:\n",
    "    print(f\"iteration {iteration} / {num_iterations}\")\n",
    "    tic = time.time()\n",
    "    \n",
    "    generator = torch.Generator()\n",
    "    \n",
    "    generator.manual_seed(iteration%nP)\n",
    "\n",
    "    kspace_mask_source = torch.randint(0, 2, (1, d.shape[1], 2, 1), generator=generator)\n",
    "    kspace_mask_target = 1 - kspace_mask_source\n",
    "\n",
    "    d_masked = d * kspace_mask_source\n",
    "    AHd = nonuniform_fourier_transform_adjoint(k, d_masked, (156,156,156))\n",
    "    AHd = torch.sum(torch.conj(C[..., None, None]) * AHd, dim=0)\n",
    "    \n",
    "    data = [\n",
    "        {\n",
    "            \"images_regridded\": AHd,\n",
    "            \"kspace_trajectory\": k,\n",
    "            \"sensitivity_maps\": C,\n",
    "            \"kspace_mask_source\": kspace_mask_source,\n",
    "            \"kspace_mask_target\": kspace_mask_target,\n",
    "            \"kspace_data\": d,\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    # TRAINING\n",
    "    if model_training:\n",
    "        trn_loss = training(\n",
    "            [0],\n",
    "            data,\n",
    "            model,\n",
    "            loss_fn,\n",
    "            optimizer,\n",
    "            accumulator,\n",
    "            group=group,\n",
    "            device=device,\n",
    "        )\n",
    "\n",
    "        averaged_model.update_parameters(\n",
    "            model,\n",
    "        )\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "\n",
    "    else:\n",
    "        trn_loss = [0] * batch_size\n",
    "\n",
    "    # VALIDATION\n",
    "    if model_validation:\n",
    "        val_loss = validation(\n",
    "            validation_index,\n",
    "            validation_data,\n",
    "            averaged_model,\n",
    "            loss_fn,\n",
    "            group=group,\n",
    "            device=device,\n",
    "        )\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "\n",
    "    else:\n",
    "        val_loss = [0] * batch_size\n",
    "\n",
    "    total_trn_loss += trn_loss\n",
    "    total_val_loss += val_loss\n",
    "\n",
    "    # SAVING\n",
    "    # Completed epoch\n",
    "    if save_checkpoint and np.mod(iteration + batch_size, nD * nP) == 0:\n",
    "        print(\"Creating tagged checkpoint ...\")\n",
    "\n",
    "        checkpoint = {\n",
    "            \"iteration\": iteration + batch_size,\n",
    "            \"model_state\": model.state_dict(),\n",
    "            \"averaged_model_state\": averaged_model.state_dict(),\n",
    "            \"optim_state\": optimizer.state_dict(),\n",
    "            \"trn_loss\": total_trn_loss,\n",
    "            \"val_loss\": total_val_loss,\n",
    "        }\n",
    "\n",
    "        epoch = (iteration + batch_size) // (nD * nP)\n",
    "        checkpoint_manager.save(checkpoint, tag=f\"_epoch_{epoch}\")\n",
    "\n",
    "        if single_epoch:\n",
    "            # Also save the checkpoint as untagged checkpoint\n",
    "            # Otherwise, training will be stuck in endless loop\n",
    "            checkpoint_manager.save(checkpoint)\n",
    "            checkpoint_manager.release()\n",
    "            break\n",
    "\n",
    "    # Intermediate checkpoint\n",
    "    elif save_checkpoint and np.mod(iteration + batch_size, checkpoint_frequency) == 0:\n",
    "        print(\"Creating untagged checkpoint ...\")\n",
    "\n",
    "        checkpoint = {\n",
    "            \"iteration\": iteration + batch_size,\n",
    "            \"model_state\": model.state_dict(),\n",
    "            \"averaged_model_state\": averaged_model.state_dict(),\n",
    "            \"optim_state\": optimizer.state_dict(),\n",
    "            \"trn_loss\": total_trn_loss,\n",
    "            \"val_loss\": total_val_loss,\n",
    "        }\n",
    "\n",
    "        checkpoint_manager.save(checkpoint, block=False)\n",
    "\n",
    "    toc = time.time() - tic\n",
    "\n",
    "    print(\n",
    "        (\n",
    "            f\"Iteration: {iteration} - \"\n",
    "            + f\"Elapsed time: {toc:.0f} - \"\n",
    "            + f\"Training loss: {[f'{loss:.3f}' for loss in trn_loss]} - \"\n",
    "            + f\"Validation loss: {[f'{loss:.3f}' for loss in val_loss]}\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "    iteration += batch_size\n",
    "    print(f\"current iteration: {iteration}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6168d96e-86c7-4cc4-86ed-601e7ad05753",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
