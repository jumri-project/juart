{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12c7a292-e8f9-4880-83cf-6a683b294b4b",
   "metadata": {},
   "source": [
    "# Inference Notebook for 3D models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b8ee3b-665b-41a6-85ee-ac083a6b3a78",
   "metadata": {},
   "source": [
    "## Importing all necessary classes and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e82023-148e-48a7-90ac-db663495bc30",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib widget\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, \"../../src\")\n",
    "\n",
    "import h5py\n",
    "import torch\n",
    "import zarr as z\n",
    "import numpy as np\n",
    "\n",
    "from juart.conopt.functional.fourier import nonuniform_fourier_transform_adjoint\n",
    "from juart.dl.checkpoint.manager import CheckpointManager\n",
    "from juart.dl.model.unrollnet import ExponentialMovingAverageModel, UnrolledNet\n",
    "from juart.dl.operation.modules import inference\n",
    "from juart.dl.model.resnet import ResNet\n",
    "from juart.conopt.tfs.fourier import nonuniform_transfer_function\n",
    "from juart.conopt.functional.fourier import nonuniform_fourier_transform_adjoint, fourier_transform_forward, fourier_transform_adjoint\n",
    "from juart.vis.interactive import InteractiveFigure3D, InteractiveMultiPlotter3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e32984-bb2c-46bd-89ab-318938bb852f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To improve performance, manually limit the number of threads\n",
    "# torch.set_num_threads(16)\n",
    "# torch.set_num_interop_threads(16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad64915-c5a6-404e-9a56-da165e68c8dc",
   "metadata": {},
   "source": [
    "## Defining all important variables for the inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ee49da-f824-4e3c-8d6c-1332ecb41d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset options\n",
    "kspace_cutoff = False\n",
    "nX_cutoff, nY_cutoff, nZ_cutoff = 64, 64, 64 \n",
    "\n",
    "# device options\n",
    "device = \"cuda:1\" # device on which the reconstructions will run\n",
    "\n",
    "# CheckpointManager options\n",
    "directory = \"corr_modelDD_01i_25P_50DC_epoch_7\" # directory of the dl-qrage model\n",
    "root_dir = \"/home/jovyan/models\" # the path to the model directory\n",
    "backend = \"local\" # the backend of the model directory\n",
    "\n",
    "# model options\n",
    "shape = (156,156,156,2,1) # number of pixels in every direction // number of measurements at T1/T2 decay\n",
    "nX, nY, nZ, nTI, nTE = shape # ordered structure of the parameters above that will be passed to the model\n",
    "features = 32 # number of hidden_inputs of the dl-qrage model\n",
    "cg_iter = 50 # number of cg iterations in the dl-qrage model reconstruction\n",
    "\n",
    "# display options\n",
    "vmax = 2 # sets the brightness normalization of the display between 0 and vmax\n",
    "iTI, iTE = 1, 0 # sets the number of measurement that should be displayed\n",
    "\n",
    "# saving\n",
    "saving = True\n",
    "\n",
    "dtype = torch.complex64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4322ab24-9d4f-49c0-b60d-bd75571f60c5",
   "metadata": {},
   "source": [
    "## Loading the dataset that should be reconstructed\n",
    "#### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931128c2-3025-409f-81d8-20f110fcad74",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/home/jovyan/juart/examples/data/3DLiss_vd_preproc.h5\"\n",
    "with h5py.File(data_path, \"r\") as f:\n",
    "    \n",
    "    k = torch.from_numpy(f['k'][:])[...,None]\n",
    "    C = torch.from_numpy(f['coilsens'][:])\n",
    "    d = torch.from_numpy(f['d'][:])[...,None]\n",
    "\n",
    "    print(f\"Coilsensitivity shape {C.shape}\")\n",
    "    print(f\"Trajectory shape {k.shape}\")\n",
    "    print(f\"Signal shape {d.shape}\")\n",
    "\n",
    "k /= (2*k.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a6150b-dcbf-4bfb-ae96-cbab3482474b",
   "metadata": {},
   "source": [
    "#### Shaping data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd93fbe-605a-492a-babb-ef0494dcf27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if kspace_cutoff == True:\n",
    "    nX, nY ,nZ = nX_cutoff, nY_cutoff, nZ_cutoff\n",
    "    shape = (nX, nY, nZ, nTI, nTE)\n",
    "    \n",
    "    mask = torch.linalg.norm(ktraj,dim=0) <= nX_cutoff//2\n",
    "    \n",
    "    ktraj = torch.stack(\n",
    "        [ktraj[:, mask[:, echo], echo] for echo in range(ktraj.shape[2])],\n",
    "        dim=-1\n",
    "    )\n",
    "    \n",
    "    d = torch.stack(\n",
    "        [d[:, mask[:, echo], echo] for echo in range(d.shape[2])],\n",
    "        dim=-1\n",
    "    )\n",
    "\n",
    "    coilsens_ksp = fourier_transform_forward(coilsens, axes=(1,2,3))\n",
    "    low_lim, up_lim = int(156/2 - nX/2), int(156/2 + nX/2)\n",
    "    coilsens_ksp = coilsens_ksp[:, low_lim:up_lim, low_lim:up_lim, low_lim:up_lim]\n",
    "    coilsens = fourier_transform_adjoint(coilsens_ksp, axes=(1,2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8666b9-e8e4-4094-8283-70483e32bcac",
   "metadata": {},
   "outputs": [],
   "source": [
    "kspace_mask_source = torch.randint(0,2,(1, k.shape[1], 1,1))\n",
    "kspace_mask_target = 1 - kspace_mask_source\n",
    "\n",
    "k_scaled = k / (2 * k.max())\n",
    "\n",
    "AHd = nonuniform_fourier_transform_adjoint(k_scaled,d,(nX,nY,nZ))\n",
    "AHd = torch.sum(torch.conj(C[...,None,None]) * AHd, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fdc4c20-fa26-47a7-8737-272f96336fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"images_regridded\": AHd,\n",
    "    \"kspace_trajectory\": k_scaled,\n",
    "    \"sensitivity_maps\": C,\n",
    "    \"kspace_mask_source\": kspace_mask_source,\n",
    "    \"kspace_mask_target\": kspace_mask_target,\n",
    "    \"kspace_data\": d,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "020a4bfb-55c3-43d8-bf74-3aaece8cb014",
   "metadata": {},
   "source": [
    "## Checkpoint Manager\n",
    "#### Initializing the CheckpointManager and loading the current state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37572d0f-c884-435e-be7e-f674654fe50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_manager = CheckpointManager(\n",
    "    directory=directory,\n",
    "    root_dir=root_dir,\n",
    "    backend=backend,\n",
    ")\n",
    "\n",
    "checkpoint = checkpoint_manager.load(\n",
    "    [\"averaged_model_state\", \"iteration\"], map_location=\"cuda:3\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a1a869a-f5c0-4653-8240-c0604bd8d5fa",
   "metadata": {},
   "source": [
    "## Model\n",
    "#### Initializing the model and using the CheckpointManager to check for save files of the model and load them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d67607-4fd4-4ec3-bea5-f6620bea7264",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UnrolledNet(\n",
    "    shape,\n",
    "    features=features,\n",
    "    CG_Iter=cg_iter,\n",
    "    num_unroll_blocks=10,\n",
    "    activation=\"ReLU\",\n",
    "    kernel_size = (3,3,3),\n",
    "    axes = (1,2,3),\n",
    "    disable_progress_bar=False,\n",
    "    ResNetCheckpoints = True,\n",
    "    ConvLayerCheckpoints = False,\n",
    "    device=device,\n",
    "    dtype = dtype\n",
    ")\n",
    "\n",
    "model = ExponentialMovingAverageModel(model, 0.9)\n",
    "model.load_state_dict(checkpoint[\"averaged_model_state\"])\n",
    "\n",
    "iteration = checkpoint[\"iteration\"]\n",
    "print(f\"Loaded averaged at iteration {iteration}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af70eed7-0aa8-416b-86f3-97db681407f6",
   "metadata": {},
   "source": [
    "## Image reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3541e8e-62a4-4629-9fd2-9a27cdc57a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = inference(data, model, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991468ce-9d07-4c5a-9968-19f3f50c2c3a",
   "metadata": {},
   "source": [
    "### Displaying the reconstructed image in an interactive Figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942463d6-48af-45a8-9c5a-a7f9e8e8b2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "InteractiveFigure3D(\n",
    "    torch.abs(images[...,0,0]).cpu().numpy(),\n",
    "    vmin=0,\n",
    "    vmax=torch.abs(images[...,0,0]).cpu().max(),\n",
    "    cmap=\"gray\",\n",
    ").interactive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c607d74-066c-4d1b-840d-59b6e3e0d797",
   "metadata": {},
   "outputs": [],
   "source": [
    "if saving:\n",
    "    torch.save(images,f'/home/jovyan/images/{directory}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e265d298-9be9-4709-be23-fae576e12d7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
