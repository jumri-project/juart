{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8543efe-dbcc-4077-ae4f-1040b6f8654d",
   "metadata": {},
   "source": [
    "# Training script for 3D reconstruction models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7863bb8b-04e4-4d77-9d10-918e2c3b8148",
   "metadata": {},
   "source": [
    "## Import of needed classes and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f803bad-2391-4716-8bef-76c70261ae46",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib widget\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, \"../../src\")\n",
    "\n",
    "import gc\n",
    "import time\n",
    "\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.distributed as dist\n",
    "\n",
    "from juart.conopt.functional.fourier import (\n",
    "    fourier_transform_adjoint,\n",
    "    fourier_transform_forward,\n",
    "    nonuniform_fourier_transform_adjoint,\n",
    ")\n",
    "from juart.conopt.tfs.fourier import nonuniform_transfer_function\n",
    "from juart.dl.checkpoint.manager import CheckpointManager\n",
    "from juart.dl.data.training import DatasetTraining\n",
    "from juart.dl.loss.loss import JointLoss\n",
    "from juart.dl.model.unrollnet import (\n",
    "    ExponentialMovingAverageModel,\n",
    "    LookaheadModel,\n",
    "    UnrolledNet,\n",
    ")\n",
    "from juart.dl.operation.modules import training, validation\n",
    "from juart.dl.utils.dist import GradientAccumulator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e490d5-b2ee-43db-9f46-b34a89e987a5",
   "metadata": {},
   "source": [
    "## Definition of the most important variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "090603f7-cab4-40eb-b91b-1c2dd46c1739",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset options\n",
    "nX, nY, nZ = 156, 156, 156  # Number of pixels in x-/y-/z-direction\n",
    "kspace_cutoff = False  # defines if nX,... should be reduced\n",
    "nX_cutoff, nY_cutoff, nZ_cutoff = 64, 64, 64  # defines nX,... for the cutoff state\n",
    "nTI, nTE = 2, 1  # Number of measurements during the T1/T2 decay\n",
    "shape = (nX, nY, nZ, nTI, nTE)  # Defining the shape later used for the model\n",
    "nD = 1  # Number of subjects\n",
    "nS = 50  # Number of slices per subject\n",
    "\n",
    "# device options\n",
    "device = \"cuda:3\"  # defines whether the model should be trained on the cpu or gpu\n",
    "group = None\n",
    "group_rank = 0\n",
    "group_index = 0\n",
    "num_groups = 1\n",
    "\n",
    "# CheckpointManager Options\n",
    "load_model_state = True  # Load the last saved model state\n",
    "load_averaged_model_state = True  # Load the last saved averaged model state\n",
    "load_optim_state = True  # Load the las saved optimizer state\n",
    "load_metrics = True  # Load the last saved metrics (iterations and loss)\n",
    "directory = (\n",
    "    \"model_test_checkpoint2\"  # Name that is used for the save directory of the model\n",
    ")\n",
    "root_dir = \"/home/jovyan/models\"  # path of the model directory\n",
    "backend = \"local\"  # backend of the model directory\n",
    "\n",
    "# Training loop options\n",
    "num_epochs = 10  # Number of epochs of the training\n",
    "model_training = True  # Activate Training mode\n",
    "model_validation = False  # Activate validation mode\n",
    "save_checkpoint = (\n",
    "    True  # Create save files that contain the current state of the training\n",
    ")\n",
    "checkpoint_frequency = 5  # Sets the number of iterations between creating save files\n",
    "single_epoch = False  # Create a seperate save file after every single epoch\n",
    "batch_size = 1  # Number of slices that should be used for training per batch\n",
    "\n",
    "# model options\n",
    "cgiter = 10\n",
    "num_unroll_blocks = 10\n",
    "activation = \"ReLU\"\n",
    "features = 32\n",
    "disable_progress_bar = False\n",
    "kernel_size = (3, 3, 3)\n",
    "axes = (1, 2, 3)\n",
    "profiler = False\n",
    "ConvLayerCheckpoints = True\n",
    "ResNetCheckpoints = True\n",
    "\n",
    "batch_size_local = batch_size // num_groups\n",
    "num_iterations = nD * nS * num_epochs  # complete number of iterations\n",
    "iteration = 0  # current iteration number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ccc7b515-c6c4-4e80-843b-087e2192a551",
   "metadata": {},
   "outputs": [],
   "source": [
    "if kspace_cutoff:\n",
    "    nX, nY, nZ = nX_cutoff, nY_cutoff, nZ_cutoff\n",
    "    shape = (nX, nY, nZ, nTI, nTE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1acb39ca-f71a-42fa-a816-97248b3ed566",
   "metadata": {},
   "source": [
    "## Initializing worker groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8a92c6a-3c4a-4c54-9fb3-4a0ca7e9ea72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W912 12:08:33.927096188 socket.cpp:200] [c10d] The hostname of the client socket cannot be retrieved. err=-3\n"
     ]
    }
   ],
   "source": [
    "dist.init_process_group(\n",
    "    backend=\"gloo\", init_method=\"tcp://127.0.0.2:12345\", world_size=1, rank=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2ef423-a3b1-45ca-8454-d23d36ac923a",
   "metadata": {},
   "source": [
    "## Initializing the neural network\n",
    "### Initializing the model\n",
    "The model is the core of the neural network. Its forward pass describes the main steps of the neural network and the models features property describes the number of hidden features of the neural network and therefore its complexity. Furthermore the activation function and the number of iterations in dataconsistency term and regularization term is defined here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89917955-b31b-4f77-8787-91f4322b1c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UnrolledNet(\n",
    "    shape,\n",
    "    features=features,\n",
    "    CG_Iter=cgiter,\n",
    "    num_unroll_blocks=num_unroll_blocks,\n",
    "    activation=activation,\n",
    "    disable_progress_bar=disable_progress_bar,\n",
    "    timing_level=0,\n",
    "    validation_level=0,\n",
    "    kernel_size=kernel_size,\n",
    "    axes=axes,\n",
    "    profiler = profiler,\n",
    "    ResNetCheckpoints = ResNetCheckpoints,\n",
    "    ConvLayerCheckpoints = ConvLayerCheckpoints,\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51918402-199d-4397-a631-b944aeb1f6f1",
   "metadata": {},
   "source": [
    "### Initializing the loss function\n",
    "The loss function defines how the difference between model prediction and correct result is calculated and it divides the loss into separate kinds of losses:\n",
    "- kspace\n",
    "- ispace\n",
    "- wavelet\n",
    "- hankel\n",
    "- casorati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b7c7e72-6ade-4bdb-b829-3fbd0f813f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = JointLoss(\n",
    "    shape,\n",
    "    3,\n",
    "    weights_kspace_loss=(0.5, 0.5),\n",
    "    weights_ispace_loss=(0.0, 0.0),\n",
    "    weights_wavelet_loss=(0.0, 0.0),\n",
    "    weights_hankel_loss=(0.0, 0.0),\n",
    "    weights_casorati_loss=(0.0, 0.0),\n",
    "    normalized_loss=True,\n",
    "    timing_level=0,\n",
    "    validation_level=0,\n",
    "    group=group,\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65220517-26bf-44c5-8098-caa2e6afe2c1",
   "metadata": {},
   "source": [
    "### Initializing the optimizer\n",
    "The optimizer determines which impact the calculated loss has on the models parameters. The impact can be variated via the learning rate lr."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "815fcdd7-49cb-45b2-b6ce-337532c98117",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=0.0001,\n",
    "    betas=[0.9, 0.999],\n",
    "    eps=1.0e-8,\n",
    "    weight_decay=0.0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0af70828-ab59-4afa-b00c-9abd5b7a5b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "accumulator = GradientAccumulator(\n",
    "    model,\n",
    "    accumulation_steps=batch_size_local,\n",
    "    max_norm=1.0,\n",
    "    normalized_gradient=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb6f03a-b145-444f-9ac9-69c7ea42343f",
   "metadata": {},
   "source": [
    "### Initializing the averaged model\n",
    "The averaged model does not use the models parameters directly it uses the floating average of the model over the last n iterations. Its more robust than using the current average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e0ad0e2-b2fb-4f49-a728-1ebc352ca7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "averaged_model = LookaheadModel(\n",
    "    model,\n",
    "    alpha=0.5,\n",
    "    k=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b38ece-47dc-4620-854a-4b63e5c7d699",
   "metadata": {},
   "source": [
    "## Checkpoint Manager\n",
    "### Initializing the CheckpointManager\n",
    "The CheckpointManager is useful for saving and/or loading models. In this case here it either creates a new directory for the model or it loads data from an already existing directory to continue the training at the point where it lastly stopped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a7ee50c-4c82-4f70-b4ac-1679327b75fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_manager = CheckpointManager(\n",
    "    directory=directory,\n",
    "    root_dir=root_dir,\n",
    "    backend=backend,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c9ea11-0729-4999-84fa-d7d55e6dc14d",
   "metadata": {},
   "source": [
    "#### Check if the model is already existing and load its last saved state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "20075413-eaf6-4b59-8d81-45989230fb49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model state ...\n",
      "Could not load model state.\n"
     ]
    }
   ],
   "source": [
    "if load_model_state:\n",
    "    print(f\"Loading model state ...\")\n",
    "    checkpoint = checkpoint_manager.load([\"model_state\"], map_location=device)\n",
    "    if all(checkpoint.values()):\n",
    "        model.load_state_dict(checkpoint[\"model_state\"])\n",
    "    else:\n",
    "        print(f\"Could not load model state.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c54eb6d6-b697-4635-b2ed-e26468cc349d",
   "metadata": {},
   "source": [
    "#### Check if the averaged model is already existing and load its last saved state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e3bfce16-23aa-4bd8-9996-f9e9a0961bd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading averaged model state ...\n",
      "Could not load averaged model state.\n"
     ]
    }
   ],
   "source": [
    "if load_averaged_model_state:\n",
    "    print(f\"Loading averaged model state ...\")\n",
    "    checkpoint = checkpoint_manager.load([\"averaged_model_state\"], map_location=device)\n",
    "    if all(checkpoint.values()):\n",
    "        averaged_model.load_state_dict(checkpoint[\"averaged_model_state\"])\n",
    "    else:\n",
    "        print(f\"Could not load averaged model state.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee214f54-60a2-4979-b4b6-b5aa8f708965",
   "metadata": {},
   "source": [
    "#### Check if the optimizer is already existing and load its last saved state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "845b5fcb-d981-46a5-a630-c163cccc3ba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading optim state ...\n",
      "Could not load optim state.\n"
     ]
    }
   ],
   "source": [
    "if load_optim_state:\n",
    "    print(f\"Loading optim state ...\")\n",
    "    checkpoint = checkpoint_manager.load([\"optim_state\"], map_location=device)\n",
    "    if all(checkpoint.values()):\n",
    "        optimizer.load_state_dict(checkpoint[\"optim_state\"])\n",
    "    else:\n",
    "        print(f\"Could not load optim state.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "00f06beb-1fae-4f46-b18f-c315adcaa3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_trn_loss = list()\n",
    "total_val_loss = list()\n",
    "iteration = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19fbc05-8e30-4ba8-a508-a7e5304b204b",
   "metadata": {},
   "source": [
    "#### Load the last saved state of the loss and the current iteration if existing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3fb75752-08b0-4828-9927-56ccd2ff3c41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading metrics ...\n",
      "Could not load metrics.\n"
     ]
    }
   ],
   "source": [
    "if load_metrics:\n",
    "    print(f\"Loading metrics ...\")\n",
    "    checkpoint = checkpoint_manager.load([\"trn_loss\", \"val_loss\", \"iteration\"])\n",
    "    if all(checkpoint.values()):\n",
    "        total_trn_loss = list(checkpoint[\"trn_loss\"])\n",
    "        total_val_loss = list(checkpoint[\"val_loss\"])\n",
    "        iteration = checkpoint[\"iteration\"]\n",
    "    else:\n",
    "        print(f\"Could not load metrics.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f2e53759-ad14-4265-b6c6-e1f987af6756",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continue with iteration 0 ...\n"
     ]
    }
   ],
   "source": [
    "print(f\"Continue with iteration {iteration} ...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10fdc4b1-6130-4c9f-89c2-91821530f280",
   "metadata": {},
   "source": [
    "## Import the data that should be used for the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "33bbb549-78f4-4429-a236-5036a38efafd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset holds following data: <KeysViewHDF5 ['coilsens', 'd', 'k']>\n",
      "Coilsensitivity info: Shape (Channels, Nx, Ny, Nz).\n",
      "Trajectory info: Shape (Dimensions, Samples, Echotimes). Scaled in units of cycle/fov\n",
      "Signal info: Shape (Channels, Samples, Echotimes).\n",
      "Coilsensitivity shape torch.Size([8, 156, 156, 156])\n",
      "Trajectory shape torch.Size([3, 2001191, 2])\n",
      "Signal shape torch.Size([8, 2001191, 2])\n"
     ]
    }
   ],
   "source": [
    "data_path = \"3DLiss_vd_preproc.h5\"\n",
    "with h5py.File(data_path, \"r\") as f:\n",
    "    print(f\"Dataset holds following data: {f.keys()}\")\n",
    "\n",
    "    print(f\"Coilsensitivity info: {f['coilsens'].attrs['info']}\")\n",
    "    print(f\"Trajectory info: {f['k'].attrs['info']}\")\n",
    "    print(f\"Signal info: {f['d'].attrs['info']}\")\n",
    "\n",
    "    shape = (156, 156, 156, 2)\n",
    "    ktraj = torch.from_numpy(f[\"k\"][:])\n",
    "    coilsens = torch.from_numpy(f[\"coilsens\"][:])\n",
    "    d = torch.from_numpy(f[\"d\"][:])\n",
    "\n",
    "    print(f\"Coilsensitivity shape {coilsens.shape}\")\n",
    "    print(f\"Trajectory shape {ktraj.shape}\")\n",
    "    print(f\"Signal shape {d.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8b3f14f1-7d55-4bc0-8025-a5c3dd49977f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if kspace_cutoff == True:\n",
    "\n",
    "    mask = torch.linalg.norm(ktraj, dim=0) <= nX_cutoff // 2\n",
    "\n",
    "    ktraj = torch.stack(\n",
    "        [ktraj[:, mask[:, echo], echo] for echo in range(ktraj.shape[2])], dim=-1\n",
    "    )\n",
    "\n",
    "    d = torch.stack([d[:, mask[:, echo], echo] for echo in range(d.shape[2])], dim=-1)\n",
    "\n",
    "    coilsens_ksp = fourier_transform_forward(coilsens, axes=(1, 2, 3))\n",
    "    low_lim, up_lim = int(156 / 2 - nX / 2), int(156 / 2 + nX / 2)\n",
    "    coilsens_ksp = coilsens_ksp[:, low_lim:up_lim, low_lim:up_lim, low_lim:up_lim]\n",
    "    coilsens = fourier_transform_adjoint(coilsens_ksp, axes=(1, 2, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba035c9a-52f4-4fc0-93d8-1f923ca3a931",
   "metadata": {},
   "source": [
    "### shaping the data\n",
    "#### In the next steps the data is just formed into the right shape so that the training function will understand how the data is structured."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "805653c7-3aa4-4c14-a974-3fa02fe20839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([156, 156, 156, 2])\n"
     ]
    }
   ],
   "source": [
    "k_scaled = ktraj / (2 * ktraj.max())\n",
    "\n",
    "AHd = nonuniform_fourier_transform_adjoint(k_scaled, d, (nX, nY, nZ))\n",
    "AHd = torch.sum(torch.conj(coilsens[..., None]) * AHd, dim=0)\n",
    "\n",
    "AHd_unsqueeze = AHd.unsqueeze(-1)\n",
    "k = k_scaled.unsqueeze(-1)\n",
    "d_unsqueeze = d.unsqueeze(-1)\n",
    "\n",
    "generator = torch.Generator()\n",
    "\n",
    "print(AHd.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df940120-3ab7-41a2-a708-2e24f5150632",
   "metadata": {},
   "source": [
    "## Actual training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8bdddfd-4362-4f4a-8d4d-74a7a74846be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0 / 500\n",
      "reading data\n",
      "reading data done -> model initialization\n"
     ]
    }
   ],
   "source": [
    "while iteration < num_iterations:\n",
    "    print(f\"iteration {iteration} / {num_iterations}\")\n",
    "    tic = time.time()\n",
    "\n",
    "    generator.manual_seed(iteration%nS)\n",
    "\n",
    "    kspace_mask_source = torch.randint(0, 2, (1, k.shape[1], 2, 1), generator=generator)\n",
    "    kspace_mask_target = 1 - kspace_mask_source\n",
    "\n",
    "    data = [\n",
    "        {\n",
    "            \"images_regridded\": AHd_unsqueeze,\n",
    "            \"kspace_trajectory\": k,\n",
    "            \"sensitivity_maps\": coilsens,\n",
    "            \"kspace_mask_source\": kspace_mask_source,\n",
    "            \"kspace_mask_target\": kspace_mask_target,\n",
    "            \"kspace_data\": d_unsqueeze,\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    # TRAINING\n",
    "    if model_training:\n",
    "\n",
    "        trn_loss = training(\n",
    "            [0],\n",
    "            data,\n",
    "            model,\n",
    "            loss_fn,\n",
    "            optimizer,\n",
    "            accumulator,\n",
    "            group=group,\n",
    "            device=device,\n",
    "        )\n",
    "\n",
    "        averaged_model.update_parameters(\n",
    "            model,\n",
    "        )\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "\n",
    "    else:\n",
    "        trn_loss = [0] * batch_size\n",
    "\n",
    "    # VALIDATION\n",
    "    if model_validation:\n",
    "\n",
    "        val_loss = validation(\n",
    "            validation_index,\n",
    "            validation_data,\n",
    "            averaged_model,\n",
    "            loss_fn,\n",
    "            group=group,\n",
    "            device=device,\n",
    "        )\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "\n",
    "    else:\n",
    "        val_loss = [0] * batch_size\n",
    "\n",
    "    total_trn_loss += trn_loss\n",
    "    total_val_loss += val_loss\n",
    "\n",
    "    # SAVING\n",
    "    # Completed epoch\n",
    "    if save_checkpoint and np.mod(iteration + batch_size, nD * nS) == 0:\n",
    "        print(\"Creating tagged checkpoint ...\")\n",
    "\n",
    "        checkpoint = {\n",
    "            \"iteration\": iteration + batch_size,\n",
    "            \"model_state\": model.state_dict(),\n",
    "            \"averaged_model_state\": averaged_model.state_dict(),\n",
    "            \"optim_state\": optimizer.state_dict(),\n",
    "            \"trn_loss\": total_trn_loss,\n",
    "            \"val_loss\": total_val_loss,\n",
    "        }\n",
    "\n",
    "        epoch = (iteration + batch_size) // (nD * nS)\n",
    "        checkpoint_manager.save(checkpoint, tag=f\"_epoch_{epoch}\")\n",
    "\n",
    "        if single_epoch:\n",
    "            # Also save the checkpoint as untagged checkpoint\n",
    "            # Otherwise, training will be stuck in endless loop\n",
    "            checkpoint_manager.save(checkpoint)\n",
    "            checkpoint_manager.release()\n",
    "            break\n",
    "\n",
    "    # Intermediate checkpoint\n",
    "    elif save_checkpoint and np.mod(iteration + batch_size, checkpoint_frequency) == 0:\n",
    "        print(\"Creating untagged checkpoint ...\")\n",
    "\n",
    "        checkpoint = {\n",
    "            \"iteration\": iteration + batch_size,\n",
    "            \"model_state\": model.state_dict(),\n",
    "            \"averaged_model_state\": averaged_model.state_dict(),\n",
    "            \"optim_state\": optimizer.state_dict(),\n",
    "            \"trn_loss\": total_trn_loss,\n",
    "            \"val_loss\": total_val_loss,\n",
    "        }\n",
    "\n",
    "        checkpoint_manager.save(checkpoint, block=False)\n",
    "\n",
    "    toc = time.time() - tic\n",
    "\n",
    "    print(\n",
    "        (\n",
    "            f\"Iteration: {iteration} - \"\n",
    "            + f\"Elapsed time: {toc:.0f} - \"\n",
    "            + f\"Training loss: {[f'{loss:.3f}' for loss in trn_loss]} - \"\n",
    "            + f\"Validation loss: {[f'{loss:.3f}' for loss in val_loss]}\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "    iteration += batch_size\n",
    "    print(f\"current iteration: {iteration}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5f1218-e0be-48f9-b27b-f0a42d69f118",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
