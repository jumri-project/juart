{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62c61772-828b-44ab-a299-33ec910180c2",
   "metadata": {},
   "source": [
    "# Dual Domain Training for 3D Datasets\n",
    "This Notebook is an upgraded version of the already existing Training_3D.ipynb. The reconstructed images of the models trained by the normal training seem to be very noisy. The dual domain training can hopefully remove the noise better. The structure of the Network stays the same but ray and the torch distributor function are used to run the training twice on two different gpus. Furthermore the ispace loss is used to weight the difference between the kspace data of the 2 models and to average their gradients before doing the optimizer step. In this way both trainings are running seperately but the optimizer step they do are the exact same because the greadients used during the optimizers step are the average of the both calculated gradients. Setting the weight_ispace_loss on 0 results in the normal Training again (except of the fact that there are 2 models getting trained but only one is saved at the end)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a03f1b-c822-497c-9317-bbef848cb246",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 10/10 [00:22<00:00,  2.24s/it]\n",
      "\u001b[36m(RayTrainWorker pid=1677971)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \n",
      "\u001b[36m(RayTrainWorker pid=1677971)\u001b[0m   warnings.warn(  # warn only once\n",
      " 90%|██████████████████████████████████████▋    | 9/10 [00:20<00:02,  2.18s/it]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "100%|██████████████████████████████████████████| 10/10 [00:22<00:00,  2.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=1677971)\u001b[0m Rank 1 - model initialization done -> loss fn initialization\n"
     ]
    }
   ],
   "source": [
    "# Import of all necessary functions and classes\n",
    "import gc\n",
    "import os\n",
    "import time\n",
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "import ray\n",
    "import torch\n",
    "import torch.distributed as dist\n",
    "from ray.air.config import RunConfig\n",
    "from ray.train import ScalingConfig\n",
    "from ray.train.torch import TorchTrainer\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2,3\"\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, \"../../src\")\n",
    "# activates the terminal output for print commands in ray\n",
    "import logging\n",
    "\n",
    "from juart.conopt.functional.fourier import (\n",
    "    nonuniform_fourier_transform_adjoint,\n",
    ")\n",
    "from juart.dl.checkpoint.manager import CheckpointManager\n",
    "from juart.dl.loss.loss import JointLoss\n",
    "from juart.dl.model.unrollnet import LookaheadModel, UnrolledNet\n",
    "from juart.dl.operation.modules import training\n",
    "from juart.dl.utils.dist import GradientAccumulator\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "\n",
    "# Training function that is later passed to the TorchTrainer\n",
    "def train_func():\n",
    "    # define variables\n",
    "    shape = (156, 156, 156, 2, 1)\n",
    "    nX, nY, nZ, nTI, nTE = shape\n",
    "    weight_kspace_loss = [0.5, 0.5]  # weight the difference in k space\n",
    "    weight_ispace_loss = [\n",
    "        0.1,\n",
    "        0.1,\n",
    "    ]  # weight the difference of the two images (dual domain) and average their gradients\n",
    "    weight_hankel_loss = [0.0, 0.0]\n",
    "    weight_casorati_loss = [0.0, 0.0]\n",
    "    weight_wavelet_loss = [0.0, 0.0]  # weight the loss in wavelet domain\n",
    "    normalized_loss = True\n",
    "\n",
    "    batch_size = 1  # number of datapoints used per batch iteration\n",
    "    nD = 1  # number of datasets\n",
    "    nP = 10  # number of permutations per epoch\n",
    "    cgiter = 10  # number of dc iterations\n",
    "    num_epochs = 10  # number of epochs\n",
    "\n",
    "    global_rank = int(dist.get_rank())\n",
    "    world_size = int(dist.get_world_size())\n",
    "    group_size = 2\n",
    "    model_dir = f\"DD_01i_{cgiter}DC_{nP}P\"\n",
    "    root_dir = \"/home/jovyan/models\"\n",
    "    endpoint_url = \"https://s3.fz-juelich.de\"\n",
    "    model_backend = \"local\"\n",
    "\n",
    "    single_epoch = False  # if its true the script will stop after 1 epoch\n",
    "    save_checkpoint = True  # enables checkpoint saving\n",
    "    checkpoint_frequency = 5  # number of iterations between the save files\n",
    "    load_model_state = (\n",
    "        True  # if true the latest model state will be loaded if available\n",
    "    )\n",
    "    load_averaged_model_state = True  # latest averaged model state will be loaded\n",
    "    load_optim_state = True  # latest optimizer state will be loaded\n",
    "    load_metrics = True  # the latest metrics (lost, iterations) will be loaded\n",
    "\n",
    "    num_groups = 1\n",
    "    batch_size_local = batch_size // num_groups\n",
    "    num_iterations = nD * nP * num_epochs\n",
    "\n",
    "    ################################################################\n",
    "    # Setting the rank for each worker\n",
    "    for rank in range(0, world_size, group_size):\n",
    "        ranks = list(range(rank, rank + group_size, 1))\n",
    "        device = f\"cuda:{global_rank}\"\n",
    "        if global_rank in ranks:\n",
    "            print(f\"Rank {global_rank} is in group {ranks} ...\")\n",
    "            group = dist.new_group(ranks, backend=\"gloo\")\n",
    "\n",
    "    ################################################################\n",
    "    # reading and shaping data\n",
    "    data_path = \"/home/jovyan/juart/examples/data/3DLiss_vd_preproc.h5\"\n",
    "    with h5py.File(data_path, \"r\") as f:\n",
    "        k = torch.from_numpy(f[\"k\"][:])[..., None]\n",
    "        C = torch.from_numpy(f[\"coilsens\"][:])\n",
    "        d = torch.from_numpy(f[\"d\"][:])[..., None]\n",
    "\n",
    "        print(f\"Coilsensitivity shape {C.shape}\")\n",
    "        print(f\"Trajectory shape {k.shape}\")\n",
    "        print(f\"Signal shape {d.shape}\")\n",
    "\n",
    "    k /= 2 * k.max()\n",
    "\n",
    "    ################################################################\n",
    "    # Defining the neural network\n",
    "\n",
    "    model = UnrolledNet(\n",
    "        shape,\n",
    "        CG_Iter=cgiter,\n",
    "        num_unroll_blocks=10,\n",
    "        num_of_resblocks=15,\n",
    "        features=[16, 32, 64],\n",
    "        kernel_size=(3, 3, 3),\n",
    "        pad_to=160,\n",
    "        activation=\"ReLU\",\n",
    "        regularizer=\"UNet\",\n",
    "        Checkpoints=True,\n",
    "    ).to(device)\n",
    "\n",
    "    loss_fn = JointLoss(\n",
    "        (3, 3),\n",
    "        weights_kspace_loss=weight_kspace_loss,\n",
    "        weights_ispace_loss=weight_ispace_loss,\n",
    "        weights_hankel_loss=weight_hankel_loss,\n",
    "        weights_casorati_loss=weight_casorati_loss,\n",
    "        weights_wavelet_loss=weight_wavelet_loss,\n",
    "        normalized_loss=normalized_loss,\n",
    "        group=group,\n",
    "        device=device,\n",
    "    )\n",
    "\n",
    "    optimizer = torch.optim.Adam(\n",
    "        model.parameters(),\n",
    "        lr=0.0001,\n",
    "        betas=[0.9, 0.999],\n",
    "        eps=1.0e-8,\n",
    "        weight_decay=0.0,\n",
    "    )\n",
    "\n",
    "    accumulator = GradientAccumulator(\n",
    "        model,\n",
    "        accumulation_steps=batch_size_local,\n",
    "        max_norm=1.0,\n",
    "        normalized_gradient=False,\n",
    "    )\n",
    "\n",
    "    averaged_model = LookaheadModel(\n",
    "        model,\n",
    "        alpha=0.5,\n",
    "        k=5,\n",
    "    )\n",
    "\n",
    "    dist.barrier()\n",
    "\n",
    "    checkpoint_manager = CheckpointManager(\n",
    "        model_dir,\n",
    "        root_dir=root_dir,\n",
    "        endpoint_url=endpoint_url,\n",
    "        backend=model_backend,\n",
    "    )\n",
    "\n",
    "    dist.barrier()\n",
    "\n",
    "    ################################################################\n",
    "    # LOADING CURRENT MODEL STATE\n",
    "    if load_model_state:\n",
    "        print(f\"Rank {global_rank} - Loading model state ...\")\n",
    "        checkpoint = checkpoint_manager.load([\"model_state\"], map_location=device)\n",
    "        if all(checkpoint.values()):\n",
    "            model.load_state_dict(checkpoint[\"model_state\"])\n",
    "        else:\n",
    "            print(f\"Rank {global_rank} - Could not load model state.\")\n",
    "\n",
    "    if load_averaged_model_state:\n",
    "        print(f\"Rank {global_rank} - Loading averaged model state ...\")\n",
    "        checkpoint = checkpoint_manager.load(\n",
    "            [\"averaged_model_state\"], map_location=device\n",
    "        )\n",
    "        if all(checkpoint.values()):\n",
    "            averaged_model.load_state_dict(checkpoint[\"averaged_model_state\"])\n",
    "        else:\n",
    "            print(f\"Rank {global_rank} - Could not load averaged model state.\")\n",
    "\n",
    "    if load_optim_state:\n",
    "        print(f\"Rank {global_rank} - Loading optim state ...\")\n",
    "        checkpoint = checkpoint_manager.load([\"optim_state\"], map_location=device)\n",
    "        if all(checkpoint.values()):\n",
    "            optimizer.load_state_dict(checkpoint[\"optim_state\"])\n",
    "        else:\n",
    "            print(f\"Rank {global_rank} - Could not load optim state.\")\n",
    "\n",
    "        total_trn_loss = list()\n",
    "        total_val_loss = list()\n",
    "        iteration = 0\n",
    "\n",
    "    if load_metrics:\n",
    "        print(f\"Rank {global_rank} - Loading metrics ...\")\n",
    "        checkpoint = checkpoint_manager.load([\"trn_loss\", \"val_loss\", \"iteration\"])\n",
    "        if all(checkpoint.values()):\n",
    "            total_trn_loss = list(checkpoint[\"trn_loss\"])\n",
    "            total_val_loss = list(checkpoint[\"val_loss\"])\n",
    "            iteration = checkpoint[\"iteration\"]\n",
    "        else:\n",
    "            print(f\"Rank {global_rank} - Could not load metrics.\")\n",
    "\n",
    "    print(f\"Rank {global_rank} - Continue with iteration {iteration} ...\")\n",
    "\n",
    "    dist.barrier()\n",
    "\n",
    "    ################################################################\n",
    "    # ACTUAL TRAINING LOOP\n",
    "    total_trn_loss = list()\n",
    "    total_val_loss = list()\n",
    "    iteration = 0\n",
    "\n",
    "    generator = torch.Generator()\n",
    "\n",
    "    while iteration < num_iterations:\n",
    "        tic = time.time()\n",
    "        generator.manual_seed(iteration % nP)\n",
    "\n",
    "        kspace_mask_worker0 = torch.randint(\n",
    "            0, 2, (1, d.shape[1], 2, 1), generator=generator\n",
    "        )\n",
    "        kspace_mask_worker1 = 1 - kspace_mask_worker0\n",
    "\n",
    "        # Defining data for worker 0\n",
    "        if global_rank == 0:\n",
    "            d_masked = d * kspace_mask_worker0\n",
    "            AHd = nonuniform_fourier_transform_adjoint(k, d_masked, (nX, nY, nZ))\n",
    "            AHd = torch.sum(torch.conj(C[..., None, None]) * AHd, dim=0)\n",
    "\n",
    "            data = [\n",
    "                {\n",
    "                    \"images_regridded\": AHd,\n",
    "                    \"kspace_trajectory\": k,\n",
    "                    \"sensitivity_maps\": C,\n",
    "                    \"kspace_mask_source\": kspace_mask_worker1,\n",
    "                    \"kspace_mask_target\": kspace_mask_worker0,\n",
    "                    \"kspace_data\": d,\n",
    "                }\n",
    "            ]\n",
    "\n",
    "        # Defining data for worker 1\n",
    "        elif global_rank == 1:\n",
    "            d_masked = d * kspace_mask_worker1\n",
    "            AHd = nonuniform_fourier_transform_adjoint(k, d_masked, (nX, nY, nZ))\n",
    "            AHd = torch.sum(torch.conj(C[..., None, None]) * AHd, dim=0)\n",
    "\n",
    "            data = [\n",
    "                {\n",
    "                    \"images_regridded\": AHd,\n",
    "                    \"kspace_trajectory\": k,\n",
    "                    \"sensitivity_maps\": C,\n",
    "                    \"kspace_mask_source\": kspace_mask_worker0,\n",
    "                    \"kspace_mask_target\": kspace_mask_worker1,\n",
    "                    \"kspace_data\": d,\n",
    "                }\n",
    "            ]\n",
    "\n",
    "        trn_loss = training(\n",
    "            [0],\n",
    "            data,\n",
    "            model,\n",
    "            loss_fn,\n",
    "            optimizer,\n",
    "            accumulator,\n",
    "            group=group,\n",
    "            device=device,\n",
    "        )\n",
    "\n",
    "        val_loss = [0] * batch_size\n",
    "        total_trn_loss.append(trn_loss)\n",
    "\n",
    "        ################################################################\n",
    "        # SAVING DATA\n",
    "        if global_rank == 0:\n",
    "            # Completed epoch\n",
    "            if save_checkpoint and np.mod(iteration + batch_size, nD * nP) == 0:\n",
    "                print(\"Creating tagged checkpoint ...\")\n",
    "\n",
    "                checkpoint = {\n",
    "                    \"iteration\": iteration + batch_size,\n",
    "                    \"model_state\": model.state_dict(),\n",
    "                    \"averaged_model_state\": averaged_model.state_dict(),\n",
    "                    \"optim_state\": optimizer.state_dict(),\n",
    "                    \"trn_loss\": total_trn_loss,\n",
    "                    \"val_loss\": total_val_loss,\n",
    "                }\n",
    "\n",
    "                epoch = (iteration + batch_size) // (nD * nP)\n",
    "                checkpoint_manager.save(checkpoint, tag=f\"_epoch_{epoch}\")\n",
    "\n",
    "                if single_epoch:\n",
    "                    # Also save the checkpoint as untagged checkpoint\n",
    "                    # Otherwise, training will be stuck in endless loop\n",
    "                    checkpoint_manager.save(checkpoint)\n",
    "                    checkpoint_manager.release()\n",
    "                    break\n",
    "\n",
    "            # Intermediate checkpoint\n",
    "            elif (\n",
    "                save_checkpoint\n",
    "                and np.mod(iteration + batch_size, checkpoint_frequency) == 0\n",
    "            ):\n",
    "                print(\"Creating untagged checkpoint ...\")\n",
    "\n",
    "                checkpoint = {\n",
    "                    \"iteration\": iteration + batch_size,\n",
    "                    \"model_state\": model.state_dict(),\n",
    "                    \"averaged_model_state\": averaged_model.state_dict(),\n",
    "                    \"optim_state\": optimizer.state_dict(),\n",
    "                    \"trn_loss\": total_trn_loss,\n",
    "                    \"val_loss\": total_val_loss,\n",
    "                }\n",
    "\n",
    "                checkpoint_manager.save(checkpoint, block=False)\n",
    "\n",
    "            toc = time.time() - tic\n",
    "\n",
    "            print(\n",
    "                (\n",
    "                    f\"Iteration: {iteration} - \"\n",
    "                    + f\"Elapsed time: {toc:.0f} - \"\n",
    "                    + f\"Training loss: {[f'{loss:.3f}' for loss in trn_loss]} - \"\n",
    "                    + f\"Validation loss: {[f'{loss:.3f}' for loss in val_loss]}\"\n",
    "                )\n",
    "            )\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "\n",
    "        iteration += batch_size\n",
    "\n",
    "    # Return the trained model\n",
    "    return total_trn_loss\n",
    "\n",
    "\n",
    "################################################################\n",
    "# main function that initializes needed classes and runs the train function\n",
    "def main():\n",
    "    ray.init(runtime_env={\"working_dir\": \"/home/jovyan/juart/src\"})\n",
    "    scaling_config = ScalingConfig(\n",
    "        num_workers=2,  # number of workers that should be initialized\n",
    "        use_gpu=True,  # should gpu be used?\n",
    "        resources_per_worker={\"CPU\": 24, \"GPU\": 1},\n",
    "    )\n",
    "\n",
    "    # Define the run configuration\n",
    "    run_config = RunConfig(\n",
    "        name=\"torch_trainer_example\",  # name of the log file\n",
    "        verbose=1,  # detail of the ouput\n",
    "    )\n",
    "\n",
    "    # Create the TorchTrainer\n",
    "    trainer = TorchTrainer(\n",
    "        train_func,\n",
    "        scaling_config=scaling_config,\n",
    "        run_config=run_config,\n",
    "    )\n",
    "\n",
    "    # Run the training\n",
    "    result = trainer.fit()  # runs the function we passed to the trainer\n",
    "    print(\"Training complete!\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
