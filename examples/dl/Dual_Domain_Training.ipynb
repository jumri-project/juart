{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18ac32d3-5ed3-4ae9-a216-bba86b4006e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib widget\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, \"../../src\")\n",
    "\n",
    "import gc\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.distributed as dist\n",
    "\n",
    "from juart.dl.checkpoint.manager import CheckpointManager\n",
    "from juart.dl.data.training import DatasetTraining\n",
    "from juart.dl.loss.loss import JointLoss\n",
    "from juart.dl.model.unrollnet import (\n",
    "    ExponentialMovingAverageModel,\n",
    "    LookaheadModel,\n",
    "    SingleContrastUnrolledNet,\n",
    "    UnrolledNet,\n",
    ")\n",
    "from juart.dl.operation.modules import training, validation\n",
    "from juart.dl.utils.dist import GradientAccumulator\n",
    "\n",
    "import os\n",
    "\n",
    "if os.getenv(\"ZS_SSL_RECON_SOFTWARE_DIR\") is not None:\n",
    "    sys.path.insert(0, os.getenv(\"ZS_SSL_RECON_SOFTWARE_DIR\"))\n",
    "\n",
    "from ray.train import ScalingConfig\n",
    "from ray.train.torch import TorchTrainer\n",
    "\n",
    "from juart.dl.utils.parser import options_parser\n",
    "from juart.dl.train.train import train_loop_per_worker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a088bb8b-e09d-489a-ac84-a5d6ba185d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parameters\n",
    "num_unroll_blocks = 10\n",
    "num_res_blocks = 15\n",
    "CG_Iter = 10\n",
    "activation = \"ReLU\"\n",
    "features = 512\n",
    "directory = (\n",
    "    \"model_test_checkpoint2\"  # Name that is used for the save directory of the model\n",
    ")\n",
    "root_dir = \"/home/jovyan/models\"  # path of the model directory\n",
    "backend = \"local\"  # backend of the model directory\n",
    "\n",
    "# Loss function parameters\n",
    "weight_kspace_loss = [0.5, 0.5]\n",
    "weight_ispace_loss = [0.1, 0.1]\n",
    "weight_hankel_loss = [0.0, 0.01]\n",
    "weight_casorati_loss = [0.0, 0.0]\n",
    "weight_wavelet_loss = [0.0, 0.0]\n",
    "normalized_loss = True\n",
    "\n",
    "# Training parameters\n",
    "epochs = 25\n",
    "model_training = True\n",
    "model_validation = False\n",
    "ema_decay = 0.9\n",
    "fractions = [0.0, 0.5, 0.5]\n",
    "\n",
    "optimizer = \"Adam\"\n",
    "normalized_gradient = False\n",
    "\n",
    "averaged_model = \"Lookahead\"\n",
    "\n",
    "save_checkpoint = True\n",
    "checkpoint_frequency = 10\n",
    "\n",
    "load_model_state = True\n",
    "load_averaged_model_state = True\n",
    "load_optim_state = True\n",
    "load_metrics = True\n",
    "\n",
    "disable_progress_bar = True\n",
    "timing_level = 0\n",
    "validation_level = 0\n",
    "\n",
    "num_threads = 24\n",
    "num_cpu_per_worker = 24\n",
    "num_gpu_per_worker = 0\n",
    "num_workers = 1\n",
    "group_size = 1\n",
    "use_gpu = False\n",
    "device = \"cpu\"\n",
    "\n",
    "data_dir = \"\"\n",
    "data_backend = \"local\"\n",
    "model_dir = \"\"\n",
    "model_backend = \"local\"\n",
    "image_dir = \"\"\n",
    "image_backend = \"local\"\n",
    "endpoint_url = \"https://s3.fz-juelich.de\"\n",
    "\n",
    "datasets = []\n",
    "slices = []\n",
    "start = 0\n",
    "stop = 3\n",
    "step = 1\n",
    "shape = 256, 256, 256, 2, 2\n",
    "num_spokes = 8\n",
    "batch_size = 1\n",
    "groups = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8597fec-b520-43fe-b7d5-bd27181dbc51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffled_indices(num_samples, num_epochs, rng):\n",
    "    indices = np.repeat(np.arange(num_samples), num_epochs)\n",
    "    indices = indices.reshape((num_samples, num_epochs))\n",
    "    indices = rng.permuted(indices, axis=0)\n",
    "    indices = indices.T.ravel()\n",
    "\n",
    "    # Check if each sample is used once and only once in every epoch\n",
    "    assert indices.size == num_samples * num_epochs\n",
    "    for i in np.split(indices, num_epochs):\n",
    "        assert np.unique(i).size == num_samples\n",
    "\n",
    "    return indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bffbe364-b525-40c2-9dec-78219148aa13",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist.init_process_group(\n",
    "    backend=\"gloo\", init_method=\"tcp://127.0.0.1:23456\", world_size=1, rank=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af909283-120e-4d7e-8036-b00f2fafc86a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank 0 - Intialize local groups ...\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "\n",
    "torch.set_num_threads(num_threads)\n",
    "#torch.set_num_interop_threads(num_threads)\n",
    "\n",
    "global_rank = int(dist.get_rank())\n",
    "world_size = int(dist.get_world_size())\n",
    "\n",
    "print(f\"Rank {global_rank} - Intialize local groups ...\")\n",
    "dist.barrier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f2dfb13-fb78-4bc4-809a-b095d6bfa03c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank 0 is in group [0] ...\n",
      "Rank 0 is local rank 0 ...\n"
     ]
    }
   ],
   "source": [
    "dist.barrier()\n",
    "\n",
    "for rank in range(0, world_size, group_size):\n",
    "    ranks = list(range(rank, rank + group_size, 1))\n",
    "    if global_rank in ranks:\n",
    "        print(f\"Rank {global_rank} is in group {ranks} ...\")\n",
    "        group = dist.new_group(ranks, backend=\"gloo\")\n",
    "    dist.barrier()\n",
    "\n",
    "group_rank = dist.get_group_rank(group, global_rank)\n",
    "group_index = global_rank // group_size\n",
    "num_groups = world_size // group_size\n",
    "\n",
    "print(f\"Rank {global_rank} is local rank {group_rank} ...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7686f1e3-788c-462c-b7e3-2a9e8ac94057",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank 0 is using device cpu ...\n"
     ]
    }
   ],
   "source": [
    "dist.barrier()\n",
    "\n",
    "if use_gpu and torch.cuda.is_available():\n",
    "    num_devices = torch.cuda.device_count()\n",
    "    device_rank = np.mod(global_rank, torch.cuda.device_count())\n",
    "    device = f\"cuda:{device_rank}\"\n",
    "    print(\n",
    "        f\"Rank {global_rank} - Using CUDA device {device_rank} of {num_devices} ...\"\n",
    "    )\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "\n",
    "print(f\"Rank {global_rank} is using device {device} ...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "68feaf12-d3d5-4863-93a1-dd9653308d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist.barrier()\n",
    "\n",
    "nD = len(datasets)\n",
    "nS = len(slices)\n",
    "nX, nY, nZ, nTI, nTE = shape\n",
    "\n",
    "num_epochs = epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "454d9222-6e24-45ad-bbcf-560b323697f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The number of batches that are computed serially via gradient accumulation\n",
    "batch_size = batch_size\n",
    "batch_size_local = batch_size // num_groups\n",
    "\n",
    "num_iterations = nD * nS * num_epochs\n",
    "\n",
    "rng = np.random.default_rng(seed=0)\n",
    "\n",
    "training_indices = shuffled_indices(nD * nS, num_epochs, rng)\n",
    "training_indices_batched = training_indices.reshape(\n",
    "    (-1, batch_size_local, num_groups)\n",
    ")\n",
    "\n",
    "validation_indices = shuffled_indices(nD * nS, num_epochs, rng)\n",
    "validation_indices_batched = validation_indices.reshape(\n",
    "    (-1, batch_size_local, num_groups)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe5fe577-18a2-42c3-943b-3b012a82c566",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare models and optimizer\n",
    "\n",
    "if groups == 1:\n",
    "    model = UnrolledNet(\n",
    "        shape,\n",
    "        features=features,\n",
    "        CG_Iter=CG_Iter,\n",
    "        num_unroll_blocks=num_unroll_blocks,\n",
    "        # weight_standardization=options[\"weight_standardization\"],\n",
    "        # spectral_normalization=options[\"spectral_normalization\"],\n",
    "        activation=activation,\n",
    "        disable_progress_bar=disable_progress_bar,\n",
    "        timing_level=timing_level,\n",
    "        validation_level=validation_level,\n",
    "        device=device,\n",
    "    )\n",
    "else:\n",
    "    model = SingleContrastUnrolledNet(\n",
    "        shape,\n",
    "        features=features,\n",
    "        CG_Iter=CG_Iter,\n",
    "        num_unroll_blocks=num_unroll_blocks,\n",
    "        # weight_standardization=options[\"weight_standardization\"],\n",
    "        # spectral_normalization=options[\"spectral_normalization\"],\n",
    "        activation=activation,\n",
    "        disable_progress_bar=disable_progress_bar,\n",
    "        timing_level=timing_level,\n",
    "        validation_level=validation_level,\n",
    "        device=device,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7990e98d-b66c-4033-b40f-41a53b3e95dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = JointLoss(\n",
    "    shape,\n",
    "    (3, 3),\n",
    "    weights_kspace_loss=weight_kspace_loss,\n",
    "    weights_ispace_loss=weight_ispace_loss,\n",
    "    weights_wavelet_loss=weight_wavelet_loss,\n",
    "    weights_hankel_loss=weight_hankel_loss,\n",
    "    weights_casorati_loss=weight_casorati_loss,\n",
    "    normalized_loss=normalized_loss,\n",
    "    timing_level=timing_level,\n",
    "    validation_level=validation_level,\n",
    "    group=group,\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1065c272-340d-493a-a990-15fc0bedf306",
   "metadata": {},
   "outputs": [],
   "source": [
    "if optimizer == \"Adam\":\n",
    "    optimizer = torch.optim.Adam(\n",
    "        model.parameters(),\n",
    "        lr=0.0001,\n",
    "        betas=[0.9, 0.999],\n",
    "        eps=1.0e-8,\n",
    "        weight_decay=0.0,\n",
    "    )\n",
    "elif optimizer == \"AdamW\":\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        model.parameters(),\n",
    "        lr=0.0001,\n",
    "        betas=[0.9, 0.999],\n",
    "        eps=1.0e-8,\n",
    "        weight_decay=0.0,\n",
    "    )\n",
    "elif optimizer == \"RAdam\":\n",
    "    optimizer = torch.optim.RAdam(\n",
    "        model.parameters(),\n",
    "        lr=0.0001,\n",
    "        betas=[0.9, 0.999],\n",
    "        eps=1.0e-8,\n",
    "        weight_decay=0.0,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b147f34f-690a-4a87-a1f5-56290010a22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "accumulator = GradientAccumulator(\n",
    "    model,\n",
    "    accumulation_steps=batch_size_local,\n",
    "    max_norm=1.0,\n",
    "    normalized_gradient=normalized_gradient\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f201a174-3b7e-4151-9dc0-09d111bf9d4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank 0 - LookaheadModel\n"
     ]
    }
   ],
   "source": [
    "if averaged_model == \"EMA\":\n",
    "    print(f\"Rank {global_rank} - ExponentialMovingAverageModel\")\n",
    "    averaged_model = ExponentialMovingAverageModel(\n",
    "        model,\n",
    "        decay=ema_decay,\n",
    "    )\n",
    "elif averaged_model == \"Lookahead\":\n",
    "    print(f\"Rank {global_rank} - LookaheadModel\")\n",
    "    averaged_model = LookaheadModel(\n",
    "        model,\n",
    "        alpha=0.5,\n",
    "        k=5,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "73c287a6-4b43-4ed0-a6eb-50dd2413844a",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_manager = CheckpointManager(\n",
    "    model_dir,\n",
    "    root_dir=root_dir,\n",
    "    endpoint_url=endpoint_url,\n",
    "    backend=model_backend,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3b8d97d8-f25d-4335-81f1-c1b52f88963a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank 0 - Loading model state ...\n",
      "Rank 0 - Could not load model state.\n"
     ]
    }
   ],
   "source": [
    "if load_model_state:\n",
    "    print(f\"Rank {global_rank} - Loading model state ...\")\n",
    "    checkpoint = checkpoint_manager.load([\"model_state\"], map_location=device)\n",
    "    if all(checkpoint.values()):\n",
    "        model.load_state_dict(checkpoint[\"model_state\"])\n",
    "    else:\n",
    "        print(f\"Rank {global_rank} - Could not load model state.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "29cdcf28-8d2c-440e-92fd-8534b13c5ee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank 0 - Loading averaged model state ...\n",
      "Rank 0 - Could not load averaged model state.\n"
     ]
    }
   ],
   "source": [
    "if load_averaged_model_state:\n",
    "    print(f\"Rank {global_rank} - Loading averaged model state ...\")\n",
    "    checkpoint = checkpoint_manager.load(\n",
    "        [\"averaged_model_state\"], map_location=device\n",
    "    )\n",
    "    if all(checkpoint.values()):\n",
    "        averaged_model.load_state_dict(checkpoint[\"averaged_model_state\"])\n",
    "    else:\n",
    "        print(f\"Rank {global_rank} - Could not load averaged model state.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "69551594-64ba-4c8d-bb15-9d83c8c724bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank 0 - Loading optim state ...\n",
      "Rank 0 - Could not load optim state.\n"
     ]
    }
   ],
   "source": [
    "if load_optim_state:\n",
    "    print(f\"Rank {global_rank} - Loading optim state ...\")\n",
    "    checkpoint = checkpoint_manager.load([\"optim_state\"], map_location=device)\n",
    "    if all(checkpoint.values()):\n",
    "        optimizer.load_state_dict(checkpoint[\"optim_state\"])\n",
    "    else:\n",
    "        print(f\"Rank {global_rank} - Could not load optim state.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dc92893b-d6f7-4423-a37f-3df929c60a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "    total_trn_loss = list()\n",
    "    total_val_loss = list()\n",
    "    iteration = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5f63f24c-ab98-4dd9-b01c-c4ee06fb8060",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank 0 - Loading metrics ...\n",
      "Rank 0 - Could not load metrics.\n",
      "Rank 0 - Continue with iteration 0 ...\n"
     ]
    }
   ],
   "source": [
    "if load_metrics:\n",
    "    print(f\"Rank {global_rank} - Loading metrics ...\")\n",
    "    checkpoint = checkpoint_manager.load([\"trn_loss\", \"val_loss\", \"iteration\"])\n",
    "    if all(checkpoint.values()):\n",
    "        total_trn_loss = list(checkpoint[\"trn_loss\"])\n",
    "        total_val_loss = list(checkpoint[\"val_loss\"])\n",
    "        iteration = checkpoint[\"iteration\"]\n",
    "    else:\n",
    "        print(f\"Rank {global_rank} - Could not load metrics.\")\n",
    "\n",
    "print(f\"Rank {global_rank} - Continue with iteration {iteration} ...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ce8c5f77-31fd-4efa-a869-e57bf5feb4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = DatasetTraining(\n",
    "    data_dir,\n",
    "    datasets,\n",
    "    slices,\n",
    "    num_spokes,\n",
    "    fractions,\n",
    "    mode=\"training\",\n",
    "    group_rank=group_rank,\n",
    "    root_dir=root_dir,\n",
    "    endpoint_url=endpoint_url,\n",
    "    backend=data_backend,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "01ffe5de-769e-4fdc-aa3a-7bdef6bb8d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "while iteration < num_iterations:\n",
    "    tic = time.time()\n",
    "\n",
    "    # Reset the seed so that training can be resumed\n",
    "    np.random.seed(iteration)\n",
    "    torch.manual_seed(iteration)\n",
    "\n",
    "    training_index = training_indices_batched[\n",
    "        iteration // batch_size,\n",
    "        :,\n",
    "        group_index,\n",
    "    ].tolist()\n",
    "    validation_index = validation_indices_batched[\n",
    "        iteration // batch_size, :, group_index\n",
    "    ].tolist()\n",
    "\n",
    "    if options[\"model_training\"]:\n",
    "        print(f\"Rank {global_rank} - Training index {training_index} ...\")\n",
    "\n",
    "        trn_loss = training(\n",
    "            training_index,\n",
    "            training_data,\n",
    "            model,\n",
    "            loss_fn,\n",
    "            optimizer,\n",
    "            accumulator,\n",
    "            group=group,\n",
    "            device=device,\n",
    "        )\n",
    "\n",
    "        averaged_model.update_parameters(\n",
    "            model,\n",
    "        )\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "\n",
    "    else:\n",
    "        trn_loss = [0] * batch_size\n",
    "\n",
    "    if options[\"model_validation\"]:\n",
    "        print(f\"Rank {global_rank} - Validation index {validation_index} ...\")\n",
    "\n",
    "        val_loss = validation(\n",
    "            validation_index,\n",
    "            validation_data,\n",
    "            averaged_model,\n",
    "            loss_fn,\n",
    "            group=group,\n",
    "            device=device,\n",
    "        )\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "\n",
    "    else:\n",
    "        val_loss = [0] * batch_size\n",
    "\n",
    "    total_trn_loss += trn_loss\n",
    "    total_val_loss += val_loss\n",
    "\n",
    "    if global_rank == 0:\n",
    "        # Completed epoch\n",
    "        if (\n",
    "            options[\"save_checkpoint\"]\n",
    "            and np.mod(iteration + batch_size, nD * nS) == 0\n",
    "        ):\n",
    "            print(\"Creating tagged checkpoint ...\")\n",
    "\n",
    "            checkpoint = {\n",
    "                \"iteration\": iteration + batch_size,\n",
    "                \"model_state\": model.state_dict(),\n",
    "                \"averaged_model_state\": averaged_model.state_dict(),\n",
    "                \"optim_state\": optimizer.state_dict(),\n",
    "                \"trn_loss\": total_trn_loss,\n",
    "                \"val_loss\": total_val_loss,\n",
    "            }\n",
    "\n",
    "            epoch = (iteration + batch_size) // (nD * nS)\n",
    "            checkpoint_manager.save(checkpoint, tag=f\"_epoch_{epoch}\")\n",
    "\n",
    "            if options[\"single_epoch\"]:\n",
    "                # Also save the checkpoint as untagged checkpoint\n",
    "                # Otherwise, training will be stuck in endless loop\n",
    "                checkpoint_manager.save(checkpoint)\n",
    "                checkpoint_manager.release()\n",
    "                break\n",
    "\n",
    "        # Intermediate checkpoint\n",
    "        elif (\n",
    "            options[\"save_checkpoint\"]\n",
    "            and np.mod(iteration + batch_size, options[\"checkpoint_frequency\"]) == 0\n",
    "        ):\n",
    "            print(\"Creating untagged checkpoint ...\")\n",
    "\n",
    "            checkpoint = {\n",
    "                \"iteration\": iteration + batch_size,\n",
    "                \"model_state\": model.state_dict(),\n",
    "                \"averaged_model_state\": averaged_model.state_dict(),\n",
    "                \"optim_state\": optimizer.state_dict(),\n",
    "                \"trn_loss\": total_trn_loss,\n",
    "                \"val_loss\": total_val_loss,\n",
    "            }\n",
    "\n",
    "            checkpoint_manager.save(checkpoint, block=False)\n",
    "\n",
    "        toc = time.time() - tic\n",
    "\n",
    "        print(\n",
    "            (\n",
    "                f\"Iteration: {iteration} - \"\n",
    "                + f\"Elapsed time: {toc:.0f} - \"\n",
    "                + f\"Training loss: {[f'{loss:.3f}' for loss in trn_loss]} - \"\n",
    "                + f\"Validation loss: {[f'{loss:.3f}' for loss in val_loss]}\"\n",
    "            )\n",
    "        )\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "    iteration += batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307b8e82-5682-43a3-a8d9-aa449599b1b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
