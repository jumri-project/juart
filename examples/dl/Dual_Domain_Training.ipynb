{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62c61772-828b-44ab-a299-33ec910180c2",
   "metadata": {},
   "source": [
    "# Dual Domain Training for 3D Datasets\n",
    "This Notebook is an upgraded version of the already existing Training_3D.ipynb. The reconstructed images of the models trained by the normal training seem to be very noisy. The dual domain training can hopefully remove the noise better. The structure of the Network stays the same but ray and the torch distributor function are used to run the training twice on two different gpus. Furthermore the ispace loss is used to weight the difference between the kspace data of the 2 models and to average their gradients before doing the optimizer step. In this way both trainings are running seperately but the optimizer step they do are the exact same because the greadients used during the optimizers step are the average of the both calculated gradients. Setting the weight_ispace_loss on 0 results in the normal Training again (except of the fact that there are 2 models getting trained but only one is saved at the end)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a03f1b-c822-497c-9317-bbef848cb246",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import of all necessary functions and classes\n",
    "import os\n",
    "import torch\n",
    "import gc\n",
    "import time\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from ray.train.torch import TorchTrainer\n",
    "from ray.train import ScalingConfig\n",
    "from ray.air.config import RunConfig\n",
    "from typing import Tuple\n",
    "import numpy as np\n",
    "import torch.distributed as dist\n",
    "import ray\n",
    "import h5py\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2,3\"\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, \"../../src\")\n",
    "from juart.dl.loss.loss import JointLoss\n",
    "from juart.dl.operation.modules import training\n",
    "from juart.dl.utils.dist import GradientAccumulator\n",
    "from juart.dl.model.unrollnet import LookaheadModel, UnrolledNet\n",
    "from juart.dl.checkpoint.manager import CheckpointManager\n",
    "from juart.conopt.functional.fourier import (\n",
    "    fourier_transform_adjoint,\n",
    "    fourier_transform_forward,\n",
    "    nonuniform_fourier_transform_adjoint,\n",
    ")\n",
    "\n",
    "# activates the terminal output for print commands in ray\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# Training function that is later passed to the TorchTrainer\n",
    "def train_func():\n",
    "\n",
    "    # define variables\n",
    "    weight_kspace_loss = [0.5, 0.5] # weight the difference in k space\n",
    "    weight_ispace_loss = [0.0, 0.0] # weight the difference of the two images (dual domain) and average their gradients\n",
    "    weight_hankel_loss = [0.0, 0.0]\n",
    "    weight_casorati_loss = [0.0, 0.0]\n",
    "    weight_wavelet_loss = [0.0, 0.0] # weight the loss in wavelet domain\n",
    "    normalized_loss = True\n",
    "    \n",
    "    batch_size = 1 # number of datapoints used per batch iteration\n",
    "    nD = 1 # number of datasets\n",
    "    nP = 50 # number of permutations per epoch\n",
    "    cgiter = 10 # number of dc iterations\n",
    "    num_epochs = 20 # number of epochs\n",
    "    \n",
    "    global_rank = int(dist.get_rank())\n",
    "    world_size = int(dist.get_world_size())\n",
    "    group_size = 2\n",
    "    model_dir = f'model_{nP}P_{cgiter}DC_{num_epochs}E'\n",
    "    root_dir =\"/home/jovyan/models\"\n",
    "    endpoint_url = \"https://s3.fz-juelich.de\"\n",
    "    model_backend = 'local'\n",
    "\n",
    "    single_epoch = True # if its true the script will stop after 1 epoch\n",
    "    save_checkpoint = True # enables checkpoint saving\n",
    "    checkpoint_frequency = 5 # number of iterations between the save files\n",
    "    load_model_state = True # if true the latest model state will be loaded if available\n",
    "    load_averaged_model_state = True # latest averaged model state will be loaded\n",
    "    load_optim_state = True # latest optimizer state will be loaded\n",
    "    load_metrics = True # the latest metrics (lost, iterations) will be loaded\n",
    "\n",
    "    num_groups = 1\n",
    "    batch_size_local = batch_size // num_groups\n",
    "    num_iterations = nD * nP * num_epochs\n",
    "    \n",
    "    ################################################################\n",
    "    # Setting the rank for each worker\n",
    "    for rank in range(0, world_size, group_size):\n",
    "        ranks = list(range(rank, rank + group_size, 1))\n",
    "        if global_rank in ranks:\n",
    "            print(f\"Rank {global_rank} is in group {ranks} ...\")\n",
    "            group = dist.new_group(ranks, backend=\"gloo\")\n",
    "    \n",
    "    ################################################################\n",
    "    # reading and shaping data\n",
    "    data_path = \"/home/jovyan/juart/examples/dl/3DLiss_vd_preproc.h5\"\n",
    "    with h5py.File(data_path, \"r\") as f:\n",
    "        print(f\"Dataset holds following data: {f.keys()}\")\n",
    "    \n",
    "        print(f\"Coilsensitivity info: {f['coilsens'].attrs['info']}\")\n",
    "        print(f\"Trajectory info: {f['k'].attrs['info']}\")\n",
    "        print(f\"Signal info: {f['d'].attrs['info']}\")\n",
    "    \n",
    "        shape = (156, 156, 156, 2)\n",
    "        nX, nY, nZ, nTI = shape\n",
    "        nTE = 1\n",
    "        ktraj = torch.from_numpy(f[\"k\"][:])\n",
    "        coilsens = torch.from_numpy(f[\"coilsens\"][:])\n",
    "        d = torch.from_numpy(f[\"d\"][:])\n",
    "    \n",
    "        print(f\"Coilsensitivity shape {coilsens.shape}\")\n",
    "        print(f\"Trajectory shape {ktraj.shape}\")\n",
    "        print(f\"Signal shape {d.shape}\")\n",
    "\n",
    "    # --- shaping data ---\n",
    "    k_scaled = ktraj / (2 * ktraj.max())\n",
    "\n",
    "    k_scaled = k_scaled.unsqueeze(-1)\n",
    "    d = d.unsqueeze(-1)\n",
    "    \n",
    "    generator = torch.Generator()\n",
    "\n",
    "    ################################################################\n",
    "    # Defining the neural network\n",
    "    \n",
    "    model = UnrolledNet((156,156,156,2,1),\n",
    "                      CG_Iter = cgiter,\n",
    "                      num_unroll_blocks = 10,\n",
    "                      num_res_blocks = 15,\n",
    "                      features = 32,\n",
    "                      weight_standardization = False, \n",
    "                      spectral_normalization = False,\n",
    "                      axes = (1,2,3),\n",
    "                      kernel_size = (3,3,3),\n",
    "                      activation = 'ReLU',\n",
    "                      ResNetCheckpoints = True).to(device)\n",
    "\n",
    "    loss_fn = JointLoss(\n",
    "        (156,156,156,2,1),\n",
    "        (3, 3),\n",
    "        weights_kspace_loss = weight_kspace_loss,\n",
    "        weights_ispace_loss = weight_ispace_loss,\n",
    "        weights_hankel_loss = weight_hankel_loss,\n",
    "        weights_casorati_loss = weight_casorati_loss,\n",
    "        weights_wavelet_loss = weight_wavelet_loss,\n",
    "        normalized_loss=normalized_loss,\n",
    "        group = group,\n",
    "        device=device,\n",
    "    )\n",
    "    \n",
    "    optimizer = torch.optim.Adam(\n",
    "        model.parameters(),\n",
    "        lr=0.0001,\n",
    "        betas=[0.9, 0.999],\n",
    "        eps=1.0e-8,\n",
    "        weight_decay=0.0,\n",
    "    )\n",
    "\n",
    "    accumulator = GradientAccumulator(\n",
    "        model,\n",
    "        accumulation_steps=batch_size_local,\n",
    "        max_norm=1.0,\n",
    "        normalized_gradient=False,\n",
    "    )\n",
    "\n",
    "    averaged_model = LookaheadModel(\n",
    "        model,\n",
    "        alpha=0.5,\n",
    "        k=5,\n",
    "    )\n",
    "\n",
    "    dist.barrier()\n",
    "    \n",
    "    checkpoint_manager = CheckpointManager(\n",
    "        model_dir,\n",
    "        root_dir=root_dir,\n",
    "        endpoint_url=endpoint_url,\n",
    "        backend=model_backend,\n",
    "    )\n",
    "\n",
    "    dist.barrier()\n",
    "\n",
    "    ################################################################\n",
    "    # LOADING CURRENT MODEL STATE\n",
    "    if load_model_state:\n",
    "        print(f\"Rank {global_rank} - Loading model state ...\")\n",
    "        checkpoint = checkpoint_manager.load([\"model_state\"], map_location=device)\n",
    "        if all(checkpoint.values()):\n",
    "            model.load_state_dict(checkpoint[\"model_state\"])\n",
    "        else:\n",
    "            print(f\"Rank {global_rank} - Could not load model state.\")\n",
    "    \n",
    "    if load_averaged_model_state:\n",
    "        print(f\"Rank {global_rank} - Loading averaged model state ...\")\n",
    "        checkpoint = checkpoint_manager.load(\n",
    "            [\"averaged_model_state\"], map_location=device\n",
    "        )\n",
    "        if all(checkpoint.values()):\n",
    "            averaged_model.load_state_dict(checkpoint[\"averaged_model_state\"])\n",
    "        else:\n",
    "            print(f\"Rank {global_rank} - Could not load averaged model state.\")\n",
    "    \n",
    "    if load_optim_state:\n",
    "        print(f\"Rank {global_rank} - Loading optim state ...\")\n",
    "        checkpoint = checkpoint_manager.load([\"optim_state\"], map_location=device)\n",
    "        if all(checkpoint.values()):\n",
    "            optimizer.load_state_dict(checkpoint[\"optim_state\"])\n",
    "        else:\n",
    "            print(f\"Rank {global_rank} - Could not load optim state.\")\n",
    "    \n",
    "        total_trn_loss = list()\n",
    "        total_val_loss = list()\n",
    "        iteration = 0\n",
    "    \n",
    "    if load_metrics:\n",
    "        print(f\"Rank {global_rank} - Loading metrics ...\")\n",
    "        checkpoint = checkpoint_manager.load([\"trn_loss\", \"val_loss\", \"iteration\"])\n",
    "        if all(checkpoint.values()):\n",
    "            total_trn_loss = list(checkpoint[\"trn_loss\"])\n",
    "            total_val_loss = list(checkpoint[\"val_loss\"])\n",
    "            iteration = checkpoint[\"iteration\"]\n",
    "        else:\n",
    "            print(f\"Rank {global_rank} - Could not load metrics.\")\n",
    "\n",
    "    print(f\"Rank {global_rank} - Continue with iteration {iteration} ...\")\n",
    "\n",
    "    dist.barrier()\n",
    "\n",
    "    ################################################################\n",
    "    # ACTUAL TRAINING LOOP\n",
    "    total_trn_loss = list()\n",
    "    total_val_loss = list()\n",
    "    iteration = 0\n",
    "\n",
    "    while iteration < num_iterations:\n",
    "        tic = time.time()\n",
    "        generator.manual_seed(iteration%nP)\n",
    "    \n",
    "        kspace_mask_worker0 = torch.randint(0, 2, (1, k_scaled.shape[1], 2, 1), generator=generator)\n",
    "        kspace_mask_worker1 = 1 - kspace_mask_worker0\n",
    "\n",
    "        # Defining data for worker 0\n",
    "        if global_rank == 0:\n",
    "            k_scaled_masked = k_scaled * kspace_mask_worker0\n",
    "            AHd = nonuniform_fourier_transform_adjoint(k_scaled_masked, d, (nX, nY, nZ))\n",
    "            AHd = torch.sum(torch.conj(coilsens[..., None,None]) * AHd, dim=0)\n",
    "        \n",
    "            data = [\n",
    "               {\n",
    "                   \"images_regridded\": AHd,\n",
    "                   \"kspace_trajectory\": k_scaled,\n",
    "                   \"sensitivity_maps\": coilsens,\n",
    "                   \"kspace_mask_source\": kspace_mask_worker0,\n",
    "                   \"kspace_mask_target\": kspace_mask_worker1,\n",
    "                   \"kspace_data\": d,\n",
    "               }\n",
    "            ]\n",
    "\n",
    "        # Defining data for worker 1\n",
    "        elif global_rank == 1:\n",
    "            k_scaled_masked = k_scaled * kspace_mask_worker1\n",
    "            AHd = nonuniform_fourier_transform_adjoint(k_scaled_masked, d, (nX, nY, nZ))\n",
    "            AHd = torch.sum(torch.conj(coilsens[..., None,None]) * AHd, dim=0)\n",
    "    \n",
    "            data = [\n",
    "               {\n",
    "                   \"images_regridded\": AHd,\n",
    "                   \"kspace_trajectory\": k_scaled,\n",
    "                   \"sensitivity_maps\": coilsens,\n",
    "                   \"kspace_mask_source\": kspace_mask_worker1,\n",
    "                   \"kspace_mask_target\": kspace_mask_worker0,\n",
    "                   \"kspace_data\": d,\n",
    "               }\n",
    "            ]\n",
    "    \n",
    "        trn_loss = training(\n",
    "           [0],\n",
    "           data,\n",
    "           model,\n",
    "           loss_fn,\n",
    "           optimizer,\n",
    "           accumulator,\n",
    "           group=group,\n",
    "           device=device,\n",
    "        )\n",
    "\n",
    "        val_loss = [0] * batch_size\n",
    "\n",
    "    ################################################################\n",
    "    # SAVING DATA\n",
    "        if global_rank == 0:\n",
    "            # Completed epoch\n",
    "            if (\n",
    "                save_checkpoint\n",
    "                and np.mod(iteration + batch_size, nD * nP) == 0\n",
    "            ):\n",
    "                print(\"Creating tagged checkpoint ...\")\n",
    "    \n",
    "                checkpoint = {\n",
    "                    \"iteration\": iteration + batch_size,\n",
    "                    \"model_state\": model.state_dict(),\n",
    "                    \"averaged_model_state\": averaged_model.state_dict(),\n",
    "                    \"optim_state\": optimizer.state_dict(),\n",
    "                    \"trn_loss\": total_trn_loss,\n",
    "                    \"val_loss\": total_val_loss,\n",
    "                }\n",
    "    \n",
    "                epoch = (iteration + batch_size) // (nD * nP)\n",
    "                checkpoint_manager.save(checkpoint, tag=f\"_epoch_{epoch}\")\n",
    "    \n",
    "                if single_epoch:\n",
    "                    # Also save the checkpoint as untagged checkpoint\n",
    "                    # Otherwise, training will be stuck in endless loop\n",
    "                    checkpoint_manager.save(checkpoint)\n",
    "                    checkpoint_manager.release()\n",
    "                    break\n",
    "    \n",
    "            # Intermediate checkpoint\n",
    "            elif (\n",
    "                save_checkpoint\n",
    "                and np.mod(iteration + batch_size, checkpoint_frequency) == 0\n",
    "            ):\n",
    "                print(\"Creating untagged checkpoint ...\")\n",
    "    \n",
    "                checkpoint = {\n",
    "                    \"iteration\": iteration + batch_size,\n",
    "                    \"model_state\": model.state_dict(),\n",
    "                    \"averaged_model_state\": averaged_model.state_dict(),\n",
    "                    \"optim_state\": optimizer.state_dict(),\n",
    "                    \"trn_loss\": total_trn_loss,\n",
    "                    \"val_loss\": total_val_loss,\n",
    "                }\n",
    "    \n",
    "                checkpoint_manager.save(checkpoint, block=False)\n",
    "    \n",
    "            toc = time.time() - tic\n",
    "    \n",
    "            print(\n",
    "                (\n",
    "                    f\"Iteration: {iteration} - \"\n",
    "                    + f\"Elapsed time: {toc:.0f} - \"\n",
    "                    + f\"Training loss: {[f'{loss:.3f}' for loss in trn_loss]} - \"\n",
    "                    + f\"Validation loss: {[f'{loss:.3f}' for loss in val_loss]}\"\n",
    "                )\n",
    "            )\n",
    "    \n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "    \n",
    "        iteration += batch_size\n",
    "\n",
    "    # Return the trained model\n",
    "    return {\"model\": model.parameters()}\n",
    "\n",
    "################################################################\n",
    "# main function that initializes needed classes and runs the train function\n",
    "def main():\n",
    "\n",
    "    dist.init_process_group(\n",
    "    backend=\"gloo\", init_method=\"tcp://127.0.0.1:23456\", world_size=1, rank=0\n",
    "    )\n",
    "    \n",
    "    ray.init(runtime_env={\"working_dir\": \"/home/jovyan/juart/src\"})\n",
    "    scaling_config = ScalingConfig(\n",
    "        num_workers=2, # number of workers that should be initialized\n",
    "        use_gpu=True,  # should gpu be used?\n",
    "        resources_per_worker={\"CPU\": 24, \"GPU\": 1},\n",
    "    )\n",
    "\n",
    "    # Define the run configuration\n",
    "    run_config = RunConfig(\n",
    "        name=\"torch_trainer_example\", # name of the log file\n",
    "        verbose=1, # detail of the ouput\n",
    "    )\n",
    "\n",
    "    # Create the TorchTrainer\n",
    "    trainer = TorchTrainer(\n",
    "        train_func,\n",
    "        scaling_config=scaling_config,\n",
    "        run_config=run_config,\n",
    "    )\n",
    "\n",
    "    # Run the training\n",
    "    result = trainer.fit() # runs the function we passed to the trainer\n",
    "    print(\"Training complete!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ce0dc0-5bdf-442d-9e94-2a0ce82c5039",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
