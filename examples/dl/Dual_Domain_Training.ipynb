{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62c61772-828b-44ab-a299-33ec910180c2",
   "metadata": {},
   "source": [
    "# Dual Domain Training for 3D Datasets\n",
    "This Notebook is an upgraded version of the already existing Training_3D.ipynb. The reconstructed images of the models trained by the normal training seem to be very noisy. The dual domain training can hopefully remove the noise better. The structure of the Network stays the same but ray and the torch distributor function are used to run the training twice on two different gpus. Furthermore the ispace loss is used to weight the difference between the kspace data of the 2 models and to average their gradients before doing the optimizer step. In this way both trainings are running seperately but the optimizer step they do are the exact same because the greadients used during the optimizers step are the average of the both calculated gradients. Setting the weight_ispace_loss on 0 results in the normal Training again (except of the fact that there are 2 models getting trained but only one is saved at the end)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a03f1b-c822-497c-9317-bbef848cb246",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-29 11:57:47,768\tWARNING services.py:2148 -- WARNING: The object store is using /tmp instead of /dev/shm because /dev/shm has only 66977792 bytes available. This will harm performance! You may be able to free up space by deleting files in /dev/shm. If you are inside a Docker container, you can increase /dev/shm size by passing '--shm-size=10.24gb' to 'docker run' (or add it to the run_options list in a Ray cluster config). Make sure to set this to more than 30% of available RAM.\n",
      "2025-09-29 11:57:49,010\tINFO worker.py:1942 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265 \u001b[39m\u001b[22m\n",
      "2025-09-29 11:57:49,109\tINFO packaging.py:588 -- Creating a file package for local module '/home/jovyan/juart/src'.\n",
      "2025-09-29 11:57:49,134\tWARNING packaging.py:430 -- File /home/jovyan/juart/src/juart/phantoms/mni/MNIbrain_hires.nii is very large (54.24MiB). Consider adding this file to the 'excludes' list to skip uploading it: `ray.init(..., runtime_env={'excludes': ['/home/jovyan/juart/src/juart/phantoms/mni/MNIbrain_hires.nii']})`\n",
      "2025-09-29 11:57:49,382\tINFO packaging.py:380 -- Pushing file package 'gcs://_ray_pkg_bf6b43a98c80cd6e.zip' (70.13MiB) to Ray cluster...\n",
      "2025-09-29 11:57:49,864\tINFO packaging.py:393 -- Successfully pushed file package 'gcs://_ray_pkg_bf6b43a98c80cd6e.zip'.\n",
      "/opt/conda/lib/python3.13/site-packages/ray/train/base_trainer.py:575: RayDeprecationWarning: `ray.train.RunConfig(verbose)` is deprecated. This parameter controls Ray Tune logging verbosity, and is only relevant when using Ray Tune. This parameter is still available in `ray.tune.RunConfig` for passing into a `ray.tune.Tuner`. See this issue for more context and migration options: https://github.com/ray-project/ray/issues/49454. Disable these warnings by setting the environment variable: RAY_TRAIN_ENABLE_V2_MIGRATION_WARNINGS=0\n",
      "  _log_deprecation_warning(VERBOSE_DEPRECATION_MESSAGE)\n",
      "2025-09-29 11:57:55,028\tINFO tune.py:616 -- [output] This uses the legacy output and progress reporter, as Jupyter notebooks are not supported by the new engine, yet. For more information, please see https://github.com/ray-project/ray/issues/36949\n",
      "2025-09-29 11:57:55,032\tINFO tensorboardx.py:193 -- pip install \"ray[tune]\" to see TensorBoard files.\n",
      "2025-09-29 11:57:55,033\tWARNING callback.py:143 -- The TensorboardX logger cannot be instantiated because either TensorboardX or one of it's dependencies is not installed. Please make sure you have the latest version of TensorboardX installed: `pip install -U tensorboardx`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 11:57:55 (running for 00:00:00.13)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 0/128 CPUs, 0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 PENDING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 11:58:00 (running for 00:00:05.19)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 PENDING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TorchTrainer pid=566798)\u001b[0m /opt/conda/lib/python3.13/site-packages/ray/train/base_trainer.py:575: RayDeprecationWarning: `ray.train.RunConfig(verbose)` is deprecated. This parameter controls Ray Tune logging verbosity, and is only relevant when using Ray Tune. This parameter is still available in `ray.tune.RunConfig` for passing into a `ray.tune.Tuner`. See this issue for more context and migration options: https://github.com/ray-project/ray/issues/49454. Disable these warnings by setting the environment variable: RAY_TRAIN_ENABLE_V2_MIGRATION_WARNINGS=0\n",
      "\u001b[36m(TorchTrainer pid=566798)\u001b[0m   _log_deprecation_warning(VERBOSE_DEPRECATION_MESSAGE)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 11:58:05 (running for 00:00:10.20)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Setting up process group for: env:// [rank=0, world_size=2]\n",
      "\u001b[36m(TorchTrainer pid=566798)\u001b[0m Started distributed worker processes: \n",
      "\u001b[36m(TorchTrainer pid=566798)\u001b[0m - (node_id=cfa7bc5017388458110899e2b51673e25920f4d8be2bb9c837561354, ip=10.1.64.190, pid=569511) world_rank=0, local_rank=0, node_rank=0\n",
      "\u001b[36m(TorchTrainer pid=566798)\u001b[0m - (node_id=cfa7bc5017388458110899e2b51673e25920f4d8be2bb9c837561354, ip=10.1.64.190, pid=569510) world_rank=1, local_rank=1, node_rank=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 is in group [0, 1] ...\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Coilsensitivity shape torch.Size([8, 156, 156, 156])\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Trajectory shape torch.Size([3, 2001191, 2, 1])\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Signal shape torch.Size([8, 2001191, 2, 1])\n",
      "== Status ==\n",
      "Current time: 2025-09-29 11:58:10 (running for 00:00:15.22)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   warnings.warn(  # warn only once\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m [rank1]:[W929 11:58:12.251824589 ProcessGroupNCCL.cpp:4718] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can pecify device_id in init_process_group() to force use of a particular device.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - Loading model state ...\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - Could not load model state.\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - Loading averaged model state ...\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - Could not load averaged model state.\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - Loading optim state ...\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - Could not load optim state.\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - Loading metrics ...\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - Could not load metrics.\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - Continue with iteration 0 ...\n",
      "== Status ==\n",
      "Current time: 2025-09-29 11:58:15 (running for 00:00:20.24)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 11:58:20 (running for 00:00:25.26)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - reading data\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 is in group [0, 1] ...\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Coilsensitivity shape torch.Size([8, 156, 156, 156])\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Trajectory shape torch.Size([3, 2001191, 2, 1])\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Signal shape torch.Size([8, 2001191, 2, 1])\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - Loading model state ...\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - Could not load model state.\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - Loading averaged model state ...\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - Could not load averaged model state.\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - Loading optim state ...\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - Could not load optim state.\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - Loading metrics ...\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - Could not load metrics.\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - Continue with iteration 0 ...\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - reading data done -> model initialization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \u001b[32m [repeated 2x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   warnings.warn(  # warn only once\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m [rank0]:[W929 11:58:12.249138466 ProcessGroupNCCL.cpp:4718] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can pecify device_id in init_process_group() to force use of a particular device.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 11:58:25 (running for 00:00:30.29)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                   | 0/10 [00:00<?, ?it/s]\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m   warnings.warn(  # warn only once\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 11:58:30 (running for 00:00:35.31)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 11:58:35 (running for 00:00:40.33)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████▎                                      | 1/10 [00:10<01:34, 10.47s/it]\n",
      "  0%|                                                   | 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 11:58:40 (running for 00:00:45.35)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 11:58:45 (running for 00:00:50.37)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████▌                                  | 2/10 [00:20<01:23, 10.39s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 11:58:50 (running for 00:00:55.39)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 11:58:55 (running for 00:01:00.41)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|████████████▉                              | 3/10 [00:31<01:12, 10.37s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 11:59:00 (running for 00:01:05.42)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 11:59:05 (running for 00:01:10.44)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|█████████████████▏                         | 4/10 [00:41<01:02, 10.36s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 11:59:10 (running for 00:01:15.46)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 11:59:15 (running for 00:01:20.48)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████████████████████▌                     | 5/10 [00:51<00:51, 10.37s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 11:59:20 (running for 00:01:25.50)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 11:59:25 (running for 00:01:30.52)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████████████████████████▊                 | 6/10 [01:02<00:41, 10.38s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 11:59:30 (running for 00:01:35.53)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 11:59:35 (running for 00:01:40.56)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 11:59:40 (running for 00:01:45.57)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████████████████████████████             | 7/10 [01:12<00:31, 10.39s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 11:59:45 (running for 00:01:50.59)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 11:59:50 (running for 00:01:55.61)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|██████████████████████████████████▍        | 8/10 [01:23<00:20, 10.39s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 11:59:55 (running for 00:02:00.63)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:00:00 (running for 00:02:05.65)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|██████████████████████████████████████▋    | 9/10 [01:33<00:10, 10.40s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 12:00:05 (running for 00:02:10.67)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:00:10 (running for 00:02:15.69)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - model initialization done -> loss fn initialization\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - reading data\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - reading data done -> model initialization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 10/10 [01:43<00:00, 10.39s/it]\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   warnings.warn(  # warn only once\n",
      " 90%|██████████████████████████████████████▋    | 9/10 [01:35<00:10, 10.47s/it]\n",
      "100%|██████████████████████████████████████████| 10/10 [01:45<00:00, 10.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 12:00:15 (running for 00:02:20.71)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m [KSpaceLoss] torch.Size([8, 2001191, 2, 1]) torch.Size([8, 2001191, 2, 1]) None\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - model initialization done -> loss fn initialization\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:00:20 (running for 00:02:25.73)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m [ImageSpaceLoss] torch.Size([156, 156, 156, 2, 1]) torch.Size([156, 156, 156, 2, 1]) None\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - Loss k-space: 1.633 - Loss image space: 0.037 - Loss Wavelet 0.000 - Loss Hankel 0.000 - Loss Casorati 0.000\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - loss fn initialization done -> compute backward pass\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   warnings.warn(  # warn only once\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 12:00:25 (running for 00:02:30.75)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:00:30 (running for 00:02:35.77)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:00:35 (running for 00:02:40.79)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:00:40 (running for 00:02:45.81)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:00:45 (running for 00:02:50.83)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:00:50 (running for 00:02:55.84)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:00:55 (running for 00:03:00.87)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:01:00 (running for 00:03:05.88)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:01:05 (running for 00:03:10.90)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:01:10 (running for 00:03:15.92)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:01:15 (running for 00:03:20.94)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:01:20 (running for 00:03:25.96)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:01:26 (running for 00:03:30.98)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:01:31 (running for 00:03:36.00)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:01:36 (running for 00:03:41.02)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:01:41 (running for 00:03:46.03)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:01:46 (running for 00:03:51.05)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:01:51 (running for 00:03:56.07)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:01:56 (running for 00:04:01.09)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:02:01 (running for 00:04:06.11)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:02:06 (running for 00:04:11.13)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:02:11 (running for 00:04:16.15)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:02:16 (running for 00:04:21.17)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:02:21 (running for 00:04:26.19)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:02:26 (running for 00:04:31.21)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:02:31 (running for 00:04:36.22)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:02:36 (running for 00:04:41.25)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:02:41 (running for 00:04:46.26)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:02:46 (running for 00:04:51.29)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:02:51 (running for 00:04:56.30)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:02:56 (running for 00:05:01.32)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:03:01 (running for 00:05:06.34)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:03:06 (running for 00:05:11.36)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:03:11 (running for 00:05:16.38)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:03:16 (running for 00:05:21.40)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:03:21 (running for 00:05:26.42)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:03:26 (running for 00:05:31.44)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:03:31 (running for 00:05:36.46)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:03:36 (running for 00:05:41.48)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:03:41 (running for 00:05:46.49)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:03:46 (running for 00:05:51.52)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:03:51 (running for 00:05:56.53)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:03:56 (running for 00:06:01.55)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:04:01 (running for 00:06:06.57)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - compute backward pass done -> compute accumulator\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m [KSpaceLoss] torch.Size([8, 2001191, 2, 1]) torch.Size([8, 2001191, 2, 1]) None\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m [ImageSpaceLoss] torch.Size([156, 156, 156, 2, 1]) torch.Size([156, 156, 156, 2, 1]) None\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - Loss k-space: 1.586 - Loss image space: 0.037 - Loss Wavelet 0.000 - Loss Hankel 0.000 - Loss Casorati 0.000\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - loss fn initialization done -> compute backward pass\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/autograd/graph.py:824: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   warnings.warn(  # warn only once\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - Index 0 - Gradient norm: 5.496\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Averaged gradient norm: 1.000\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Iteration: 0 - Elapsed time: 353 - Training loss: ['1.646'] - Validation loss: ['0.000']\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:04:06 (running for 00:06:11.59)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:04:11 (running for 00:06:16.61)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - reading data\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - compute backward pass done -> compute accumulator\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - Index 0 - Gradient norm: 6.660\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - reading data done -> model initialization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/autograd/graph.py:824: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   warnings.warn(  # warn only once\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 12:04:16 (running for 00:06:21.64)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:04:21 (running for 00:06:26.66)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                   | 0/10 [00:00<?, ?it/s]\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m   warnings.warn(  # warn only once\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 12:04:26 (running for 00:06:31.68)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:04:31 (running for 00:06:36.70)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████▎                                      | 1/10 [00:10<01:33, 10.38s/it]\n",
      "  0%|                                                   | 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 12:04:36 (running for 00:06:41.72)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:04:41 (running for 00:06:46.73)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████▌                                  | 2/10 [00:20<01:23, 10.39s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 12:04:46 (running for 00:06:51.76)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:04:51 (running for 00:06:56.77)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|████████████▉                              | 3/10 [00:31<01:12, 10.39s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 12:04:56 (running for 00:07:01.80)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:05:01 (running for 00:07:06.81)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|█████████████████▏                         | 4/10 [00:41<01:02, 10.40s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 12:05:06 (running for 00:07:11.84)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:05:11 (running for 00:07:16.85)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████████████████████▌                     | 5/10 [00:51<00:52, 10.41s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 12:05:16 (running for 00:07:21.87)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:05:21 (running for 00:07:26.89)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████████████████████████▊                 | 6/10 [01:02<00:41, 10.41s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 12:05:26 (running for 00:07:31.91)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:05:31 (running for 00:07:36.93)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████████████████████████████             | 7/10 [01:12<00:31, 10.41s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 12:05:36 (running for 00:07:41.95)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:05:42 (running for 00:07:46.97)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|██████████████████████████████████▍        | 8/10 [01:23<00:20, 10.41s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 12:05:47 (running for 00:07:51.99)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:05:52 (running for 00:07:57.01)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|██████████████████████████████████████▋    | 9/10 [01:33<00:10, 10.41s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 12:05:57 (running for 00:08:02.03)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:06:02 (running for 00:08:07.05)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - model initialization done -> loss fn initialization\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - reading data\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - reading data done -> model initialization\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:06:07 (running for 00:08:12.16)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 10/10 [01:44<00:00, 10.41s/it]\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   warnings.warn(  # warn only once\n",
      " 90%|██████████████████████████████████████▋    | 9/10 [01:34<00:10, 10.45s/it]\n",
      "100%|██████████████████████████████████████████| 10/10 [01:44<00:00, 10.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 12:06:12 (running for 00:08:17.18)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m [KSpaceLoss] torch.Size([8, 2001191, 2, 1]) torch.Size([8, 2001191, 2, 1]) None\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - model initialization done -> loss fn initialization\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m [ImageSpaceLoss] torch.Size([156, 156, 156, 2, 1]) torch.Size([156, 156, 156, 2, 1]) None\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - Loss k-space: 1.658 - Loss image space: 0.035 - Loss Wavelet 0.000 - Loss Hankel 0.000 - Loss Casorati 0.000\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - loss fn initialization done -> compute backward pass\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   warnings.warn(  # warn only once\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 12:06:17 (running for 00:08:22.20)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:06:22 (running for 00:08:27.22)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:06:27 (running for 00:08:32.25)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:06:32 (running for 00:08:37.26)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:06:37 (running for 00:08:42.29)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:06:42 (running for 00:08:47.31)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:06:47 (running for 00:08:52.33)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:06:52 (running for 00:08:57.34)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:06:57 (running for 00:09:02.37)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:07:02 (running for 00:09:07.38)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:07:07 (running for 00:09:12.41)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:07:12 (running for 00:09:17.42)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:07:17 (running for 00:09:22.44)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:07:22 (running for 00:09:27.46)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:07:27 (running for 00:09:32.48)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:07:32 (running for 00:09:37.50)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:07:37 (running for 00:09:42.52)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:07:42 (running for 00:09:47.54)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:07:47 (running for 00:09:52.56)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:07:52 (running for 00:09:57.58)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:07:57 (running for 00:10:02.60)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:08:02 (running for 00:10:07.62)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:08:07 (running for 00:10:12.64)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:08:12 (running for 00:10:17.66)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:08:17 (running for 00:10:22.68)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:08:22 (running for 00:10:27.69)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:08:27 (running for 00:10:32.72)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:08:32 (running for 00:10:37.73)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:08:37 (running for 00:10:42.75)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:08:42 (running for 00:10:47.77)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:08:47 (running for 00:10:52.79)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:08:52 (running for 00:10:57.81)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:08:57 (running for 00:11:02.83)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:09:02 (running for 00:11:07.85)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:09:07 (running for 00:11:12.87)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:09:12 (running for 00:11:17.88)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:09:17 (running for 00:11:22.90)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:09:22 (running for 00:11:27.92)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:09:27 (running for 00:11:32.94)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:09:33 (running for 00:11:37.96)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:09:38 (running for 00:11:42.99)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:09:43 (running for 00:11:48.00)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:09:48 (running for 00:11:53.03)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:09:53 (running for 00:11:58.04)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - compute backward pass done -> compute accumulator\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m [KSpaceLoss] torch.Size([8, 2001191, 2, 1]) torch.Size([8, 2001191, 2, 1]) None\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m [ImageSpaceLoss] torch.Size([156, 156, 156, 2, 1]) torch.Size([156, 156, 156, 2, 1]) None\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - Loss k-space: 1.512 - Loss image space: 0.037 - Loss Wavelet 0.000 - Loss Hankel 0.000 - Loss Casorati 0.000\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - loss fn initialization done -> compute backward pass\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:09:58 (running for 00:12:03.07)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/autograd/graph.py:824: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   warnings.warn(  # warn only once\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - Index 0 - Gradient norm: 5.421\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Averaged gradient norm: 1.000\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Iteration: 1 - Elapsed time: 352 - Training loss: ['1.621'] - Validation loss: ['0.000']\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:10:03 (running for 00:12:08.09)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - reading data\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - compute backward pass done -> compute accumulator\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - Index 0 - Gradient norm: 6.748\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:10:08 (running for 00:12:13.12)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - reading data done -> model initialization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/autograd/graph.py:824: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   warnings.warn(  # warn only once\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 12:10:13 (running for 00:12:18.14)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                   | 0/10 [00:00<?, ?it/s]\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m   warnings.warn(  # warn only once\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 12:10:18 (running for 00:12:23.16)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:10:23 (running for 00:12:28.18)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████▎                                      | 1/10 [00:10<01:33, 10.41s/it]\n",
      "  0%|                                                   | 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 12:10:28 (running for 00:12:33.20)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:10:33 (running for 00:12:38.22)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████▌                                  | 2/10 [00:20<01:23, 10.42s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 12:10:38 (running for 00:12:43.24)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:10:43 (running for 00:12:48.26)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|████████████▉                              | 3/10 [00:31<01:12, 10.42s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 12:10:48 (running for 00:12:53.28)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:10:53 (running for 00:12:58.30)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|█████████████████▏                         | 4/10 [00:41<01:02, 10.42s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 12:10:58 (running for 00:13:03.32)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:11:03 (running for 00:13:08.34)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████████████████████▌                     | 5/10 [00:52<00:52, 10.42s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 12:11:08 (running for 00:13:13.36)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:11:13 (running for 00:13:18.38)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:11:18 (running for 00:13:23.40)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████████████████████████▊                 | 6/10 [01:02<00:41, 10.43s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 12:11:23 (running for 00:13:28.42)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:11:28 (running for 00:13:33.44)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████████████████████████████             | 7/10 [01:12<00:31, 10.43s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 12:11:33 (running for 00:13:38.46)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:11:38 (running for 00:13:43.48)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|██████████████████████████████████▍        | 8/10 [01:23<00:20, 10.43s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 12:11:43 (running for 00:13:48.50)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:11:48 (running for 00:13:53.52)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|██████████████████████████████████████▋    | 9/10 [01:33<00:10, 10.43s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 12:11:53 (running for 00:13:58.53)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:11:58 (running for 00:14:03.55)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - model initialization done -> loss fn initialization\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - reading data\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - reading data done -> model initialization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 10/10 [01:44<00:00, 10.43s/it]\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   warnings.warn(  # warn only once\n",
      " 90%|██████████████████████████████████████▋    | 9/10 [01:34<00:10, 10.48s/it]\n",
      "100%|██████████████████████████████████████████| 10/10 [01:44<00:00, 10.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 12:12:03 (running for 00:14:08.57)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m [KSpaceLoss] torch.Size([8, 2001191, 2, 1]) torch.Size([8, 2001191, 2, 1]) None\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - model initialization done -> loss fn initialization\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m [ImageSpaceLoss] torch.Size([156, 156, 156, 2, 1]) torch.Size([156, 156, 156, 2, 1]) None\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - Loss k-space: 1.619 - Loss image space: 0.037 - Loss Wavelet 0.000 - Loss Hankel 0.000 - Loss Casorati 0.000\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - loss fn initialization done -> compute backward pass\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:12:08 (running for 00:14:13.59)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   warnings.warn(  # warn only once\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 12:12:13 (running for 00:14:18.61)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:12:18 (running for 00:14:23.63)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:12:23 (running for 00:14:28.65)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:12:28 (running for 00:14:33.67)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:12:33 (running for 00:14:38.69)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:12:38 (running for 00:14:43.71)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:12:43 (running for 00:14:48.73)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:12:48 (running for 00:14:53.75)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:12:53 (running for 00:14:58.77)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:12:58 (running for 00:15:03.79)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:13:03 (running for 00:15:08.81)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:13:08 (running for 00:15:13.83)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:13:13 (running for 00:15:18.84)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:13:18 (running for 00:15:23.86)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:13:23 (running for 00:15:28.88)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:13:28 (running for 00:15:33.90)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:13:33 (running for 00:15:38.92)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:13:38 (running for 00:15:43.94)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:13:43 (running for 00:15:48.96)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:13:49 (running for 00:15:53.98)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:13:54 (running for 00:15:59.00)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:13:59 (running for 00:16:04.02)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:14:04 (running for 00:16:09.04)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:14:09 (running for 00:16:14.06)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:14:14 (running for 00:16:19.08)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:14:19 (running for 00:16:24.10)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:14:24 (running for 00:16:29.12)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:14:29 (running for 00:16:34.14)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:14:34 (running for 00:16:39.16)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:14:39 (running for 00:16:44.18)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:14:44 (running for 00:16:49.19)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:14:49 (running for 00:16:54.21)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:14:54 (running for 00:16:59.23)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:14:59 (running for 00:17:04.25)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:15:04 (running for 00:17:09.27)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:15:09 (running for 00:17:14.29)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:15:14 (running for 00:17:19.31)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:15:19 (running for 00:17:24.33)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:15:24 (running for 00:17:29.35)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:15:29 (running for 00:17:34.37)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:15:34 (running for 00:17:39.39)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:15:39 (running for 00:17:44.41)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:15:44 (running for 00:17:49.42)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:15:49 (running for 00:17:54.45)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - compute backward pass done -> compute accumulator\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m [KSpaceLoss] torch.Size([8, 2001191, 2, 1]) torch.Size([8, 2001191, 2, 1]) None\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m [ImageSpaceLoss] torch.Size([156, 156, 156, 2, 1]) torch.Size([156, 156, 156, 2, 1]) None\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - Loss k-space: 1.567 - Loss image space: 0.036 - Loss Wavelet 0.000 - Loss Hankel 0.000 - Loss Casorati 0.000\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - loss fn initialization done -> compute backward pass\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/autograd/graph.py:824: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   warnings.warn(  # warn only once\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - Index 0 - Gradient norm: 5.481\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Averaged gradient norm: 1.000\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Iteration: 2 - Elapsed time: 354 - Training loss: ['1.629'] - Validation loss: ['0.000']\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:15:54 (running for 00:17:59.46)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:15:59 (running for 00:18:04.49)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - reading data\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - compute backward pass done -> compute accumulator\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - Index 0 - Gradient norm: 6.684\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - reading data done -> model initialization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/autograd/graph.py:824: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   warnings.warn(  # warn only once\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 12:16:04 (running for 00:18:09.51)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                   | 0/10 [00:00<?, ?it/s]\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m   warnings.warn(  # warn only once\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 12:16:09 (running for 00:18:14.53)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:16:14 (running for 00:18:19.55)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:16:19 (running for 00:18:24.57)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████▎                                      | 1/10 [00:10<01:33, 10.39s/it]\n",
      "  0%|                                                   | 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 12:16:24 (running for 00:18:29.59)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:16:29 (running for 00:18:34.61)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████▌                                  | 2/10 [00:20<01:23, 10.41s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 12:16:34 (running for 00:18:39.62)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:16:39 (running for 00:18:44.65)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|████████████▉                              | 3/10 [00:31<01:12, 10.41s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 12:16:44 (running for 00:18:49.66)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:16:49 (running for 00:18:54.68)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|█████████████████▏                         | 4/10 [00:41<01:02, 10.41s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 12:16:54 (running for 00:18:59.70)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:16:59 (running for 00:19:04.72)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████████████████████▌                     | 5/10 [00:52<00:52, 10.42s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 12:17:04 (running for 00:19:09.74)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:17:09 (running for 00:19:14.76)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████████████████████████▊                 | 6/10 [01:02<00:41, 10.42s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 12:17:14 (running for 00:19:19.78)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:17:19 (running for 00:19:24.80)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████████████████████████████             | 7/10 [01:12<00:31, 10.43s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 12:17:24 (running for 00:19:29.82)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:17:29 (running for 00:19:34.84)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|██████████████████████████████████▍        | 8/10 [01:23<00:20, 10.44s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 12:17:34 (running for 00:19:39.86)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:17:39 (running for 00:19:44.88)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|██████████████████████████████████████▋    | 9/10 [01:33<00:10, 10.45s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 12:17:44 (running for 00:19:49.90)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:17:49 (running for 00:19:54.92)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - model initialization done -> loss fn initialization\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - reading data\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - reading data done -> model initialization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 10/10 [01:44<00:00, 10.43s/it]\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   warnings.warn(  # warn only once\n",
      " 90%|██████████████████████████████████████▋    | 9/10 [01:34<00:10, 10.48s/it]\n",
      "100%|██████████████████████████████████████████| 10/10 [01:44<00:00, 10.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 12:17:54 (running for 00:19:59.94)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:18:00 (running for 00:20:04.96)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m [KSpaceLoss] torch.Size([8, 2001191, 2, 1]) torch.Size([8, 2001191, 2, 1]) None\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - model initialization done -> loss fn initialization\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m [ImageSpaceLoss] torch.Size([156, 156, 156, 2, 1]) torch.Size([156, 156, 156, 2, 1]) None\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - Loss k-space: 1.714 - Loss image space: 0.035 - Loss Wavelet 0.000 - Loss Hankel 0.000 - Loss Casorati 0.000\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - loss fn initialization done -> compute backward pass\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   warnings.warn(  # warn only once\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 12:18:05 (running for 00:20:09.99)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:18:10 (running for 00:20:15.02)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:18:15 (running for 00:20:20.04)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:18:20 (running for 00:20:25.06)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:18:25 (running for 00:20:30.08)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:18:30 (running for 00:20:35.10)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:18:35 (running for 00:20:40.12)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:18:40 (running for 00:20:45.14)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:18:45 (running for 00:20:50.15)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:18:50 (running for 00:20:55.18)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:18:55 (running for 00:21:00.19)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:19:00 (running for 00:21:05.22)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:19:05 (running for 00:21:10.23)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:19:10 (running for 00:21:15.26)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:19:15 (running for 00:21:20.27)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:19:20 (running for 00:21:25.29)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:19:25 (running for 00:21:30.31)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:19:30 (running for 00:21:35.33)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:19:35 (running for 00:21:40.35)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:19:40 (running for 00:21:45.37)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:19:45 (running for 00:21:50.39)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:19:50 (running for 00:21:55.41)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:19:55 (running for 00:22:00.43)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:20:00 (running for 00:22:05.45)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:20:05 (running for 00:22:10.46)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:20:10 (running for 00:22:15.48)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:20:15 (running for 00:22:20.50)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:20:20 (running for 00:22:25.52)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:20:25 (running for 00:22:30.54)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:20:30 (running for 00:22:35.56)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:20:35 (running for 00:22:40.58)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:20:40 (running for 00:22:45.60)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:20:45 (running for 00:22:50.62)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:20:50 (running for 00:22:55.64)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:20:55 (running for 00:23:00.66)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:21:00 (running for 00:23:05.68)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:21:05 (running for 00:23:10.70)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:21:10 (running for 00:23:15.72)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:21:15 (running for 00:23:20.74)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:21:20 (running for 00:23:25.76)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:21:25 (running for 00:23:30.77)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:21:30 (running for 00:23:35.80)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:21:35 (running for 00:23:40.81)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:21:40 (running for 00:23:45.83)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - compute backward pass done -> compute accumulator\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m [KSpaceLoss] torch.Size([8, 2001191, 2, 1]) torch.Size([8, 2001191, 2, 1]) None\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m [ImageSpaceLoss] torch.Size([156, 156, 156, 2, 1]) torch.Size([156, 156, 156, 2, 1]) None\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - Loss k-space: 1.478 - Loss image space: 0.038 - Loss Wavelet 0.000 - Loss Hankel 0.000 - Loss Casorati 0.000\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - loss fn initialization done -> compute backward pass\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/autograd/graph.py:824: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   warnings.warn(  # warn only once\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 12:21:45 (running for 00:23:50.85)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - Index 0 - Gradient norm: 5.272\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Averaged gradient norm: 1.000\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Iteration: 3 - Elapsed time: 353 - Training loss: ['1.633'] - Validation loss: ['0.000']\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:21:50 (running for 00:23:55.88)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - reading data\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - compute backward pass done -> compute accumulator\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - Index 0 - Gradient norm: 6.964\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - reading data done -> model initialization\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:21:55 (running for 00:24:00.90)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/autograd/graph.py:824: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   warnings.warn(  # warn only once\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 12:22:00 (running for 00:24:05.92)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                   | 0/10 [00:00<?, ?it/s]\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m   warnings.warn(  # warn only once\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 12:22:05 (running for 00:24:10.94)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:22:10 (running for 00:24:15.96)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████▎                                      | 1/10 [00:10<01:33, 10.41s/it]\n",
      "  0%|                                                   | 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 12:22:16 (running for 00:24:20.98)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:22:21 (running for 00:24:26.00)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████▌                                  | 2/10 [00:20<01:23, 10.41s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 12:22:26 (running for 00:24:31.02)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:22:31 (running for 00:24:36.04)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|████████████▉                              | 3/10 [00:31<01:12, 10.42s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 12:22:36 (running for 00:24:41.06)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:22:41 (running for 00:24:46.08)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|█████████████████▏                         | 4/10 [00:41<01:02, 10.42s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 12:22:46 (running for 00:24:51.10)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:22:51 (running for 00:24:56.12)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████████████████████▌                     | 5/10 [00:52<00:52, 10.42s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 12:22:56 (running for 00:25:01.14)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:23:01 (running for 00:25:06.16)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████████████████████████▊                 | 6/10 [01:02<00:41, 10.43s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 12:23:06 (running for 00:25:11.18)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:23:11 (running for 00:25:16.20)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████████████████████████████             | 7/10 [01:12<00:31, 10.44s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 12:23:16 (running for 00:25:21.22)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:23:21 (running for 00:25:26.24)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:23:26 (running for 00:25:31.26)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|██████████████████████████████████▍        | 8/10 [01:23<00:20, 10.44s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 12:23:31 (running for 00:25:36.28)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:23:36 (running for 00:25:41.30)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|██████████████████████████████████████▋    | 9/10 [01:33<00:10, 10.44s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 12:23:41 (running for 00:25:46.32)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:23:46 (running for 00:25:51.34)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - model initialization done -> loss fn initialization\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - reading data\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - reading data done -> model initialization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 10/10 [01:44<00:00, 10.43s/it]\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   warnings.warn(  # warn only once\n",
      " 90%|██████████████████████████████████████▋    | 9/10 [01:34<00:10, 10.48s/it]\n",
      "100%|██████████████████████████████████████████| 10/10 [01:44<00:00, 10.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 12:23:51 (running for 00:25:56.36)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m [KSpaceLoss] torch.Size([8, 2001191, 2, 1]) torch.Size([8, 2001191, 2, 1]) None\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - model initialization done -> loss fn initialization\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m [ImageSpaceLoss] torch.Size([156, 156, 156, 2, 1]) torch.Size([156, 156, 156, 2, 1]) None\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - Loss k-space: 1.585 - Loss image space: 0.036 - Loss Wavelet 0.000 - Loss Hankel 0.000 - Loss Casorati 0.000\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - loss fn initialization done -> compute backward pass\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   warnings.warn(  # warn only once\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 12:23:56 (running for 00:26:01.38)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:24:01 (running for 00:26:06.40)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:24:06 (running for 00:26:11.42)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:24:11 (running for 00:26:16.44)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:24:16 (running for 00:26:21.46)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:24:21 (running for 00:26:26.48)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:24:26 (running for 00:26:31.50)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:24:31 (running for 00:26:36.53)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:24:36 (running for 00:26:41.54)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:24:41 (running for 00:26:46.57)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:24:46 (running for 00:26:51.58)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:24:51 (running for 00:26:56.61)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:24:56 (running for 00:27:01.63)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:25:01 (running for 00:27:06.65)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:25:06 (running for 00:27:11.67)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:25:11 (running for 00:27:16.69)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:25:16 (running for 00:27:21.71)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:25:21 (running for 00:27:26.73)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:25:26 (running for 00:27:31.75)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:25:31 (running for 00:27:36.77)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:25:36 (running for 00:27:41.79)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:25:41 (running for 00:27:46.81)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:25:46 (running for 00:27:51.83)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:25:51 (running for 00:27:56.85)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:25:56 (running for 00:28:01.87)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:26:01 (running for 00:28:06.90)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:26:06 (running for 00:28:11.92)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:26:11 (running for 00:28:16.94)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:26:16 (running for 00:28:21.96)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:26:22 (running for 00:28:26.98)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:26:27 (running for 00:28:32.00)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:26:32 (running for 00:28:37.02)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:26:37 (running for 00:28:42.04)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:26:42 (running for 00:28:47.06)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:26:47 (running for 00:28:52.08)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:26:52 (running for 00:28:57.11)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:26:57 (running for 00:29:02.12)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:27:02 (running for 00:29:07.15)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:27:07 (running for 00:29:12.17)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:27:12 (running for 00:29:17.19)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:27:17 (running for 00:29:22.21)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:27:22 (running for 00:29:27.23)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:27:27 (running for 00:29:32.25)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:27:32 (running for 00:29:37.27)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:27:37 (running for 00:29:42.29)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - compute backward pass done -> compute accumulator\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m [KSpaceLoss] torch.Size([8, 2001191, 2, 1]) torch.Size([8, 2001191, 2, 1]) None\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m [ImageSpaceLoss] torch.Size([156, 156, 156, 2, 1]) torch.Size([156, 156, 156, 2, 1]) None\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - Loss k-space: 1.575 - Loss image space: 0.035 - Loss Wavelet 0.000 - Loss Hankel 0.000 - Loss Casorati 0.000\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - loss fn initialization done -> compute backward pass\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/autograd/graph.py:824: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   warnings.warn(  # warn only once\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - Index 0 - Gradient norm: 5.376\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Averaged gradient norm: 1.000\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Creating untagged checkpoint ...\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m 2025-09-29 12:27:39 Schedule checkpoint save with tag:  ...\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m 2025-09-29 12:27:39 Saved checkpoint to buffer 0.0 seconds\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Iteration: 4 - Elapsed time: 353 - Training loss: ['1.616'] - Validation loss: ['0.000']\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m 2025-09-29 12:27:39 Saved buffer to filesystem in 0.0 seconds\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m 2025-09-29 12:27:39 Completed saving checkpoint.\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:27:42 (running for 00:29:47.31)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:27:47 (running for 00:29:52.34)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - reading data\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - reading data done -> model initialization\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - compute backward pass done -> compute accumulator\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - Index 0 - Gradient norm: 6.548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/autograd/graph.py:824: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   warnings.warn(  # warn only once\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 12:27:52 (running for 00:29:57.36)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:27:57 (running for 00:30:02.38)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                   | 0/10 [00:00<?, ?it/s]\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m   warnings.warn(  # warn only once\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 12:28:02 (running for 00:30:07.40)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:28:07 (running for 00:30:12.42)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████▎                                      | 1/10 [00:10<01:33, 10.42s/it]\n",
      "  0%|                                                   | 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 12:28:12 (running for 00:30:17.44)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:28:17 (running for 00:30:22.46)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████▌                                  | 2/10 [00:20<01:23, 10.41s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 12:28:22 (running for 00:30:27.48)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:28:27 (running for 00:30:32.50)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|████████████▉                              | 3/10 [00:31<01:12, 10.42s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 12:28:32 (running for 00:30:37.52)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:28:37 (running for 00:30:42.53)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|█████████████████▏                         | 4/10 [00:41<01:02, 10.42s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 12:28:42 (running for 00:30:47.55)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:28:47 (running for 00:30:52.57)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████████████████████▌                     | 5/10 [00:52<00:52, 10.43s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 12:28:52 (running for 00:30:57.59)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:28:57 (running for 00:31:02.61)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████████████████████████▊                 | 6/10 [01:02<00:41, 10.43s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 12:29:02 (running for 00:31:07.63)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:29:07 (running for 00:31:12.65)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:29:12 (running for 00:31:17.68)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████████████████████████████             | 7/10 [01:12<00:31, 10.43s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 12:29:17 (running for 00:31:22.69)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:29:22 (running for 00:31:27.72)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|██████████████████████████████████▍        | 8/10 [01:23<00:20, 10.43s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 12:29:27 (running for 00:31:32.73)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:29:32 (running for 00:31:37.75)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|██████████████████████████████████████▋    | 9/10 [01:33<00:10, 10.43s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 12:29:37 (running for 00:31:42.77)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:29:42 (running for 00:31:47.80)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - model initialization done -> loss fn initialization\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - reading data\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - reading data done -> model initialization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 10/10 [01:44<00:00, 10.43s/it]\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   warnings.warn(  # warn only once\n",
      " 90%|██████████████████████████████████████▋    | 9/10 [01:34<00:10, 10.48s/it]\n",
      "100%|██████████████████████████████████████████| 10/10 [01:44<00:00, 10.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 12:29:47 (running for 00:31:52.81)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m [KSpaceLoss] torch.Size([8, 2001191, 2, 1]) torch.Size([8, 2001191, 2, 1]) None\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - model initialization done -> loss fn initialization\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m [ImageSpaceLoss] torch.Size([156, 156, 156, 2, 1]) torch.Size([156, 156, 156, 2, 1]) None\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - Loss k-space: 1.675 - Loss image space: 0.036 - Loss Wavelet 0.000 - Loss Hankel 0.000 - Loss Casorati 0.000\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - loss fn initialization done -> compute backward pass\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   warnings.warn(  # warn only once\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 12:29:52 (running for 00:31:57.84)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:29:57 (running for 00:32:02.85)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:30:02 (running for 00:32:07.88)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:30:07 (running for 00:32:12.90)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:30:12 (running for 00:32:17.92)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:30:17 (running for 00:32:22.94)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:30:22 (running for 00:32:27.96)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:30:28 (running for 00:32:32.98)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:30:33 (running for 00:32:38.00)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:30:38 (running for 00:32:43.02)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:30:43 (running for 00:32:48.04)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:30:48 (running for 00:32:53.06)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:30:53 (running for 00:32:58.08)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:30:58 (running for 00:33:03.10)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:31:03 (running for 00:33:08.12)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:31:08 (running for 00:33:13.14)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:31:13 (running for 00:33:18.16)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:31:18 (running for 00:33:23.18)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:31:23 (running for 00:33:28.20)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:31:28 (running for 00:33:33.22)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:31:33 (running for 00:33:38.24)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:31:38 (running for 00:33:43.26)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:31:43 (running for 00:33:48.28)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:31:48 (running for 00:33:53.29)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:31:53 (running for 00:33:58.32)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:31:58 (running for 00:34:03.33)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:32:03 (running for 00:34:08.36)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:32:08 (running for 00:34:13.37)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:32:13 (running for 00:34:18.40)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:32:18 (running for 00:34:23.41)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:32:23 (running for 00:34:28.44)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:32:28 (running for 00:34:33.45)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:32:33 (running for 00:34:38.48)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:32:38 (running for 00:34:43.49)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:32:43 (running for 00:34:48.51)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:32:48 (running for 00:34:53.53)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:32:53 (running for 00:34:58.55)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:32:58 (running for 00:35:03.57)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:33:03 (running for 00:35:08.59)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:33:08 (running for 00:35:13.61)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:33:13 (running for 00:35:18.63)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:33:18 (running for 00:35:23.65)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:33:23 (running for 00:35:28.67)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:33:28 (running for 00:35:33.71)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:33:33 (running for 00:35:38.73)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - compute backward pass done -> compute accumulator\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m [KSpaceLoss] torch.Size([8, 2001191, 2, 1]) torch.Size([8, 2001191, 2, 1]) None\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m [ImageSpaceLoss] torch.Size([156, 156, 156, 2, 1]) torch.Size([156, 156, 156, 2, 1]) None\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - Loss k-space: 1.526 - Loss image space: 0.038 - Loss Wavelet 0.000 - Loss Hankel 0.000 - Loss Casorati 0.000\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - loss fn initialization done -> compute backward pass\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/autograd/graph.py:824: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   warnings.warn(  # warn only once\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - Index 0 - Gradient norm: 5.324\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Averaged gradient norm: 1.000\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Iteration: 5 - Elapsed time: 357 - Training loss: ['1.637'] - Validation loss: ['0.000']\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:33:38 (running for 00:35:43.75)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:33:43 (running for 00:35:48.78)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - reading data\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - compute backward pass done -> compute accumulator\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - Index 0 - Gradient norm: 6.551\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - reading data done -> model initialization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/autograd/graph.py:824: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   warnings.warn(  # warn only once\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 12:33:48 (running for 00:35:53.80)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:33:53 (running for 00:35:58.83)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                   | 0/10 [00:00<?, ?it/s]\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m   warnings.warn(  # warn only once\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 12:33:58 (running for 00:36:03.85)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:34:03 (running for 00:36:08.87)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████▎                                      | 1/10 [00:10<01:33, 10.42s/it]\n",
      "  0%|                                                   | 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 12:34:08 (running for 00:36:13.89)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:34:13 (running for 00:36:18.91)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████▌                                  | 2/10 [00:20<01:23, 10.42s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 12:34:18 (running for 00:36:23.93)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:34:23 (running for 00:36:28.95)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|████████████▉                              | 3/10 [00:31<01:12, 10.42s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 12:34:29 (running for 00:36:33.96)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:34:34 (running for 00:36:38.98)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|█████████████████▏                         | 4/10 [00:41<01:02, 10.43s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 12:34:39 (running for 00:36:44.00)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:34:44 (running for 00:36:49.02)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████████████████████▌                     | 5/10 [00:52<00:52, 10.43s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 12:34:49 (running for 00:36:54.04)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:34:54 (running for 00:36:59.06)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████████████████████████▊                 | 6/10 [01:02<00:41, 10.43s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 12:34:59 (running for 00:37:04.08)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:35:04 (running for 00:37:09.10)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████████████████████████████             | 7/10 [01:12<00:31, 10.43s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 12:35:09 (running for 00:37:14.12)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:35:14 (running for 00:37:19.14)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|██████████████████████████████████▍        | 8/10 [01:23<00:20, 10.43s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 12:35:19 (running for 00:37:24.16)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:35:24 (running for 00:37:29.18)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|██████████████████████████████████████▋    | 9/10 [01:33<00:10, 10.44s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 12:35:29 (running for 00:37:34.20)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:35:34 (running for 00:37:39.22)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - model initialization done -> loss fn initialization\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - reading data\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - reading data done -> model initialization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 10/10 [01:44<00:00, 10.44s/it]\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   warnings.warn(  # warn only once\n",
      " 90%|██████████████████████████████████████▋    | 9/10 [01:34<00:10, 10.49s/it]\n",
      "100%|██████████████████████████████████████████| 10/10 [01:44<00:00, 10.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 12:35:39 (running for 00:37:44.24)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:35:44 (running for 00:37:49.27)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:35:49 (running for 00:37:54.29)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m [KSpaceLoss] torch.Size([8, 2001191, 2, 1]) torch.Size([8, 2001191, 2, 1]) None\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - model initialization done -> loss fn initialization\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m [ImageSpaceLoss] torch.Size([156, 156, 156, 2, 1]) torch.Size([156, 156, 156, 2, 1]) None\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - Loss k-space: 1.628 - Loss image space: 0.036 - Loss Wavelet 0.000 - Loss Hankel 0.000 - Loss Casorati 0.000\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - loss fn initialization done -> compute backward pass\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   warnings.warn(  # warn only once\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 12:35:54 (running for 00:37:59.32)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:35:59 (running for 00:38:04.34)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:36:04 (running for 00:38:09.36)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:36:09 (running for 00:38:14.38)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:36:14 (running for 00:38:19.40)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:36:19 (running for 00:38:24.41)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:36:24 (running for 00:38:29.44)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:36:29 (running for 00:38:34.45)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:36:34 (running for 00:38:39.47)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:36:39 (running for 00:38:44.49)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:36:44 (running for 00:38:49.51)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:36:49 (running for 00:38:54.53)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:36:54 (running for 00:38:59.55)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:36:59 (running for 00:39:04.57)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:37:04 (running for 00:39:09.59)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:37:09 (running for 00:39:14.61)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:37:14 (running for 00:39:19.63)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:37:19 (running for 00:39:24.64)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:37:24 (running for 00:39:29.66)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:37:29 (running for 00:39:34.68)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:37:34 (running for 00:39:39.70)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:37:39 (running for 00:39:44.72)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:37:44 (running for 00:39:49.74)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:37:49 (running for 00:39:54.76)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:37:54 (running for 00:39:59.79)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:37:59 (running for 00:40:04.80)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:38:04 (running for 00:40:09.83)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:38:09 (running for 00:40:14.85)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:38:14 (running for 00:40:19.87)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:38:19 (running for 00:40:24.88)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:38:24 (running for 00:40:29.91)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:38:29 (running for 00:40:34.92)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:38:34 (running for 00:40:39.94)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:38:40 (running for 00:40:44.96)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:38:45 (running for 00:40:49.98)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:38:50 (running for 00:40:55.00)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:38:55 (running for 00:41:00.03)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:39:00 (running for 00:41:05.05)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:39:05 (running for 00:41:10.36)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:39:10 (running for 00:41:15.38)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:39:15 (running for 00:41:20.40)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:39:20 (running for 00:41:25.42)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:39:25 (running for 00:41:30.44)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:39:30 (running for 00:41:35.46)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:39:35 (running for 00:41:40.49)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - compute backward pass done -> compute accumulator\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m [KSpaceLoss] torch.Size([8, 2001191, 2, 1]) torch.Size([8, 2001191, 2, 1]) None\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m [ImageSpaceLoss] torch.Size([156, 156, 156, 2, 1]) torch.Size([156, 156, 156, 2, 1]) None\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - Loss k-space: 1.576 - Loss image space: 0.036 - Loss Wavelet 0.000 - Loss Hankel 0.000 - Loss Casorati 0.000\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - loss fn initialization done -> compute backward pass\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/autograd/graph.py:824: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m   warnings.warn(  # warn only once\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - Index 0 - Gradient norm: 5.422\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Averaged gradient norm: 1.000\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Iteration: 6 - Elapsed time: 361 - Training loss: ['1.638'] - Validation loss: ['0.000']\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:39:40 (running for 00:41:45.51)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:39:45 (running for 00:41:50.53)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - reading data\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - compute backward pass done -> compute accumulator\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - Index 0 - Gradient norm: 6.310\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - reading data done -> model initialization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/autograd/graph.py:824: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   warnings.warn(  # warn only once\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 12:39:50 (running for 00:41:55.55)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                   | 0/10 [00:00<?, ?it/s]\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m   warnings.warn(  # warn only once\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 12:39:55 (running for 00:42:00.58)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:40:00 (running for 00:42:05.59)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████▎                                      | 1/10 [00:10<01:33, 10.42s/it]\n",
      "  0%|                                                   | 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 12:40:05 (running for 00:42:10.62)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:40:10 (running for 00:42:15.63)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:40:15 (running for 00:42:20.66)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████▌                                  | 2/10 [00:20<01:23, 10.43s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 12:40:20 (running for 00:42:25.67)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:40:25 (running for 00:42:30.70)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|████████████▉                              | 3/10 [00:31<01:12, 10.42s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 12:40:30 (running for 00:42:35.71)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:40:35 (running for 00:42:40.74)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|█████████████████▏                         | 4/10 [00:41<01:02, 10.42s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 12:40:40 (running for 00:42:45.75)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:40:45 (running for 00:42:50.78)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████████████████████▌                     | 5/10 [00:52<00:52, 10.42s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 12:40:50 (running for 00:42:55.80)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:40:55 (running for 00:43:00.82)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████████████████████████▊                 | 6/10 [01:02<00:41, 10.43s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 12:41:00 (running for 00:43:05.84)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:41:05 (running for 00:43:10.86)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████████████████████████████             | 7/10 [01:13<00:31, 10.44s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 12:41:10 (running for 00:43:15.88)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:41:15 (running for 00:43:20.90)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|██████████████████████████████████▍        | 8/10 [01:23<00:20, 10.44s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 12:41:20 (running for 00:43:25.92)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:41:25 (running for 00:43:30.94)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|██████████████████████████████████████▋    | 9/10 [01:33<00:10, 10.44s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 12:41:31 (running for 00:43:35.96)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:41:36 (running for 00:43:40.98)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - model initialization done -> loss fn initialization\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - reading data\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - reading data done -> model initialization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 10/10 [01:44<00:00, 10.44s/it]\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   warnings.warn(  # warn only once\n",
      " 90%|██████████████████████████████████████▋    | 9/10 [01:34<00:10, 10.48s/it]\n",
      "100%|██████████████████████████████████████████| 10/10 [01:44<00:00, 10.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 12:41:41 (running for 00:43:46.00)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:41:46 (running for 00:43:51.02)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m [KSpaceLoss] torch.Size([8, 2001191, 2, 1]) torch.Size([8, 2001191, 2, 1]) None\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - model initialization done -> loss fn initialization\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m [ImageSpaceLoss] torch.Size([156, 156, 156, 2, 1]) torch.Size([156, 156, 156, 2, 1]) None\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - Loss k-space: 1.642 - Loss image space: 0.036 - Loss Wavelet 0.000 - Loss Hankel 0.000 - Loss Casorati 0.000\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - loss fn initialization done -> compute backward pass\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   warnings.warn(  # warn only once\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 12:41:51 (running for 00:43:56.05)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:41:56 (running for 00:44:01.07)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:42:01 (running for 00:44:06.10)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:42:06 (running for 00:44:11.12)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:42:11 (running for 00:44:16.14)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:42:16 (running for 00:44:21.16)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:42:21 (running for 00:44:26.18)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:42:26 (running for 00:44:31.20)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:42:31 (running for 00:44:36.22)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:42:36 (running for 00:44:41.24)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:42:41 (running for 00:44:46.26)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:42:46 (running for 00:44:51.28)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:42:51 (running for 00:44:56.30)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:42:56 (running for 00:45:01.32)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:43:01 (running for 00:45:06.34)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:43:06 (running for 00:45:11.36)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:43:11 (running for 00:45:16.38)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:43:16 (running for 00:45:21.40)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:43:21 (running for 00:45:26.42)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:43:26 (running for 00:45:31.44)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:43:31 (running for 00:45:36.45)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:43:36 (running for 00:45:41.47)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:43:41 (running for 00:45:46.49)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:43:46 (running for 00:45:51.51)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:43:51 (running for 00:45:56.53)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:43:56 (running for 00:46:01.55)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:44:01 (running for 00:46:06.56)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:44:06 (running for 00:46:11.58)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:44:11 (running for 00:46:16.60)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:44:16 (running for 00:46:21.62)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:44:21 (running for 00:46:26.64)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:44:26 (running for 00:46:31.66)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:44:31 (running for 00:46:36.68)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:44:36 (running for 00:46:41.70)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:44:41 (running for 00:46:46.72)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:44:46 (running for 00:46:51.75)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:44:51 (running for 00:46:56.77)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:44:56 (running for 00:47:01.79)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:45:01 (running for 00:47:06.81)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:45:06 (running for 00:47:11.83)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:45:11 (running for 00:47:16.85)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:45:16 (running for 00:47:21.88)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:45:21 (running for 00:47:26.90)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:45:26 (running for 00:47:31.93)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:45:31 (running for 00:47:36.95)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:45:37 (running for 00:47:41.97)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - compute backward pass done -> compute accumulator\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m [KSpaceLoss] torch.Size([8, 2001191, 2, 1]) torch.Size([8, 2001191, 2, 1]) None\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m [ImageSpaceLoss] torch.Size([156, 156, 156, 2, 1]) torch.Size([156, 156, 156, 2, 1]) None\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - Loss k-space: 1.551 - Loss image space: 0.036 - Loss Wavelet 0.000 - Loss Hankel 0.000 - Loss Casorati 0.000\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - loss fn initialization done -> compute backward pass\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/autograd/graph.py:824: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m   warnings.warn(  # warn only once\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - Index 0 - Gradient norm: 5.224\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Averaged gradient norm: 1.000\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Iteration: 7 - Elapsed time: 362 - Training loss: ['1.632'] - Validation loss: ['0.000']\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:45:42 (running for 00:47:46.99)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:45:47 (running for 00:47:52.02)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - reading data\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - compute backward pass done -> compute accumulator\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - Index 0 - Gradient norm: 6.046\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - reading data done -> model initialization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/autograd/graph.py:824: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   warnings.warn(  # warn only once\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 12:45:52 (running for 00:47:57.04)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                   | 0/10 [00:00<?, ?it/s]\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m   warnings.warn(  # warn only once\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 12:45:57 (running for 00:48:02.06)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:46:02 (running for 00:48:07.08)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:46:07 (running for 00:48:12.10)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████▎                                      | 1/10 [00:10<01:33, 10.42s/it]\n",
      "  0%|                                                   | 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 12:46:12 (running for 00:48:17.12)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:46:17 (running for 00:48:22.14)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████▌                                  | 2/10 [00:20<01:23, 10.42s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 12:46:22 (running for 00:48:27.16)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:46:27 (running for 00:48:32.18)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|████████████▉                              | 3/10 [00:31<01:12, 10.42s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 12:46:32 (running for 00:48:37.20)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:46:37 (running for 00:48:42.22)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|█████████████████▏                         | 4/10 [00:41<01:02, 10.42s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 12:46:42 (running for 00:48:47.24)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:46:47 (running for 00:48:52.26)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████████████████████▌                     | 5/10 [00:52<00:52, 10.42s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 12:46:52 (running for 00:48:57.27)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:46:57 (running for 00:49:02.29)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████████████████████████▊                 | 6/10 [01:02<00:41, 10.43s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 12:47:02 (running for 00:49:07.31)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:47:07 (running for 00:49:12.33)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████████████████████████████             | 7/10 [01:12<00:31, 10.43s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 12:47:12 (running for 00:49:17.35)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:47:17 (running for 00:49:22.37)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|██████████████████████████████████▍        | 8/10 [01:23<00:20, 10.43s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 12:47:22 (running for 00:49:27.39)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:47:27 (running for 00:49:32.41)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|██████████████████████████████████████▋    | 9/10 [01:33<00:10, 10.44s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 12:47:32 (running for 00:49:37.43)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:47:37 (running for 00:49:42.45)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - model initialization done -> loss fn initialization\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - reading data\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - reading data done -> model initialization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 10/10 [01:44<00:00, 10.43s/it]\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   warnings.warn(  # warn only once\n",
      " 90%|██████████████████████████████████████▋    | 9/10 [01:34<00:10, 10.48s/it]\n",
      "100%|██████████████████████████████████████████| 10/10 [01:44<00:00, 10.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 12:47:42 (running for 00:49:47.47)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:47:47 (running for 00:49:52.49)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m [KSpaceLoss] torch.Size([8, 2001191, 2, 1]) torch.Size([8, 2001191, 2, 1]) None\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - model initialization done -> loss fn initialization\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m [ImageSpaceLoss] torch.Size([156, 156, 156, 2, 1]) torch.Size([156, 156, 156, 2, 1]) None\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - Loss k-space: 1.627 - Loss image space: 0.037 - Loss Wavelet 0.000 - Loss Hankel 0.000 - Loss Casorati 0.000\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - loss fn initialization done -> compute backward pass\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   warnings.warn(  # warn only once\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 12:47:52 (running for 00:49:57.52)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:47:57 (running for 00:50:02.54)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:48:02 (running for 00:50:07.56)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:48:07 (running for 00:50:12.58)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:48:12 (running for 00:50:17.60)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:48:17 (running for 00:50:22.61)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:48:22 (running for 00:50:27.63)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:48:27 (running for 00:50:32.65)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:48:32 (running for 00:50:37.66)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:48:37 (running for 00:50:42.68)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:48:42 (running for 00:50:47.70)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:48:47 (running for 00:50:52.72)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:48:52 (running for 00:50:57.74)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:48:57 (running for 00:51:02.76)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:49:02 (running for 00:51:07.78)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:49:07 (running for 00:51:12.80)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:49:12 (running for 00:51:17.81)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:49:17 (running for 00:51:22.84)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:49:22 (running for 00:51:27.85)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:49:27 (running for 00:51:32.87)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:49:32 (running for 00:51:37.89)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:49:37 (running for 00:51:42.91)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:49:42 (running for 00:51:47.93)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:49:47 (running for 00:51:52.95)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:49:53 (running for 00:51:57.97)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:49:58 (running for 00:52:02.99)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:50:03 (running for 00:52:08.01)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:50:08 (running for 00:52:13.03)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:50:13 (running for 00:52:18.05)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:50:18 (running for 00:52:23.07)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:50:23 (running for 00:52:28.09)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:50:28 (running for 00:52:33.11)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:50:33 (running for 00:52:38.13)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:50:38 (running for 00:52:43.15)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:50:43 (running for 00:52:48.16)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:50:48 (running for 00:52:53.19)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:50:53 (running for 00:52:58.20)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:50:58 (running for 00:53:03.34)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:51:03 (running for 00:53:08.35)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:51:08 (running for 00:53:13.38)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:51:13 (running for 00:53:18.39)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:51:18 (running for 00:53:23.42)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:51:23 (running for 00:53:28.43)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:51:28 (running for 00:53:33.46)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:51:33 (running for 00:53:38.47)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - compute backward pass done -> compute accumulator\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m [KSpaceLoss] torch.Size([8, 2001191, 2, 1]) torch.Size([8, 2001191, 2, 1]) None\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m [ImageSpaceLoss] torch.Size([156, 156, 156, 2, 1]) torch.Size([156, 156, 156, 2, 1]) None\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - Loss k-space: 1.582 - Loss image space: 0.036 - Loss Wavelet 0.000 - Loss Hankel 0.000 - Loss Casorati 0.000\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - loss fn initialization done -> compute backward pass\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/autograd/graph.py:824: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   warnings.warn(  # warn only once\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 12:51:38 (running for 00:53:43.49)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - Index 0 - Gradient norm: 5.269\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - compute backward pass done -> compute accumulator\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Averaged gradient norm: 1.000\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Iteration: 8 - Elapsed time: 360 - Training loss: ['1.641'] - Validation loss: ['0.000']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/autograd/graph.py:824: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m   warnings.warn(  # warn only once\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 12:51:43 (running for 00:53:48.51)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - reading data\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - Index 0 - Gradient norm: 6.122\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:51:48 (running for 00:53:53.54)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - reading data done -> model initialization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   warnings.warn(  # warn only once\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 12:51:53 (running for 00:53:58.56)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                   | 0/10 [00:00<?, ?it/s]\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m   warnings.warn(  # warn only once\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 12:51:58 (running for 00:54:03.58)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:52:03 (running for 00:54:08.60)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████▎                                      | 1/10 [00:10<01:33, 10.38s/it]\n",
      "  0%|                                                   | 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 12:52:08 (running for 00:54:13.62)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:52:13 (running for 00:54:18.63)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████▌                                  | 2/10 [00:20<01:23, 10.40s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 12:52:18 (running for 00:54:23.66)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:52:23 (running for 00:54:28.67)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|████████████▉                              | 3/10 [00:31<01:12, 10.41s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 12:52:28 (running for 00:54:33.69)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:52:33 (running for 00:54:38.71)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|█████████████████▏                         | 4/10 [00:41<01:02, 10.42s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 12:52:38 (running for 00:54:43.73)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:52:43 (running for 00:54:48.75)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:52:48 (running for 00:54:53.77)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████████████████████▌                     | 5/10 [00:52<00:52, 10.42s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 12:52:53 (running for 00:54:58.78)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:52:58 (running for 00:55:03.80)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████████████████████████▊                 | 6/10 [01:02<00:41, 10.42s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 12:53:03 (running for 00:55:08.82)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:53:08 (running for 00:55:13.84)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████████████████████████████             | 7/10 [01:12<00:31, 10.42s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 12:53:13 (running for 00:55:18.86)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:53:18 (running for 00:55:23.88)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|██████████████████████████████████▍        | 8/10 [01:23<00:20, 10.42s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 12:53:23 (running for 00:55:28.89)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:53:28 (running for 00:55:33.91)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|██████████████████████████████████████▋    | 9/10 [01:33<00:10, 10.43s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 12:53:33 (running for 00:55:38.93)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:53:38 (running for 00:55:43.95)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - model initialization done -> loss fn initialization\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - reading data\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - reading data done -> model initialization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 10/10 [01:44<00:00, 10.42s/it]\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   warnings.warn(  # warn only once\n",
      " 90%|██████████████████████████████████████▋    | 9/10 [01:34<00:10, 10.48s/it]\n",
      "100%|██████████████████████████████████████████| 10/10 [01:44<00:00, 10.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 12:53:44 (running for 00:55:48.97)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m [KSpaceLoss] torch.Size([8, 2001191, 2, 1]) torch.Size([8, 2001191, 2, 1]) None\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - model initialization done -> loss fn initialization\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m [ImageSpaceLoss] torch.Size([156, 156, 156, 2, 1]) torch.Size([156, 156, 156, 2, 1]) None\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:53:49 (running for 00:55:54.00)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - Loss k-space: 1.640 - Loss image space: 0.036 - Loss Wavelet 0.000 - Loss Hankel 0.000 - Loss Casorati 0.000\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - loss fn initialization done -> compute backward pass\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   warnings.warn(  # warn only once\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 12:53:54 (running for 00:55:59.02)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:53:59 (running for 00:56:04.04)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:54:04 (running for 00:56:09.06)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:54:09 (running for 00:56:14.09)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:54:14 (running for 00:56:19.11)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:54:19 (running for 00:56:24.14)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:54:24 (running for 00:56:29.15)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:54:29 (running for 00:56:34.18)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:54:34 (running for 00:56:39.20)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:54:39 (running for 00:56:44.22)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:54:44 (running for 00:56:49.23)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:54:49 (running for 00:56:54.26)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:54:54 (running for 00:56:59.27)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:54:59 (running for 00:57:04.30)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:55:04 (running for 00:57:09.32)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:55:09 (running for 00:57:14.34)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:55:14 (running for 00:57:19.35)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:55:19 (running for 00:57:24.38)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:55:24 (running for 00:57:29.40)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:55:29 (running for 00:57:34.42)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:55:34 (running for 00:57:39.43)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:55:39 (running for 00:57:44.55)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:55:44 (running for 00:57:49.57)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:55:49 (running for 00:57:54.59)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:55:54 (running for 00:57:59.61)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:55:59 (running for 00:58:04.63)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:56:04 (running for 00:58:09.65)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:56:09 (running for 00:58:14.67)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:56:14 (running for 00:58:19.69)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:56:19 (running for 00:58:24.71)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:56:24 (running for 00:58:29.72)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:56:29 (running for 00:58:34.74)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:56:34 (running for 00:58:39.76)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:56:39 (running for 00:58:44.78)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:56:44 (running for 00:58:49.80)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:56:49 (running for 00:58:54.82)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:56:54 (running for 00:58:59.84)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:56:59 (running for 00:59:04.86)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:57:04 (running for 00:59:09.88)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:57:09 (running for 00:59:14.90)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:57:14 (running for 00:59:19.92)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:57:19 (running for 00:59:24.94)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:57:24 (running for 00:59:29.96)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:57:30 (running for 00:59:34.98)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - compute backward pass done -> compute accumulator\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m [KSpaceLoss] torch.Size([8, 2001191, 2, 1]) torch.Size([8, 2001191, 2, 1]) None\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m [ImageSpaceLoss] torch.Size([156, 156, 156, 2, 1]) torch.Size([156, 156, 156, 2, 1]) None\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - Loss k-space: 1.514 - Loss image space: 0.036 - Loss Wavelet 0.000 - Loss Hankel 0.000 - Loss Casorati 0.000\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - loss fn initialization done -> compute backward pass\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/autograd/graph.py:824: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   warnings.warn(  # warn only once\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 12:57:35 (running for 00:59:39.99)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - Index 0 - Gradient norm: 5.299\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Averaged gradient norm: 1.000\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Creating untagged checkpoint ...\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m 2025-09-29 12:57:36 Schedule checkpoint save with tag:  ...\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m 2025-09-29 12:57:36 Saved checkpoint to buffer 0.0 seconds\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Iteration: 9 - Elapsed time: 357 - Training loss: ['1.613'] - Validation loss: ['0.000']\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m 2025-09-29 12:57:37 Saved buffer to filesystem in 0.1 seconds\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m 2025-09-29 12:57:37 Completed saving checkpoint.\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:57:40 (running for 00:59:45.02)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:57:45 (running for 00:59:50.04)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - reading data\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - compute backward pass done -> compute accumulator\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - Index 0 - Gradient norm: 6.183\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - reading data done -> model initialization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/autograd/graph.py:824: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   warnings.warn(  # warn only once\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 12:57:50 (running for 00:59:55.06)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                   | 0/10 [00:00<?, ?it/s]\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m   warnings.warn(  # warn only once\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 12:57:55 (running for 01:00:00.09)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:58:00 (running for 01:00:05.11)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████▎                                      | 1/10 [00:10<01:35, 10.58s/it]\n",
      "  0%|                                                   | 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 12:58:05 (running for 01:00:10.13)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:58:10 (running for 01:00:15.15)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████▌                                  | 2/10 [00:21<01:23, 10.49s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 12:58:15 (running for 01:00:20.17)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:58:20 (running for 01:00:25.19)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|████████████▉                              | 3/10 [00:31<01:13, 10.46s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 12:58:25 (running for 01:00:30.21)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:58:30 (running for 01:00:35.23)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|█████████████████▏                         | 4/10 [00:41<01:02, 10.44s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 12:58:35 (running for 01:00:40.24)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:58:40 (running for 01:00:45.27)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████████████████████▌                     | 5/10 [00:52<00:52, 10.44s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 12:58:45 (running for 01:00:50.28)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:58:50 (running for 01:00:55.30)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:58:55 (running for 01:01:00.32)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████████████████████████▊                 | 6/10 [01:02<00:41, 10.43s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 12:59:00 (running for 01:01:05.35)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:59:05 (running for 01:01:10.37)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████████████████████████████             | 7/10 [01:13<00:31, 10.44s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 12:59:10 (running for 01:01:15.39)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:59:15 (running for 01:01:20.42)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|██████████████████████████████████▍        | 8/10 [01:23<00:20, 10.44s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 12:59:20 (running for 01:01:25.44)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:59:25 (running for 01:01:30.47)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|██████████████████████████████████████▋    | 9/10 [01:34<00:10, 10.45s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 12:59:30 (running for 01:01:35.50)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:59:35 (running for 01:01:40.52)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - model initialization done -> loss fn initialization\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - reading data\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - reading data done -> model initialization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 10/10 [01:44<00:00, 10.45s/it]\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   warnings.warn(  # warn only once\n",
      " 90%|██████████████████████████████████████▋    | 9/10 [01:35<00:10, 10.51s/it]\n",
      "100%|██████████████████████████████████████████| 10/10 [01:46<00:00, 10.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 12:59:40 (running for 01:01:45.54)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:59:45 (running for 01:01:50.56)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m [KSpaceLoss] torch.Size([8, 2001191, 2, 1]) torch.Size([8, 2001191, 2, 1]) None\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - model initialization done -> loss fn initialization\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m [ImageSpaceLoss] torch.Size([156, 156, 156, 2, 1]) torch.Size([156, 156, 156, 2, 1]) None\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - Loss k-space: 1.696 - Loss image space: 0.037 - Loss Wavelet 0.000 - Loss Hankel 0.000 - Loss Casorati 0.000\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - loss fn initialization done -> compute backward pass\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   warnings.warn(  # warn only once\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 12:59:50 (running for 01:01:55.59)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 12:59:55 (running for 01:02:00.61)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:00:00 (running for 01:02:05.63)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:00:05 (running for 01:02:10.65)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:00:10 (running for 01:02:15.67)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:00:15 (running for 01:02:20.69)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:00:20 (running for 01:02:25.71)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:00:25 (running for 01:02:30.73)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:00:30 (running for 01:02:35.75)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:00:35 (running for 01:02:40.77)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:00:40 (running for 01:02:45.79)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:00:45 (running for 01:02:50.81)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:00:50 (running for 01:02:55.83)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:00:55 (running for 01:03:00.85)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:01:00 (running for 01:03:05.87)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:01:05 (running for 01:03:10.89)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:01:10 (running for 01:03:15.91)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:01:15 (running for 01:03:20.93)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:01:20 (running for 01:03:25.95)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:01:26 (running for 01:03:30.97)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:01:31 (running for 01:03:35.99)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:01:36 (running for 01:03:41.01)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:01:41 (running for 01:03:46.03)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:01:46 (running for 01:03:51.05)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:01:51 (running for 01:03:56.07)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:01:56 (running for 01:04:01.09)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:02:01 (running for 01:04:06.11)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:02:06 (running for 01:04:11.13)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:02:11 (running for 01:04:16.15)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:02:16 (running for 01:04:21.17)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:02:21 (running for 01:04:26.19)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:02:26 (running for 01:04:31.21)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:02:31 (running for 01:04:36.23)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:02:36 (running for 01:04:41.25)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:02:41 (running for 01:04:46.27)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:02:46 (running for 01:04:51.29)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:02:51 (running for 01:04:56.31)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:02:56 (running for 01:05:01.32)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:03:01 (running for 01:05:06.35)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:03:06 (running for 01:05:11.37)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:03:11 (running for 01:05:16.39)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:03:16 (running for 01:05:21.41)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:03:21 (running for 01:05:26.44)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:03:26 (running for 01:05:31.46)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - compute backward pass done -> compute accumulator\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m [KSpaceLoss] torch.Size([8, 2001191, 2, 1]) torch.Size([8, 2001191, 2, 1]) None\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m [ImageSpaceLoss] torch.Size([156, 156, 156, 2, 1]) torch.Size([156, 156, 156, 2, 1]) None\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - Loss k-space: 1.554 - Loss image space: 0.038 - Loss Wavelet 0.000 - Loss Hankel 0.000 - Loss Casorati 0.000\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - loss fn initialization done -> compute backward pass\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:03:31 (running for 01:05:36.48)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/autograd/graph.py:824: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   warnings.warn(  # warn only once\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - Index 0 - Gradient norm: 5.246\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Averaged gradient norm: 1.000\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Iteration: 10 - Elapsed time: 355 - Training loss: ['1.662'] - Validation loss: ['0.000']\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:03:36 (running for 01:05:41.51)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:03:41 (running for 01:05:46.54)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - reading data\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - compute backward pass done -> compute accumulator\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - Index 0 - Gradient norm: 5.980\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - reading data done -> model initialization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/autograd/graph.py:824: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   warnings.warn(  # warn only once\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 13:03:46 (running for 01:05:51.56)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:03:51 (running for 01:05:56.59)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                   | 0/10 [00:00<?, ?it/s]\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m   warnings.warn(  # warn only once\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 13:03:56 (running for 01:06:01.60)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:04:01 (running for 01:06:06.62)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████▎                                      | 1/10 [00:10<01:33, 10.40s/it]\n",
      "  0%|                                                   | 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 13:04:06 (running for 01:06:11.64)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:04:11 (running for 01:06:16.66)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████▌                                  | 2/10 [00:20<01:23, 10.41s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 13:04:16 (running for 01:06:21.68)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:04:21 (running for 01:06:26.70)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|████████████▉                              | 3/10 [00:31<01:12, 10.42s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 13:04:26 (running for 01:06:31.72)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:04:31 (running for 01:06:36.74)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|█████████████████▏                         | 4/10 [00:41<01:02, 10.42s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 13:04:36 (running for 01:06:41.76)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:04:41 (running for 01:06:46.78)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████████████████████▌                     | 5/10 [00:52<00:52, 10.43s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 13:04:46 (running for 01:06:51.80)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:04:51 (running for 01:06:56.82)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████████████████████████▊                 | 6/10 [01:02<00:41, 10.43s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 13:04:56 (running for 01:07:01.84)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:05:01 (running for 01:07:06.86)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████████████████████████████             | 7/10 [01:12<00:31, 10.44s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 13:05:06 (running for 01:07:11.88)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:05:11 (running for 01:07:16.90)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|██████████████████████████████████▍        | 8/10 [01:23<00:20, 10.43s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 13:05:16 (running for 01:07:21.92)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:05:21 (running for 01:07:26.94)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|██████████████████████████████████████▋    | 9/10 [01:33<00:10, 10.43s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 13:05:26 (running for 01:07:31.96)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:05:32 (running for 01:07:36.98)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - model initialization done -> loss fn initialization\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - reading data\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - reading data done -> model initialization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 10/10 [01:44<00:00, 10.43s/it]\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   warnings.warn(  # warn only once\n",
      " 90%|██████████████████████████████████████▋    | 9/10 [01:34<00:10, 10.48s/it]\n",
      "100%|██████████████████████████████████████████| 10/10 [01:44<00:00, 10.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 13:05:37 (running for 01:07:42.01)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:05:42 (running for 01:07:47.04)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m [KSpaceLoss] torch.Size([8, 2001191, 2, 1]) torch.Size([8, 2001191, 2, 1]) None\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - model initialization done -> loss fn initialization\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m [ImageSpaceLoss] torch.Size([156, 156, 156, 2, 1]) torch.Size([156, 156, 156, 2, 1]) None\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:05:47 (running for 01:07:52.06)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - Loss k-space: 1.689 - Loss image space: 0.034 - Loss Wavelet 0.000 - Loss Hankel 0.000 - Loss Casorati 0.000\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - loss fn initialization done -> compute backward pass\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   warnings.warn(  # warn only once\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 13:05:52 (running for 01:07:57.09)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:05:57 (running for 01:08:02.12)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:06:02 (running for 01:08:07.14)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:06:07 (running for 01:08:12.15)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:06:12 (running for 01:08:17.17)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:06:17 (running for 01:08:22.19)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:06:22 (running for 01:08:27.21)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:06:27 (running for 01:08:32.23)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:06:32 (running for 01:08:37.25)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:06:37 (running for 01:08:42.26)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:06:42 (running for 01:08:47.29)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:06:47 (running for 01:08:52.30)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:06:52 (running for 01:08:57.32)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:06:57 (running for 01:09:02.34)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:07:02 (running for 01:09:07.36)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:07:07 (running for 01:09:12.38)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:07:12 (running for 01:09:17.40)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:07:17 (running for 01:09:22.42)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:07:22 (running for 01:09:27.44)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:07:27 (running for 01:09:32.46)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:07:32 (running for 01:09:37.48)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:07:37 (running for 01:09:42.50)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:07:42 (running for 01:09:47.52)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:07:47 (running for 01:09:52.54)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:07:52 (running for 01:09:57.56)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:07:57 (running for 01:10:02.58)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:08:02 (running for 01:10:07.60)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:08:07 (running for 01:10:12.62)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:08:12 (running for 01:10:17.64)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:08:17 (running for 01:10:22.65)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:08:22 (running for 01:10:27.67)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:08:27 (running for 01:10:32.69)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:08:32 (running for 01:10:37.71)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:08:37 (running for 01:10:42.73)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:08:42 (running for 01:10:47.75)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:08:47 (running for 01:10:52.77)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:08:52 (running for 01:10:57.79)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:08:57 (running for 01:11:02.80)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:09:02 (running for 01:11:07.82)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:09:07 (running for 01:11:12.84)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:09:12 (running for 01:11:17.86)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:09:17 (running for 01:11:22.88)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:09:22 (running for 01:11:27.90)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:09:27 (running for 01:11:32.92)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - compute backward pass done -> compute accumulator\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m [KSpaceLoss] torch.Size([8, 2001191, 2, 1]) torch.Size([8, 2001191, 2, 1]) None\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m [ImageSpaceLoss] torch.Size([156, 156, 156, 2, 1]) torch.Size([156, 156, 156, 2, 1]) None\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - Loss k-space: 1.494 - Loss image space: 0.038 - Loss Wavelet 0.000 - Loss Hankel 0.000 - Loss Casorati 0.000\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - loss fn initialization done -> compute backward pass\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:09:32 (running for 01:11:37.94)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/autograd/graph.py:824: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   warnings.warn(  # warn only once\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - Index 0 - Gradient norm: 6.078\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Averaged gradient norm: 1.000\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Iteration: 11 - Elapsed time: 361 - Training loss: ['1.628'] - Validation loss: ['0.000']\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:09:38 (running for 01:11:42.96)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - reading data\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - compute backward pass done -> compute accumulator\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - Index 0 - Gradient norm: 5.099\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:09:43 (running for 01:11:47.98)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - reading data done -> model initialization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/autograd/graph.py:824: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   warnings.warn(  # warn only once\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 13:09:48 (running for 01:11:53.00)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                   | 0/10 [00:00<?, ?it/s]\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m   warnings.warn(  # warn only once\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 13:09:53 (running for 01:11:58.03)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:09:58 (running for 01:12:03.05)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████▎                                      | 1/10 [00:10<01:33, 10.39s/it]\n",
      "  0%|                                                   | 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 13:10:03 (running for 01:12:08.07)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:10:08 (running for 01:12:13.09)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████▌                                  | 2/10 [00:20<01:23, 10.41s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 13:10:13 (running for 01:12:18.11)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:10:18 (running for 01:12:23.13)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|████████████▉                              | 3/10 [00:31<01:12, 10.43s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 13:10:23 (running for 01:12:28.15)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:10:28 (running for 01:12:33.17)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|█████████████████▏                         | 4/10 [00:41<01:02, 10.43s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 13:10:33 (running for 01:12:38.19)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:10:38 (running for 01:12:43.21)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████████████████████▌                     | 5/10 [00:52<00:52, 10.43s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 13:10:43 (running for 01:12:48.23)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:10:48 (running for 01:12:53.24)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:10:53 (running for 01:12:58.27)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████████████████████████▊                 | 6/10 [01:02<00:41, 10.43s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 13:10:58 (running for 01:13:03.28)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:11:03 (running for 01:13:08.31)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████████████████████████████             | 7/10 [01:12<00:31, 10.43s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 13:11:08 (running for 01:13:13.32)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:11:13 (running for 01:13:18.34)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|██████████████████████████████████▍        | 8/10 [01:23<00:20, 10.43s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 13:11:18 (running for 01:13:23.36)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:11:23 (running for 01:13:28.38)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|██████████████████████████████████████▋    | 9/10 [01:33<00:10, 10.43s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 13:11:28 (running for 01:13:33.40)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:11:33 (running for 01:13:38.42)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - model initialization done -> loss fn initialization\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - reading data\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - reading data done -> model initialization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 10/10 [01:44<00:00, 10.43s/it]\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   warnings.warn(  # warn only once\n",
      " 90%|██████████████████████████████████████▋    | 9/10 [01:34<00:10, 10.48s/it]\n",
      "100%|██████████████████████████████████████████| 10/10 [01:44<00:00, 10.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 13:11:38 (running for 01:13:43.44)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m [KSpaceLoss] torch.Size([8, 2001191, 2, 1]) torch.Size([8, 2001191, 2, 1]) None\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - model initialization done -> loss fn initialization\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m [ImageSpaceLoss] torch.Size([156, 156, 156, 2, 1]) torch.Size([156, 156, 156, 2, 1]) None\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:11:43 (running for 01:13:48.46)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - Loss k-space: 1.665 - Loss image space: 0.037 - Loss Wavelet 0.000 - Loss Hankel 0.000 - Loss Casorati 0.000\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - loss fn initialization done -> compute backward pass\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   warnings.warn(  # warn only once\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 13:11:48 (running for 01:13:53.48)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:11:53 (running for 01:13:58.50)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:11:58 (running for 01:14:03.52)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:12:03 (running for 01:14:08.54)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:12:08 (running for 01:14:13.56)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:12:13 (running for 01:14:18.58)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:12:18 (running for 01:14:23.59)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:12:23 (running for 01:14:28.62)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:12:28 (running for 01:14:33.63)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:12:33 (running for 01:14:38.66)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:12:38 (running for 01:14:43.68)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:12:43 (running for 01:14:48.70)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:12:48 (running for 01:14:53.71)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:12:53 (running for 01:14:58.73)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:12:58 (running for 01:15:03.75)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:13:03 (running for 01:15:08.77)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:13:08 (running for 01:15:13.79)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:13:13 (running for 01:15:18.81)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:13:18 (running for 01:15:23.83)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:13:23 (running for 01:15:28.85)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:13:28 (running for 01:15:33.87)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:13:33 (running for 01:15:38.89)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:13:38 (running for 01:15:43.91)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:13:43 (running for 01:15:48.93)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:13:48 (running for 01:15:53.95)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:13:54 (running for 01:15:58.97)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:13:59 (running for 01:16:03.99)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:14:04 (running for 01:16:09.01)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:14:09 (running for 01:16:14.03)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:14:14 (running for 01:16:19.05)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:14:19 (running for 01:16:24.07)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:14:24 (running for 01:16:29.09)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:14:29 (running for 01:16:34.11)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:14:34 (running for 01:16:39.13)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:14:39 (running for 01:16:44.15)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:14:44 (running for 01:16:49.18)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:14:49 (running for 01:16:54.20)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:14:54 (running for 01:16:59.22)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:14:59 (running for 01:17:04.24)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:15:04 (running for 01:17:09.27)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:15:09 (running for 01:17:14.28)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:15:14 (running for 01:17:19.30)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:15:19 (running for 01:17:24.32)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:15:24 (running for 01:17:29.34)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - compute backward pass done -> compute accumulator\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m [KSpaceLoss] torch.Size([8, 2001191, 2, 1]) torch.Size([8, 2001191, 2, 1]) None\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m [ImageSpaceLoss] torch.Size([156, 156, 156, 2, 1]) torch.Size([156, 156, 156, 2, 1]) None\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - Loss k-space: 1.553 - Loss image space: 0.036 - Loss Wavelet 0.000 - Loss Hankel 0.000 - Loss Casorati 0.000\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - loss fn initialization done -> compute backward pass\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/autograd/graph.py:824: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   warnings.warn(  # warn only once\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - Index 0 - Gradient norm: 5.187\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Averaged gradient norm: 1.000\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Iteration: 12 - Elapsed time: 354 - Training loss: ['1.645'] - Validation loss: ['0.000']\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:15:29 (running for 01:17:34.36)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:15:34 (running for 01:17:39.38)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - reading data\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - compute backward pass done -> compute accumulator\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - Index 0 - Gradient norm: 5.785\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - reading data done -> model initialization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/autograd/graph.py:824: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   warnings.warn(  # warn only once\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 13:15:39 (running for 01:17:44.41)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:15:44 (running for 01:17:49.43)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                   | 0/10 [00:00<?, ?it/s]\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m   warnings.warn(  # warn only once\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 13:15:49 (running for 01:17:54.45)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:15:54 (running for 01:17:59.47)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████▎                                      | 1/10 [00:10<01:33, 10.41s/it]\n",
      "  0%|                                                   | 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 13:15:59 (running for 01:18:04.49)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:16:04 (running for 01:18:09.51)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████▌                                  | 2/10 [00:20<01:23, 10.42s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 13:16:09 (running for 01:18:14.53)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:16:14 (running for 01:18:19.54)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|████████████▉                              | 3/10 [00:31<01:12, 10.42s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 13:16:19 (running for 01:18:24.56)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:16:24 (running for 01:18:29.58)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|█████████████████▏                         | 4/10 [00:41<01:02, 10.42s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 13:16:29 (running for 01:18:34.60)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:16:34 (running for 01:18:39.62)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████████████████████▌                     | 5/10 [00:52<00:52, 10.42s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 13:16:39 (running for 01:18:44.63)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:16:44 (running for 01:18:49.65)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████████████████████████▊                 | 6/10 [01:02<00:41, 10.43s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 13:16:49 (running for 01:18:54.67)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:16:54 (running for 01:18:59.69)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████████████████████████████             | 7/10 [01:12<00:31, 10.43s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 13:16:59 (running for 01:19:04.71)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:17:04 (running for 01:19:09.73)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|██████████████████████████████████▍        | 8/10 [01:23<00:20, 10.43s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 13:17:09 (running for 01:19:14.75)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:17:14 (running for 01:19:19.77)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|██████████████████████████████████████▋    | 9/10 [01:33<00:10, 10.44s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 13:17:19 (running for 01:19:24.80)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:17:24 (running for 01:19:29.82)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:17:29 (running for 01:19:34.84)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - model initialization done -> loss fn initialization\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - reading data\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - reading data done -> model initialization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 10/10 [01:44<00:00, 10.43s/it]\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   warnings.warn(  # warn only once\n",
      " 90%|██████████████████████████████████████▋    | 9/10 [01:34<00:10, 10.48s/it]\n",
      "100%|██████████████████████████████████████████| 10/10 [01:44<00:00, 10.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 13:17:34 (running for 01:19:39.87)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m [KSpaceLoss] torch.Size([8, 2001191, 2, 1]) torch.Size([8, 2001191, 2, 1]) None\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - model initialization done -> loss fn initialization\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m [ImageSpaceLoss] torch.Size([156, 156, 156, 2, 1]) torch.Size([156, 156, 156, 2, 1]) None\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - Loss k-space: 1.702 - Loss image space: 0.035 - Loss Wavelet 0.000 - Loss Hankel 0.000 - Loss Casorati 0.000\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - loss fn initialization done -> compute backward pass\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   warnings.warn(  # warn only once\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 13:17:39 (running for 01:19:44.89)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:17:44 (running for 01:19:49.91)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:17:49 (running for 01:19:54.93)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:17:54 (running for 01:19:59.95)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:18:00 (running for 01:20:04.97)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:18:05 (running for 01:20:09.99)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:18:10 (running for 01:20:15.01)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:18:15 (running for 01:20:20.03)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:18:20 (running for 01:20:25.05)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:18:25 (running for 01:20:30.07)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:18:30 (running for 01:20:35.09)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:18:35 (running for 01:20:40.11)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:18:40 (running for 01:20:45.13)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:18:45 (running for 01:20:50.41)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:18:50 (running for 01:20:55.43)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:18:55 (running for 01:21:00.45)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:19:00 (running for 01:21:05.47)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:19:05 (running for 01:21:10.49)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:19:10 (running for 01:21:15.51)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:19:15 (running for 01:21:20.53)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:19:20 (running for 01:21:25.55)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:19:25 (running for 01:21:30.57)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:19:30 (running for 01:21:35.59)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:19:35 (running for 01:21:40.62)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:19:40 (running for 01:21:45.63)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:19:45 (running for 01:21:50.66)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:19:50 (running for 01:21:55.67)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:19:55 (running for 01:22:00.70)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:20:00 (running for 01:22:05.71)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:20:05 (running for 01:22:10.74)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:20:10 (running for 01:22:15.75)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:20:15 (running for 01:22:20.78)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:20:20 (running for 01:22:25.79)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:20:25 (running for 01:22:30.82)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:20:30 (running for 01:22:35.83)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:20:35 (running for 01:22:40.85)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:20:40 (running for 01:22:45.87)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:20:45 (running for 01:22:50.89)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:20:50 (running for 01:22:55.91)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:20:55 (running for 01:23:00.93)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:21:00 (running for 01:23:05.95)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:21:06 (running for 01:23:10.97)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:21:11 (running for 01:23:15.98)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:21:16 (running for 01:23:21.01)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:21:21 (running for 01:23:26.02)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - compute backward pass done -> compute accumulator\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m [KSpaceLoss] torch.Size([8, 2001191, 2, 1]) torch.Size([8, 2001191, 2, 1]) None\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m [ImageSpaceLoss] torch.Size([156, 156, 156, 2, 1]) torch.Size([156, 156, 156, 2, 1]) None\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - Loss k-space: 1.554 - Loss image space: 0.038 - Loss Wavelet 0.000 - Loss Hankel 0.000 - Loss Casorati 0.000\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - loss fn initialization done -> compute backward pass\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/autograd/graph.py:824: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   warnings.warn(  # warn only once\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - Index 0 - Gradient norm: 5.050\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Averaged gradient norm: 1.000\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Iteration: 13 - Elapsed time: 354 - Training loss: ['1.664'] - Validation loss: ['0.000']\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:21:26 (running for 01:23:31.05)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:21:31 (running for 01:23:36.07)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - reading data\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - compute backward pass done -> compute accumulator\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - Index 0 - Gradient norm: 5.825\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - reading data done -> model initialization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/autograd/graph.py:824: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   warnings.warn(  # warn only once\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 13:21:36 (running for 01:23:41.09)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                   | 0/10 [00:00<?, ?it/s]\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m   warnings.warn(  # warn only once\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 13:21:41 (running for 01:23:46.11)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:21:46 (running for 01:23:51.13)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████▎                                      | 1/10 [00:10<01:33, 10.39s/it]\n",
      "  0%|                                                   | 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 13:21:51 (running for 01:23:56.15)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:21:56 (running for 01:24:01.17)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████▌                                  | 2/10 [00:20<01:23, 10.42s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 13:22:01 (running for 01:24:06.19)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:22:06 (running for 01:24:11.21)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|████████████▉                              | 3/10 [00:31<01:12, 10.42s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 13:22:11 (running for 01:24:16.23)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:22:16 (running for 01:24:21.25)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|█████████████████▏                         | 4/10 [00:41<01:02, 10.43s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 13:22:21 (running for 01:24:26.27)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:22:26 (running for 01:24:31.29)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:22:31 (running for 01:24:36.31)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████████████████████▌                     | 5/10 [00:52<00:52, 10.43s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 13:22:36 (running for 01:24:41.33)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:22:41 (running for 01:24:46.35)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████████████████████████▊                 | 6/10 [01:02<00:41, 10.43s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 13:22:46 (running for 01:24:51.37)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:22:51 (running for 01:24:56.40)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████████████████████████████             | 7/10 [01:12<00:31, 10.44s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 13:22:56 (running for 01:25:01.42)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:23:01 (running for 01:25:06.44)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|██████████████████████████████████▍        | 8/10 [01:23<00:20, 10.44s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 13:23:06 (running for 01:25:11.46)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:23:11 (running for 01:25:16.48)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|██████████████████████████████████████▋    | 9/10 [01:33<00:10, 10.44s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 13:23:16 (running for 01:25:21.50)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:23:21 (running for 01:25:26.53)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - model initialization done -> loss fn initialization\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - reading data\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - reading data done -> model initialization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 10/10 [01:44<00:00, 10.43s/it]\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   warnings.warn(  # warn only once\n",
      " 90%|██████████████████████████████████████▋    | 9/10 [01:34<00:10, 10.48s/it]\n",
      "100%|██████████████████████████████████████████| 10/10 [01:44<00:00, 10.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 13:23:26 (running for 01:25:31.55)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m [KSpaceLoss] torch.Size([8, 2001191, 2, 1]) torch.Size([8, 2001191, 2, 1]) None\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - model initialization done -> loss fn initialization\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m [ImageSpaceLoss] torch.Size([156, 156, 156, 2, 1]) torch.Size([156, 156, 156, 2, 1]) None\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:23:31 (running for 01:25:36.57)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - Loss k-space: 1.644 - Loss image space: 0.035 - Loss Wavelet 0.000 - Loss Hankel 0.000 - Loss Casorati 0.000\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - loss fn initialization done -> compute backward pass\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   warnings.warn(  # warn only once\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 13:23:36 (running for 01:25:41.60)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:23:41 (running for 01:25:46.62)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:23:46 (running for 01:25:51.64)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:23:51 (running for 01:25:56.66)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:23:56 (running for 01:26:01.68)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:24:01 (running for 01:26:06.70)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:24:06 (running for 01:26:11.72)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:24:11 (running for 01:26:16.74)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:24:16 (running for 01:26:21.77)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:24:21 (running for 01:26:26.79)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:24:26 (running for 01:26:31.81)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:24:31 (running for 01:26:36.83)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:24:36 (running for 01:26:41.85)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:24:41 (running for 01:26:46.87)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:24:46 (running for 01:26:51.90)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:24:51 (running for 01:26:56.92)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:24:56 (running for 01:27:01.94)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:25:01 (running for 01:27:06.96)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:25:07 (running for 01:27:11.98)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:25:12 (running for 01:27:17.00)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:25:17 (running for 01:27:22.02)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:25:22 (running for 01:27:27.04)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:25:27 (running for 01:27:32.07)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:25:32 (running for 01:27:37.08)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:25:37 (running for 01:27:42.10)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:25:42 (running for 01:27:47.12)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:25:47 (running for 01:27:52.15)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:25:52 (running for 01:27:57.16)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:25:57 (running for 01:28:02.19)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:26:02 (running for 01:28:07.20)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:26:07 (running for 01:28:12.23)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:26:12 (running for 01:28:17.24)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:26:17 (running for 01:28:22.26)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:26:22 (running for 01:28:27.28)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:26:27 (running for 01:28:32.30)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:26:32 (running for 01:28:37.32)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:26:37 (running for 01:28:42.34)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:26:42 (running for 01:28:47.37)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:26:47 (running for 01:28:52.39)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:26:52 (running for 01:28:57.41)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:26:57 (running for 01:29:02.44)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:27:02 (running for 01:29:07.46)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:27:07 (running for 01:29:12.48)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:27:12 (running for 01:29:17.50)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - compute backward pass done -> compute accumulator\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m [KSpaceLoss] torch.Size([8, 2001191, 2, 1]) torch.Size([8, 2001191, 2, 1]) None\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m [ImageSpaceLoss] torch.Size([156, 156, 156, 2, 1]) torch.Size([156, 156, 156, 2, 1]) None\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - Loss k-space: 1.520 - Loss image space: 0.036 - Loss Wavelet 0.000 - Loss Hankel 0.000 - Loss Casorati 0.000\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - loss fn initialization done -> compute backward pass\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/autograd/graph.py:824: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   warnings.warn(  # warn only once\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - Index 0 - Gradient norm: 5.082\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Averaged gradient norm: 1.000\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Creating untagged checkpoint ...\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m 2025-09-29 13:27:16 Schedule checkpoint save with tag:  ...\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m 2025-09-29 13:27:16 Saved checkpoint to buffer 0.0 seconds\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Iteration: 14 - Elapsed time: 353 - Training loss: ['1.617'] - Validation loss: ['0.000']\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m 2025-09-29 13:27:16 Saved buffer to filesystem in 0.1 seconds\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m 2025-09-29 13:27:16 Completed saving checkpoint.\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:27:17 (running for 01:29:22.52)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:27:22 (running for 01:29:27.54)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - reading data\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - compute backward pass done -> compute accumulator\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - Index 0 - Gradient norm: 5.946\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - reading data done -> model initialization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/autograd/graph.py:824: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   warnings.warn(  # warn only once\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 13:27:27 (running for 01:29:32.56)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                   | 0/10 [00:00<?, ?it/s]\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m   warnings.warn(  # warn only once\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 13:27:32 (running for 01:29:37.58)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:27:37 (running for 01:29:42.61)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:27:42 (running for 01:29:47.62)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████▎                                      | 1/10 [00:10<01:33, 10.40s/it]\n",
      "  0%|                                                   | 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 13:27:47 (running for 01:29:52.65)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:27:52 (running for 01:29:57.69)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████▌                                  | 2/10 [00:20<01:24, 10.50s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 13:27:57 (running for 01:30:02.72)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:28:02 (running for 01:30:07.73)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|████████████▉                              | 3/10 [00:31<01:13, 10.50s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 13:28:07 (running for 01:30:12.75)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:28:12 (running for 01:30:17.77)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|█████████████████▏                         | 4/10 [00:41<01:02, 10.49s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 13:28:17 (running for 01:30:22.79)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:28:22 (running for 01:30:27.81)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████████████████████▌                     | 5/10 [00:52<00:52, 10.48s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 13:28:27 (running for 01:30:32.83)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:28:32 (running for 01:30:37.85)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████████████████████████▊                 | 6/10 [01:02<00:41, 10.48s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 13:28:37 (running for 01:30:42.87)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:28:42 (running for 01:30:47.89)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████████████████████████████             | 7/10 [01:13<00:31, 10.48s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 13:28:47 (running for 01:30:52.91)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:28:52 (running for 01:30:57.93)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|██████████████████████████████████▍        | 8/10 [01:23<00:20, 10.48s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 13:28:57 (running for 01:31:02.95)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:29:03 (running for 01:31:07.96)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|██████████████████████████████████████▋    | 9/10 [01:34<00:10, 10.48s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 13:29:08 (running for 01:31:12.98)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:29:13 (running for 01:31:18.00)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - model initialization done -> loss fn initialization\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - reading data\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - reading data done -> model initialization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 10/10 [01:44<00:00, 10.48s/it]\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m   warnings.warn(  # warn only once\n",
      " 90%|██████████████████████████████████████▋    | 9/10 [01:34<00:10, 10.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 13:29:18 (running for 01:31:23.02)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 10/10 [01:44<00:00, 10.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 13:29:23 (running for 01:31:28.04)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m [KSpaceLoss] torch.Size([8, 2001191, 2, 1]) torch.Size([8, 2001191, 2, 1]) None\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - model initialization done -> loss fn initialization\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m [ImageSpaceLoss] torch.Size([156, 156, 156, 2, 1]) torch.Size([156, 156, 156, 2, 1]) None\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:29:28 (running for 01:31:33.06)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - Loss k-space: 1.628 - Loss image space: 0.037 - Loss Wavelet 0.000 - Loss Hankel 0.000 - Loss Casorati 0.000\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - loss fn initialization done -> compute backward pass\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   warnings.warn(  # warn only once\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 13:29:33 (running for 01:31:38.09)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:29:38 (running for 01:31:43.11)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:29:43 (running for 01:31:48.13)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:29:48 (running for 01:31:53.15)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:29:53 (running for 01:31:58.17)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:29:58 (running for 01:32:03.19)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:30:03 (running for 01:32:08.21)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:30:08 (running for 01:32:13.23)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:30:13 (running for 01:32:18.25)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:30:18 (running for 01:32:23.27)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:30:23 (running for 01:32:28.29)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:30:28 (running for 01:32:33.31)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:30:33 (running for 01:32:38.32)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:30:38 (running for 01:32:43.34)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:30:43 (running for 01:32:48.36)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:30:48 (running for 01:32:53.38)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:30:53 (running for 01:32:58.40)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:30:58 (running for 01:33:03.42)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:31:03 (running for 01:33:08.44)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:31:08 (running for 01:33:13.46)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:31:13 (running for 01:33:18.48)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:31:18 (running for 01:33:23.50)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:31:23 (running for 01:33:28.52)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:31:28 (running for 01:33:33.54)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:31:33 (running for 01:33:38.56)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:31:38 (running for 01:33:43.58)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:31:43 (running for 01:33:48.60)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:31:48 (running for 01:33:53.62)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:31:53 (running for 01:33:58.63)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:31:58 (running for 01:34:03.65)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:32:03 (running for 01:34:08.67)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:32:08 (running for 01:34:13.69)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:32:13 (running for 01:34:18.71)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:32:18 (running for 01:34:23.73)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:32:23 (running for 01:34:28.75)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:32:28 (running for 01:34:33.77)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:32:33 (running for 01:34:38.79)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:32:38 (running for 01:34:43.81)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:32:43 (running for 01:34:48.83)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:32:48 (running for 01:34:53.85)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:32:53 (running for 01:34:58.87)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:32:58 (running for 01:35:03.89)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:33:03 (running for 01:35:08.90)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:33:08 (running for 01:35:13.92)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - compute backward pass done -> compute accumulator\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m [KSpaceLoss] torch.Size([8, 2001191, 2, 1]) torch.Size([8, 2001191, 2, 1]) None\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m [ImageSpaceLoss] torch.Size([156, 156, 156, 2, 1]) torch.Size([156, 156, 156, 2, 1]) None\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - Loss k-space: 1.594 - Loss image space: 0.034 - Loss Wavelet 0.000 - Loss Hankel 0.000 - Loss Casorati 0.000\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - loss fn initialization done -> compute backward pass\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/autograd/graph.py:824: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   warnings.warn(  # warn only once\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - Index 0 - Gradient norm: 5.183\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Averaged gradient norm: 1.000\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Iteration: 15 - Elapsed time: 357 - Training loss: ['1.647'] - Validation loss: ['0.000']\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:33:13 (running for 01:35:18.94)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:33:19 (running for 01:35:23.96)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - reading data\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - compute backward pass done -> compute accumulator\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - Index 0 - Gradient norm: 5.468\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - reading data done -> model initialization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/autograd/graph.py:824: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   warnings.warn(  # warn only once\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 13:33:24 (running for 01:35:28.98)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:33:29 (running for 01:35:34.01)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                   | 0/10 [00:00<?, ?it/s]\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m   warnings.warn(  # warn only once\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 13:33:34 (running for 01:35:39.03)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:33:39 (running for 01:35:44.05)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████▎                                      | 1/10 [00:10<01:33, 10.39s/it]\n",
      "  0%|                                                   | 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 13:33:44 (running for 01:35:49.06)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:33:49 (running for 01:35:54.09)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████▌                                  | 2/10 [00:20<01:23, 10.41s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 13:33:54 (running for 01:35:59.10)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:33:59 (running for 01:36:04.13)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|████████████▉                              | 3/10 [00:31<01:12, 10.42s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 13:34:04 (running for 01:36:09.14)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:34:09 (running for 01:36:14.16)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|█████████████████▏                         | 4/10 [00:41<01:02, 10.43s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 13:34:14 (running for 01:36:19.18)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:34:19 (running for 01:36:24.20)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████████████████████▌                     | 5/10 [00:52<00:52, 10.43s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 13:34:24 (running for 01:36:29.22)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:34:29 (running for 01:36:34.24)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████████████████████████▊                 | 6/10 [01:02<00:41, 10.43s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 13:34:34 (running for 01:36:39.26)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:34:39 (running for 01:36:44.28)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████████████████████████████             | 7/10 [01:12<00:31, 10.43s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 13:34:44 (running for 01:36:49.30)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:34:49 (running for 01:36:54.32)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|██████████████████████████████████▍        | 8/10 [01:23<00:20, 10.43s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 13:34:54 (running for 01:36:59.34)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:34:59 (running for 01:37:04.36)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|██████████████████████████████████████▋    | 9/10 [01:33<00:10, 10.43s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 13:35:04 (running for 01:37:09.37)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:35:09 (running for 01:37:14.39)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - model initialization done -> loss fn initialization\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - reading data\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - reading data done -> model initialization\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:35:14 (running for 01:37:19.41)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 10/10 [01:44<00:00, 10.43s/it]\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   warnings.warn(  # warn only once\n",
      " 90%|██████████████████████████████████████▋    | 9/10 [01:34<00:10, 10.48s/it]\n",
      "100%|██████████████████████████████████████████| 10/10 [01:44<00:00, 10.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 13:35:19 (running for 01:37:24.44)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m [KSpaceLoss] torch.Size([8, 2001191, 2, 1]) torch.Size([8, 2001191, 2, 1]) None\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - model initialization done -> loss fn initialization\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m [ImageSpaceLoss] torch.Size([156, 156, 156, 2, 1]) torch.Size([156, 156, 156, 2, 1]) None\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - Loss k-space: 1.622 - Loss image space: 0.035 - Loss Wavelet 0.000 - Loss Hankel 0.000 - Loss Casorati 0.000\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - loss fn initialization done -> compute backward pass\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   warnings.warn(  # warn only once\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 13:35:24 (running for 01:37:29.46)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:35:29 (running for 01:37:34.48)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:35:34 (running for 01:37:39.50)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:35:39 (running for 01:37:44.52)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:35:44 (running for 01:37:49.54)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:35:49 (running for 01:37:54.56)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:35:54 (running for 01:37:59.58)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:35:59 (running for 01:38:04.60)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:36:04 (running for 01:38:09.62)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:36:09 (running for 01:38:14.64)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:36:14 (running for 01:38:19.66)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:36:19 (running for 01:38:24.68)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:36:24 (running for 01:38:29.70)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:36:29 (running for 01:38:34.72)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:36:34 (running for 01:38:39.74)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:36:39 (running for 01:38:44.76)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:36:44 (running for 01:38:49.79)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:36:49 (running for 01:38:54.81)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:36:54 (running for 01:38:59.83)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:36:59 (running for 01:39:04.86)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:37:04 (running for 01:39:09.88)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:37:09 (running for 01:39:14.90)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:37:14 (running for 01:39:19.92)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:37:19 (running for 01:39:24.94)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:37:24 (running for 01:39:29.96)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:37:30 (running for 01:39:34.98)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:37:35 (running for 01:39:39.99)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:37:40 (running for 01:39:45.01)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:37:45 (running for 01:39:50.03)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:37:50 (running for 01:39:55.22)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:37:55 (running for 01:40:00.24)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:38:00 (running for 01:40:05.26)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:38:05 (running for 01:40:10.28)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:38:10 (running for 01:40:15.31)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:38:15 (running for 01:40:20.33)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:38:20 (running for 01:40:25.35)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:38:25 (running for 01:40:30.38)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:38:30 (running for 01:40:35.40)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:38:35 (running for 01:40:40.42)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:38:40 (running for 01:40:45.44)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:38:45 (running for 01:40:50.45)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:38:50 (running for 01:40:55.47)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:38:55 (running for 01:41:00.49)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:39:00 (running for 01:41:05.51)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:39:05 (running for 01:41:10.53)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - compute backward pass done -> compute accumulator\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m [KSpaceLoss] torch.Size([8, 2001191, 2, 1]) torch.Size([8, 2001191, 2, 1]) None\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m [ImageSpaceLoss] torch.Size([156, 156, 156, 2, 1]) torch.Size([156, 156, 156, 2, 1]) None\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - Loss k-space: 1.515 - Loss image space: 0.035 - Loss Wavelet 0.000 - Loss Hankel 0.000 - Loss Casorati 0.000\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - loss fn initialization done -> compute backward pass\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/autograd/graph.py:824: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   warnings.warn(  # warn only once\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - Index 0 - Gradient norm: 5.088\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Averaged gradient norm: 1.000\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Iteration: 16 - Elapsed time: 353 - Training loss: ['1.604'] - Validation loss: ['0.000']\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:39:10 (running for 01:41:15.56)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - reading data\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - compute backward pass done -> compute accumulator\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - Index 0 - Gradient norm: 5.718\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:39:15 (running for 01:41:20.58)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - reading data done -> model initialization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/autograd/graph.py:824: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   warnings.warn(  # warn only once\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 13:39:20 (running for 01:41:25.61)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                   | 0/10 [00:00<?, ?it/s]\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m   warnings.warn(  # warn only once\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 13:39:25 (running for 01:41:30.63)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:39:30 (running for 01:41:35.65)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████▎                                      | 1/10 [00:10<01:33, 10.42s/it]\n",
      "  0%|                                                   | 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 13:39:35 (running for 01:41:40.67)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:39:40 (running for 01:41:45.69)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████▌                                  | 2/10 [00:20<01:23, 10.42s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 13:39:45 (running for 01:41:50.71)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:39:50 (running for 01:41:55.73)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|████████████▉                              | 3/10 [00:31<01:12, 10.42s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 13:39:55 (running for 01:42:00.75)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:40:00 (running for 01:42:05.77)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|█████████████████▏                         | 4/10 [00:41<01:02, 10.43s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 13:40:05 (running for 01:42:10.78)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:40:10 (running for 01:42:15.81)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████████████████████▌                     | 5/10 [00:52<00:52, 10.43s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 13:40:15 (running for 01:42:20.82)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:40:20 (running for 01:42:25.84)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████████████████████████▊                 | 6/10 [01:02<00:41, 10.43s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 13:40:25 (running for 01:42:30.86)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:40:30 (running for 01:42:35.88)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:40:35 (running for 01:42:40.90)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████████████████████████████             | 7/10 [01:12<00:31, 10.42s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 13:40:40 (running for 01:42:45.92)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:40:45 (running for 01:42:50.94)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|██████████████████████████████████▍        | 8/10 [01:23<00:20, 10.43s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 13:40:50 (running for 01:42:55.96)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:40:56 (running for 01:43:00.97)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|██████████████████████████████████████▋    | 9/10 [01:33<00:10, 10.44s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 13:41:01 (running for 01:43:05.99)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:41:06 (running for 01:43:11.01)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - model initialization done -> loss fn initialization\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - reading data\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - reading data done -> model initialization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 10/10 [01:44<00:00, 10.43s/it]\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   warnings.warn(  # warn only once\n",
      " 90%|██████████████████████████████████████▋    | 9/10 [01:34<00:10, 10.48s/it]\n",
      "100%|██████████████████████████████████████████| 10/10 [01:44<00:00, 10.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 13:41:11 (running for 01:43:16.03)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m [KSpaceLoss] torch.Size([8, 2001191, 2, 1]) torch.Size([8, 2001191, 2, 1]) None\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - model initialization done -> loss fn initialization\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m [ImageSpaceLoss] torch.Size([156, 156, 156, 2, 1]) torch.Size([156, 156, 156, 2, 1]) None\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - Loss k-space: 1.595 - Loss image space: 0.036 - Loss Wavelet 0.000 - Loss Hankel 0.000 - Loss Casorati 0.000\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - loss fn initialization done -> compute backward pass\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   warnings.warn(  # warn only once\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 13:41:16 (running for 01:43:21.05)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:41:21 (running for 01:43:26.07)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:41:26 (running for 01:43:31.10)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:41:31 (running for 01:43:36.12)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:41:36 (running for 01:43:41.13)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:41:41 (running for 01:43:46.16)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:41:46 (running for 01:43:51.18)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:41:51 (running for 01:43:56.20)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:41:56 (running for 01:44:01.22)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:42:01 (running for 01:44:06.24)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:42:06 (running for 01:44:11.26)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:42:11 (running for 01:44:16.28)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:42:16 (running for 01:44:21.30)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:42:21 (running for 01:44:26.32)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:42:26 (running for 01:44:31.33)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:42:31 (running for 01:44:36.36)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:42:36 (running for 01:44:41.37)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:42:41 (running for 01:44:46.40)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:42:46 (running for 01:44:51.41)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:42:51 (running for 01:44:56.44)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:42:56 (running for 01:45:01.45)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:43:01 (running for 01:45:06.48)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:43:06 (running for 01:45:11.49)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:43:11 (running for 01:45:16.51)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:43:16 (running for 01:45:21.53)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:43:21 (running for 01:45:26.55)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:43:26 (running for 01:45:31.57)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:43:31 (running for 01:45:36.59)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:43:36 (running for 01:45:41.61)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:43:41 (running for 01:45:46.63)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:43:46 (running for 01:45:51.65)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:43:51 (running for 01:45:56.67)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:43:56 (running for 01:46:01.69)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:44:01 (running for 01:46:06.71)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:44:06 (running for 01:46:11.73)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:44:11 (running for 01:46:16.75)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:44:16 (running for 01:46:21.77)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:44:21 (running for 01:46:26.79)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:44:26 (running for 01:46:31.80)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:44:31 (running for 01:46:36.82)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:44:36 (running for 01:46:41.84)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:44:41 (running for 01:46:46.86)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:44:46 (running for 01:46:51.88)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:44:51 (running for 01:46:56.90)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:44:56 (running for 01:47:01.92)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - compute backward pass done -> compute accumulator\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m [KSpaceLoss] torch.Size([8, 2001191, 2, 1]) torch.Size([8, 2001191, 2, 1]) None\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m [ImageSpaceLoss] torch.Size([156, 156, 156, 2, 1]) torch.Size([156, 156, 156, 2, 1]) None\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - Loss k-space: 1.562 - Loss image space: 0.035 - Loss Wavelet 0.000 - Loss Hankel 0.000 - Loss Casorati 0.000\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - loss fn initialization done -> compute backward pass\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/autograd/graph.py:824: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   warnings.warn(  # warn only once\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - Index 0 - Gradient norm: 5.134\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Averaged gradient norm: 1.000\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Iteration: 17 - Elapsed time: 353 - Training loss: ['1.614'] - Validation loss: ['0.000']\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:45:01 (running for 01:47:06.94)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:45:07 (running for 01:47:11.96)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - reading data\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - compute backward pass done -> compute accumulator\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - Index 0 - Gradient norm: 5.409\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - reading data done -> model initialization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/autograd/graph.py:824: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   warnings.warn(  # warn only once\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 13:45:12 (running for 01:47:16.99)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                   | 0/10 [00:00<?, ?it/s]\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m   warnings.warn(  # warn only once\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 13:45:17 (running for 01:47:22.01)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:45:22 (running for 01:47:27.03)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████▎                                      | 1/10 [00:10<01:33, 10.42s/it]\n",
      "  0%|                                                   | 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 13:45:27 (running for 01:47:32.05)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:45:32 (running for 01:47:37.07)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████▌                                  | 2/10 [00:20<01:23, 10.41s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 13:45:37 (running for 01:47:42.09)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:45:42 (running for 01:47:47.11)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|████████████▉                              | 3/10 [00:31<01:12, 10.43s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 13:45:47 (running for 01:47:52.13)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:45:52 (running for 01:47:57.15)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:45:57 (running for 01:48:02.17)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|█████████████████▏                         | 4/10 [00:41<01:02, 10.45s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 13:46:02 (running for 01:48:07.19)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:46:07 (running for 01:48:12.21)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████████████████████▌                     | 5/10 [00:52<00:52, 10.47s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 13:46:12 (running for 01:48:17.23)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:46:17 (running for 01:48:22.24)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████████████████████████▊                 | 6/10 [01:02<00:41, 10.47s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 13:46:22 (running for 01:48:27.27)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:46:27 (running for 01:48:32.28)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████████████████████████████             | 7/10 [01:13<00:31, 10.48s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 13:46:32 (running for 01:48:37.31)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:46:37 (running for 01:48:42.32)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|██████████████████████████████████▍        | 8/10 [01:23<00:20, 10.48s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 13:46:42 (running for 01:48:47.34)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:46:47 (running for 01:48:52.36)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|██████████████████████████████████████▋    | 9/10 [01:34<00:10, 10.49s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 13:46:52 (running for 01:48:57.38)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:46:57 (running for 01:49:02.40)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - model initialization done -> loss fn initialization\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - reading data\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - reading data done -> model initialization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 10/10 [01:44<00:00, 10.47s/it]\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m   warnings.warn(  # warn only once\n",
      " 90%|██████████████████████████████████████▋    | 9/10 [01:35<00:10, 10.46s/it]\n",
      "100%|██████████████████████████████████████████| 10/10 [01:45<00:00, 10.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 13:47:02 (running for 01:49:07.42)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:47:07 (running for 01:49:12.44)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m [KSpaceLoss] torch.Size([8, 2001191, 2, 1]) torch.Size([8, 2001191, 2, 1]) None\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - model initialization done -> loss fn initialization\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m [ImageSpaceLoss] torch.Size([156, 156, 156, 2, 1]) torch.Size([156, 156, 156, 2, 1]) None\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - Loss k-space: 1.643 - Loss image space: 0.037 - Loss Wavelet 0.000 - Loss Hankel 0.000 - Loss Casorati 0.000\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - loss fn initialization done -> compute backward pass\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   warnings.warn(  # warn only once\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 13:47:12 (running for 01:49:17.46)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:47:17 (running for 01:49:22.48)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:47:22 (running for 01:49:27.51)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:47:27 (running for 01:49:32.52)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:47:32 (running for 01:49:37.54)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:47:37 (running for 01:49:42.56)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:47:42 (running for 01:49:47.58)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:47:47 (running for 01:49:52.60)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:47:52 (running for 01:49:57.62)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:47:57 (running for 01:50:02.64)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:48:02 (running for 01:50:07.66)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:48:07 (running for 01:50:12.68)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:48:12 (running for 01:50:17.70)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:48:17 (running for 01:50:22.71)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:48:22 (running for 01:50:27.73)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:48:27 (running for 01:50:32.75)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:48:32 (running for 01:50:37.77)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:48:37 (running for 01:50:42.79)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:48:42 (running for 01:50:47.81)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:48:47 (running for 01:50:52.83)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:48:52 (running for 01:50:57.85)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:48:57 (running for 01:51:02.86)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:49:02 (running for 01:51:07.89)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:49:07 (running for 01:51:12.90)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:49:12 (running for 01:51:17.93)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:49:17 (running for 01:51:22.94)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:49:23 (running for 01:51:27.96)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:49:28 (running for 01:51:32.98)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:49:33 (running for 01:51:38.00)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:49:38 (running for 01:51:43.02)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:49:43 (running for 01:51:48.04)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:49:48 (running for 01:51:53.06)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:49:53 (running for 01:51:58.08)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:49:58 (running for 01:52:03.09)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:50:03 (running for 01:52:08.11)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:50:08 (running for 01:52:13.13)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:50:13 (running for 01:52:18.15)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:50:18 (running for 01:52:23.17)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:50:23 (running for 01:52:28.19)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:50:28 (running for 01:52:33.21)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:50:33 (running for 01:52:38.23)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:50:38 (running for 01:52:43.25)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:50:43 (running for 01:52:48.27)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:50:48 (running for 01:52:53.29)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - compute backward pass done -> compute accumulator\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m [KSpaceLoss] torch.Size([8, 2001191, 2, 1]) torch.Size([8, 2001191, 2, 1]) None\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m [ImageSpaceLoss] torch.Size([156, 156, 156, 2, 1]) torch.Size([156, 156, 156, 2, 1]) None\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - Loss k-space: 1.564 - Loss image space: 0.036 - Loss Wavelet 0.000 - Loss Hankel 0.000 - Loss Casorati 0.000\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - loss fn initialization done -> compute backward pass\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/autograd/graph.py:824: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   warnings.warn(  # warn only once\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - Index 0 - Gradient norm: 5.005\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Averaged gradient norm: 1.000\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Iteration: 18 - Elapsed time: 353 - Training loss: ['1.640'] - Validation loss: ['0.000']\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:50:53 (running for 01:52:58.31)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:50:58 (running for 01:53:03.33)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - reading data\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - compute backward pass done -> compute accumulator\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - Index 0 - Gradient norm: 5.251\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - reading data done -> model initialization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/autograd/graph.py:824: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   warnings.warn(  # warn only once\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 13:51:03 (running for 01:53:08.36)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:51:08 (running for 01:53:13.38)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                   | 0/10 [00:00<?, ?it/s]\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m   warnings.warn(  # warn only once\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 13:51:13 (running for 01:53:18.40)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:51:18 (running for 01:53:23.42)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████▎                                      | 1/10 [00:10<01:33, 10.41s/it]\n",
      "  0%|                                                   | 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 13:51:23 (running for 01:53:28.44)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:51:28 (running for 01:53:33.46)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████▌                                  | 2/10 [00:20<01:23, 10.41s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 13:51:33 (running for 01:53:38.48)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:51:38 (running for 01:53:43.50)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|████████████▉                              | 3/10 [00:31<01:12, 10.42s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 13:51:43 (running for 01:53:48.52)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:51:48 (running for 01:53:53.54)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|█████████████████▏                         | 4/10 [00:41<01:02, 10.42s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 13:51:53 (running for 01:53:58.56)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:51:58 (running for 01:54:03.58)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████████████████████▌                     | 5/10 [00:52<00:52, 10.43s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 13:52:03 (running for 01:54:08.60)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:52:08 (running for 01:54:13.62)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████████████████████████▊                 | 6/10 [01:02<00:41, 10.43s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 13:52:13 (running for 01:54:18.64)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:52:18 (running for 01:54:23.66)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████████████████████████████             | 7/10 [01:13<00:31, 10.44s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 13:52:23 (running for 01:54:28.68)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:52:28 (running for 01:54:33.69)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|██████████████████████████████████▍        | 8/10 [01:23<00:20, 10.44s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 13:52:33 (running for 01:54:38.71)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:52:38 (running for 01:54:43.73)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|██████████████████████████████████████▋    | 9/10 [01:33<00:10, 10.44s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 13:52:43 (running for 01:54:48.75)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:52:48 (running for 01:54:53.77)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - model initialization done -> loss fn initialization\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - reading data\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - reading data done -> model initialization\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:52:53 (running for 01:54:58.79)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 10/10 [01:44<00:00, 10.44s/it]\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   warnings.warn(  # warn only once\n",
      " 90%|██████████████████████████████████████▋    | 9/10 [01:34<00:10, 10.49s/it]\n",
      "100%|██████████████████████████████████████████| 10/10 [01:44<00:00, 10.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 13:52:58 (running for 01:55:03.81)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m [KSpaceLoss] torch.Size([8, 2001191, 2, 1]) torch.Size([8, 2001191, 2, 1]) None\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - model initialization done -> loss fn initialization\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m [ImageSpaceLoss] torch.Size([156, 156, 156, 2, 1]) torch.Size([156, 156, 156, 2, 1]) None\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - Loss k-space: 1.576 - Loss image space: 0.036 - Loss Wavelet 0.000 - Loss Hankel 0.000 - Loss Casorati 0.000\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - loss fn initialization done -> compute backward pass\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   warnings.warn(  # warn only once\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 13:53:03 (running for 01:55:08.83)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:53:08 (running for 01:55:13.85)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:53:13 (running for 01:55:18.88)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:53:18 (running for 01:55:23.89)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:53:23 (running for 01:55:28.92)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:53:28 (running for 01:55:33.93)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:53:33 (running for 01:55:38.96)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:53:39 (running for 01:55:43.97)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:53:44 (running for 01:55:48.99)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:53:49 (running for 01:55:54.01)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:53:54 (running for 01:55:59.04)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:53:59 (running for 01:56:04.05)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:54:04 (running for 01:56:09.07)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:54:09 (running for 01:56:14.09)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:54:14 (running for 01:56:19.11)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:54:19 (running for 01:56:24.13)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:54:24 (running for 01:56:29.15)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:54:29 (running for 01:56:34.17)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:54:34 (running for 01:56:39.19)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:54:39 (running for 01:56:44.21)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:54:44 (running for 01:56:49.23)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:54:49 (running for 01:56:54.25)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:54:54 (running for 01:56:59.27)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:54:59 (running for 01:57:04.29)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:55:04 (running for 01:57:09.31)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:55:09 (running for 01:57:14.33)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:55:14 (running for 01:57:19.35)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:55:19 (running for 01:57:24.36)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:55:24 (running for 01:57:29.38)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:55:29 (running for 01:57:34.40)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:55:34 (running for 01:57:39.42)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:55:39 (running for 01:57:44.44)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:55:44 (running for 01:57:49.46)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:55:49 (running for 01:57:54.48)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:55:54 (running for 01:57:59.50)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:55:59 (running for 01:58:04.52)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:56:04 (running for 01:58:09.54)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:56:09 (running for 01:58:14.55)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:56:14 (running for 01:58:19.58)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:56:19 (running for 01:58:24.59)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:56:24 (running for 01:58:29.61)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:56:29 (running for 01:58:34.63)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:56:34 (running for 01:58:39.65)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:56:39 (running for 01:58:44.67)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:56:44 (running for 01:58:49.69)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - compute backward pass done -> compute accumulator\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m [KSpaceLoss] torch.Size([8, 2001191, 2, 1]) torch.Size([8, 2001191, 2, 1]) None\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m [ImageSpaceLoss] torch.Size([156, 156, 156, 2, 1]) torch.Size([156, 156, 156, 2, 1]) None\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - Loss k-space: 1.566 - Loss image space: 0.035 - Loss Wavelet 0.000 - Loss Hankel 0.000 - Loss Casorati 0.000\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - loss fn initialization done -> compute backward pass\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/autograd/graph.py:824: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m   warnings.warn(  # warn only once\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - Index 0 - Gradient norm: 5.037\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Averaged gradient norm: 1.000\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Creating untagged checkpoint ...\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m 2025-09-29 13:56:48 Schedule checkpoint save with tag:  ...\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m 2025-09-29 13:56:48 Saved checkpoint to buffer 0.0 seconds\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Iteration: 19 - Elapsed time: 355 - Training loss: ['1.606'] - Validation loss: ['0.000']\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m 2025-09-29 13:56:48 Saved buffer to filesystem in 0.1 seconds\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m 2025-09-29 13:56:48 Completed saving checkpoint.\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:56:49 (running for 01:58:54.71)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:56:54 (running for 01:58:59.73)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - reading data\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - compute backward pass done -> compute accumulator\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - Index 0 - Gradient norm: 5.592\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - reading data done -> model initialization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/autograd/graph.py:824: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   warnings.warn(  # warn only once\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 13:56:59 (running for 01:59:04.75)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:57:04 (running for 01:59:09.78)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                   | 0/10 [00:00<?, ?it/s]\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m   warnings.warn(  # warn only once\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 13:57:09 (running for 01:59:14.80)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:57:14 (running for 01:59:19.82)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████▎                                      | 1/10 [00:10<01:33, 10.38s/it]\n",
      "  0%|                                                   | 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 13:57:19 (running for 01:59:24.83)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:57:24 (running for 01:59:29.85)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████▌                                  | 2/10 [00:20<01:23, 10.41s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 13:57:29 (running for 01:59:34.87)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:57:34 (running for 01:59:39.89)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|████████████▉                              | 3/10 [00:31<01:12, 10.42s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 13:57:39 (running for 01:59:44.91)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:57:44 (running for 01:59:49.93)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|█████████████████▏                         | 4/10 [00:41<01:02, 10.42s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 13:57:49 (running for 01:59:54.95)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:57:55 (running for 01:59:59.97)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████████████████████▌                     | 5/10 [00:52<00:52, 10.43s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 13:58:00 (running for 02:00:04.99)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:58:05 (running for 02:00:10.01)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████████████████████████▊                 | 6/10 [01:02<00:41, 10.43s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 13:58:10 (running for 02:00:15.02)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:58:15 (running for 02:00:20.04)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████████████████████████████             | 7/10 [01:12<00:31, 10.43s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 13:58:20 (running for 02:00:25.06)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:58:25 (running for 02:00:30.08)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|██████████████████████████████████▍        | 8/10 [01:23<00:20, 10.43s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 13:58:30 (running for 02:00:35.10)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:58:35 (running for 02:00:40.12)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|██████████████████████████████████████▋    | 9/10 [01:33<00:10, 10.43s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 13:58:40 (running for 02:00:45.14)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:58:45 (running for 02:00:50.16)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:58:50 (running for 02:00:55.18)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - model initialization done -> loss fn initialization\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - reading data\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - reading data done -> model initialization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 10/10 [01:44<00:00, 10.43s/it]\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   warnings.warn(  # warn only once\n",
      " 90%|██████████████████████████████████████▋    | 9/10 [01:34<00:10, 10.48s/it]\n",
      "100%|██████████████████████████████████████████| 10/10 [01:44<00:00, 10.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 13:58:55 (running for 02:01:00.20)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m [KSpaceLoss] torch.Size([8, 2001191, 2, 1]) torch.Size([8, 2001191, 2, 1]) None\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - model initialization done -> loss fn initialization\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m [ImageSpaceLoss] torch.Size([156, 156, 156, 2, 1]) torch.Size([156, 156, 156, 2, 1]) None\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - Loss k-space: 1.655 - Loss image space: 0.036 - Loss Wavelet 0.000 - Loss Hankel 0.000 - Loss Casorati 0.000\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - loss fn initialization done -> compute backward pass\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   warnings.warn(  # warn only once\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 13:59:00 (running for 02:01:05.23)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:59:05 (running for 02:01:10.38)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:59:10 (running for 02:01:15.40)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:59:15 (running for 02:01:20.42)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:59:20 (running for 02:01:25.44)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:59:25 (running for 02:01:30.46)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:59:30 (running for 02:01:35.49)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:59:35 (running for 02:01:40.51)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:59:40 (running for 02:01:45.53)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:59:45 (running for 02:01:50.55)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:59:50 (running for 02:01:55.57)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 13:59:55 (running for 02:02:00.59)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:00:00 (running for 02:02:05.61)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:00:05 (running for 02:02:10.63)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:00:10 (running for 02:02:15.65)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:00:15 (running for 02:02:20.68)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:00:20 (running for 02:02:25.70)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:00:25 (running for 02:02:30.72)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:00:30 (running for 02:02:35.74)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:00:35 (running for 02:02:40.77)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:00:40 (running for 02:02:45.79)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:00:45 (running for 02:02:50.81)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:00:50 (running for 02:02:55.83)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:00:55 (running for 02:03:00.85)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:01:00 (running for 02:03:05.87)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:01:05 (running for 02:03:10.89)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:01:10 (running for 02:03:15.91)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:01:15 (running for 02:03:20.93)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:01:20 (running for 02:03:25.95)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:01:26 (running for 02:03:30.97)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:01:31 (running for 02:03:35.99)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:01:36 (running for 02:03:41.01)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:01:41 (running for 02:03:46.03)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:01:46 (running for 02:03:51.05)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:01:51 (running for 02:03:56.07)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:01:56 (running for 02:04:01.09)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:02:01 (running for 02:04:06.11)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:02:06 (running for 02:04:11.13)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:02:11 (running for 02:04:16.15)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:02:16 (running for 02:04:21.17)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:02:21 (running for 02:04:26.19)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:02:26 (running for 02:04:31.21)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:02:31 (running for 02:04:36.23)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:02:36 (running for 02:04:41.25)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:02:41 (running for 02:04:46.27)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - compute backward pass done -> compute accumulator\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m [KSpaceLoss] torch.Size([8, 2001191, 2, 1]) torch.Size([8, 2001191, 2, 1]) None\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m [ImageSpaceLoss] torch.Size([156, 156, 156, 2, 1]) torch.Size([156, 156, 156, 2, 1]) None\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - Loss k-space: 1.559 - Loss image space: 0.036 - Loss Wavelet 0.000 - Loss Hankel 0.000 - Loss Casorati 0.000\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - loss fn initialization done -> compute backward pass\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/autograd/graph.py:824: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   warnings.warn(  # warn only once\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - Index 0 - Gradient norm: 5.017\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Averaged gradient norm: 1.000\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Iteration: 20 - Elapsed time: 354 - Training loss: ['1.643'] - Validation loss: ['0.000']\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:02:46 (running for 02:04:51.29)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - reading data\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - compute backward pass done -> compute accumulator\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - Index 0 - Gradient norm: 5.189\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:02:51 (running for 02:04:56.31)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - reading data done -> model initialization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/autograd/graph.py:824: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   warnings.warn(  # warn only once\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 14:02:56 (running for 02:05:01.34)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                   | 0/10 [00:00<?, ?it/s]\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m   warnings.warn(  # warn only once\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 14:03:01 (running for 02:05:06.36)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:03:06 (running for 02:05:11.38)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████▎                                      | 1/10 [00:10<01:33, 10.42s/it]\n",
      "  0%|                                                   | 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 14:03:11 (running for 02:05:16.40)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:03:16 (running for 02:05:21.42)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████▌                                  | 2/10 [00:20<01:23, 10.40s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 14:03:21 (running for 02:05:26.44)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:03:26 (running for 02:05:31.47)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|████████████▉                              | 3/10 [00:31<01:12, 10.41s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 14:03:31 (running for 02:05:36.49)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:03:36 (running for 02:05:41.51)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|█████████████████▏                         | 4/10 [00:41<01:02, 10.43s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 14:03:41 (running for 02:05:46.53)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:03:46 (running for 02:05:51.55)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:03:51 (running for 02:05:56.57)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████████████████████▌                     | 5/10 [00:52<00:52, 10.43s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 14:03:56 (running for 02:06:01.59)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:04:01 (running for 02:06:06.61)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████████████████████████▊                 | 6/10 [01:02<00:41, 10.42s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 14:04:06 (running for 02:06:11.63)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:04:11 (running for 02:06:16.65)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████████████████████████████             | 7/10 [01:12<00:31, 10.43s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 14:04:16 (running for 02:06:21.67)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:04:21 (running for 02:06:26.69)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|██████████████████████████████████▍        | 8/10 [01:23<00:20, 10.43s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 14:04:26 (running for 02:06:31.71)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:04:31 (running for 02:06:36.72)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|██████████████████████████████████████▋    | 9/10 [01:33<00:10, 10.43s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 14:04:36 (running for 02:06:41.75)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:04:41 (running for 02:06:46.76)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - model initialization done -> loss fn initialization\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - reading data\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - reading data done -> model initialization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 10/10 [01:44<00:00, 10.43s/it]\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   warnings.warn(  # warn only once\n",
      " 90%|██████████████████████████████████████▋    | 9/10 [01:34<00:10, 10.48s/it]\n",
      "100%|██████████████████████████████████████████| 10/10 [01:44<00:00, 10.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 14:04:46 (running for 02:06:51.78)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m [KSpaceLoss] torch.Size([8, 2001191, 2, 1]) torch.Size([8, 2001191, 2, 1]) None\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - model initialization done -> loss fn initialization\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m [ImageSpaceLoss] torch.Size([156, 156, 156, 2, 1]) torch.Size([156, 156, 156, 2, 1]) None\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:04:51 (running for 02:06:56.80)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - Loss k-space: 1.622 - Loss image space: 0.035 - Loss Wavelet 0.000 - Loss Hankel 0.000 - Loss Casorati 0.000\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - loss fn initialization done -> compute backward pass\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m   warnings.warn(  # warn only once\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 14:04:56 (running for 02:07:01.83)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:05:01 (running for 02:07:06.85)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:05:06 (running for 02:07:11.87)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:05:11 (running for 02:07:16.89)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:05:16 (running for 02:07:21.91)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:05:21 (running for 02:07:26.93)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:05:26 (running for 02:07:31.95)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:05:32 (running for 02:07:36.97)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:05:37 (running for 02:07:41.99)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:05:42 (running for 02:07:47.00)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:05:47 (running for 02:07:52.03)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:05:52 (running for 02:07:57.04)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:05:57 (running for 02:08:02.06)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:06:02 (running for 02:08:07.08)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:06:07 (running for 02:08:12.11)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:06:12 (running for 02:08:17.12)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:06:17 (running for 02:08:22.15)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:06:22 (running for 02:08:27.16)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:06:27 (running for 02:08:32.19)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:06:32 (running for 02:08:37.20)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:06:37 (running for 02:08:42.22)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:06:42 (running for 02:08:47.24)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:06:47 (running for 02:08:52.26)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:06:52 (running for 02:08:57.28)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:06:57 (running for 02:09:02.31)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:07:02 (running for 02:09:07.32)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:07:07 (running for 02:09:12.35)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:07:12 (running for 02:09:17.37)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:07:17 (running for 02:09:22.39)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:07:22 (running for 02:09:27.41)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:07:27 (running for 02:09:32.43)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:07:32 (running for 02:09:37.44)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:07:37 (running for 02:09:42.46)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:07:42 (running for 02:09:47.48)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:07:47 (running for 02:09:52.51)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:07:52 (running for 02:09:57.52)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:07:57 (running for 02:10:02.54)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:08:02 (running for 02:10:07.56)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:08:07 (running for 02:10:12.58)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:08:12 (running for 02:10:17.60)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:08:17 (running for 02:10:22.62)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:08:22 (running for 02:10:27.64)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:08:27 (running for 02:10:32.66)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:08:32 (running for 02:10:37.68)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - compute backward pass done -> compute accumulator\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m [KSpaceLoss] torch.Size([8, 2001191, 2, 1]) torch.Size([8, 2001191, 2, 1]) None\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m [ImageSpaceLoss] torch.Size([156, 156, 156, 2, 1]) torch.Size([156, 156, 156, 2, 1]) None\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - Loss k-space: 1.585 - Loss image space: 0.037 - Loss Wavelet 0.000 - Loss Hankel 0.000 - Loss Casorati 0.000\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - loss fn initialization done -> compute backward pass\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/autograd/graph.py:824: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   warnings.warn(  # warn only once\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - Index 0 - Gradient norm: 5.045\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Averaged gradient norm: 1.000\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Iteration: 21 - Elapsed time: 354 - Training loss: ['1.640'] - Validation loss: ['0.000']\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:08:37 (running for 02:10:42.70)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:08:42 (running for 02:10:47.72)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - reading data\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - compute backward pass done -> compute accumulator\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - Index 0 - Gradient norm: 5.085\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - reading data done -> model initialization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/autograd/graph.py:824: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m   warnings.warn(  # warn only once\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 14:08:47 (running for 02:10:52.75)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:08:52 (running for 02:10:57.77)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                   | 0/10 [00:00<?, ?it/s]\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   warnings.warn(  # warn only once\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 14:08:57 (running for 02:11:02.79)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:09:02 (running for 02:11:07.81)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████▎                                      | 1/10 [00:10<01:33, 10.41s/it]\n",
      "  0%|                                                   | 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 14:09:07 (running for 02:11:12.83)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:09:12 (running for 02:11:17.85)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████▌                                  | 2/10 [00:20<01:23, 10.41s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 14:09:17 (running for 02:11:22.87)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:09:22 (running for 02:11:27.89)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|████████████▉                              | 3/10 [00:31<01:12, 10.41s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 14:09:27 (running for 02:11:32.92)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:09:32 (running for 02:11:37.93)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|█████████████████▏                         | 4/10 [00:41<01:02, 10.43s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 14:09:37 (running for 02:11:42.96)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:09:43 (running for 02:11:47.98)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████████████████████▌                     | 5/10 [00:52<00:52, 10.43s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 14:09:48 (running for 02:11:53.00)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:09:53 (running for 02:11:58.02)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████████████████████████▊                 | 6/10 [01:02<00:41, 10.43s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 14:09:58 (running for 02:12:03.04)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:10:03 (running for 02:12:08.06)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████████████████████████████             | 7/10 [01:13<00:31, 10.43s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 14:10:08 (running for 02:12:13.08)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:10:13 (running for 02:12:18.10)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|██████████████████████████████████▍        | 8/10 [01:23<00:20, 10.44s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 14:10:18 (running for 02:12:23.12)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:10:23 (running for 02:12:28.14)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|██████████████████████████████████████▋    | 9/10 [01:33<00:10, 10.45s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 14:10:28 (running for 02:12:33.16)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:10:33 (running for 02:12:38.17)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - model initialization done -> loss fn initialization\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - reading data\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - reading data done -> model initialization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 10/10 [01:44<00:00, 10.44s/it]\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   warnings.warn(  # warn only once\n",
      " 90%|██████████████████████████████████████▋    | 9/10 [01:34<00:10, 10.48s/it]\n",
      "100%|██████████████████████████████████████████| 10/10 [01:44<00:00, 10.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 14:10:38 (running for 02:12:43.20)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:10:43 (running for 02:12:48.22)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m [KSpaceLoss] torch.Size([8, 2001191, 2, 1]) torch.Size([8, 2001191, 2, 1]) None\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - model initialization done -> loss fn initialization\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m [ImageSpaceLoss] torch.Size([156, 156, 156, 2, 1]) torch.Size([156, 156, 156, 2, 1]) None\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - Loss k-space: 1.606 - Loss image space: 0.036 - Loss Wavelet 0.000 - Loss Hankel 0.000 - Loss Casorati 0.000\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - loss fn initialization done -> compute backward pass\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   warnings.warn(  # warn only once\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 14:10:48 (running for 02:12:53.24)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:10:53 (running for 02:12:58.26)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:10:58 (running for 02:13:03.29)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:11:03 (running for 02:13:08.31)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:11:08 (running for 02:13:13.33)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:11:13 (running for 02:13:18.35)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:11:18 (running for 02:13:23.37)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:11:23 (running for 02:13:28.39)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:11:28 (running for 02:13:33.41)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:11:33 (running for 02:13:38.43)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:11:38 (running for 02:13:43.45)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:11:43 (running for 02:13:48.47)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:11:48 (running for 02:13:53.49)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:11:53 (running for 02:13:58.50)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:11:58 (running for 02:14:03.52)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:12:03 (running for 02:14:08.54)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:12:08 (running for 02:14:13.56)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:12:13 (running for 02:14:18.58)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:12:18 (running for 02:14:23.60)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:12:23 (running for 02:14:28.62)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:12:28 (running for 02:14:33.64)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:12:33 (running for 02:14:38.66)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:12:38 (running for 02:14:43.68)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:12:43 (running for 02:14:48.69)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:12:48 (running for 02:14:53.81)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:12:53 (running for 02:14:58.83)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:12:58 (running for 02:15:03.85)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:13:03 (running for 02:15:08.87)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:13:08 (running for 02:15:13.89)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:13:13 (running for 02:15:18.91)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:13:18 (running for 02:15:23.93)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:13:23 (running for 02:15:28.95)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:13:29 (running for 02:15:33.97)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:13:34 (running for 02:15:38.99)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:13:39 (running for 02:15:44.01)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:13:44 (running for 02:15:49.02)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:13:49 (running for 02:15:54.04)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:13:54 (running for 02:15:59.06)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:13:59 (running for 02:16:04.08)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:14:04 (running for 02:16:09.10)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:14:09 (running for 02:16:14.12)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:14:14 (running for 02:16:19.14)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:14:19 (running for 02:16:24.16)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:14:24 (running for 02:16:29.18)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:14:29 (running for 02:16:34.20)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - compute backward pass done -> compute accumulator\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m [KSpaceLoss] torch.Size([8, 2001191, 2, 1]) torch.Size([8, 2001191, 2, 1]) None\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m [ImageSpaceLoss] torch.Size([156, 156, 156, 2, 1]) torch.Size([156, 156, 156, 2, 1]) None\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - Loss k-space: 1.587 - Loss image space: 0.035 - Loss Wavelet 0.000 - Loss Hankel 0.000 - Loss Casorati 0.000\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - loss fn initialization done -> compute backward pass\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/autograd/graph.py:824: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m   warnings.warn(  # warn only once\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - Index 0 - Gradient norm: 4.967\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Averaged gradient norm: 1.000\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Iteration: 22 - Elapsed time: 354 - Training loss: ['1.632'] - Validation loss: ['0.000']\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:14:34 (running for 02:16:39.22)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:14:39 (running for 02:16:44.24)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - reading data\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - compute backward pass done -> compute accumulator\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - Index 0 - Gradient norm: 5.326\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - reading data done -> model initialization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/autograd/graph.py:824: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   warnings.warn(  # warn only once\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 14:14:44 (running for 02:16:49.26)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                   | 0/10 [00:00<?, ?it/s]\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m   warnings.warn(  # warn only once\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 14:14:49 (running for 02:16:54.29)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:14:54 (running for 02:16:59.31)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████▎                                      | 1/10 [00:10<01:33, 10.40s/it]\n",
      "  0%|                                                   | 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 14:14:59 (running for 02:17:04.33)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:15:04 (running for 02:17:09.35)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████▌                                  | 2/10 [00:20<01:23, 10.42s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 14:15:09 (running for 02:17:14.37)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:15:14 (running for 02:17:19.39)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|████████████▉                              | 3/10 [00:31<01:12, 10.42s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 14:15:19 (running for 02:17:24.41)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:15:24 (running for 02:17:29.43)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|█████████████████▏                         | 4/10 [00:41<01:02, 10.42s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 14:15:29 (running for 02:17:34.45)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:15:34 (running for 02:17:39.46)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:15:39 (running for 02:17:44.48)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████████████████████▌                     | 5/10 [00:52<00:52, 10.43s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 14:15:44 (running for 02:17:49.50)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:15:49 (running for 02:17:54.52)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████████████████████████▊                 | 6/10 [01:02<00:41, 10.43s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 14:15:54 (running for 02:17:59.54)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:15:59 (running for 02:18:04.56)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████████████████████████████             | 7/10 [01:12<00:31, 10.44s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 14:16:04 (running for 02:18:09.58)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:16:09 (running for 02:18:14.60)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|██████████████████████████████████▍        | 8/10 [01:23<00:20, 10.44s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 14:16:14 (running for 02:18:19.62)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:16:19 (running for 02:18:24.64)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|██████████████████████████████████████▋    | 9/10 [01:33<00:10, 10.44s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 14:16:24 (running for 02:18:29.65)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:16:29 (running for 02:18:34.67)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - model initialization done -> loss fn initialization\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - reading data\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - reading data done -> model initialization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 10/10 [01:44<00:00, 10.43s/it]\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   warnings.warn(  # warn only once\n",
      " 90%|██████████████████████████████████████▋    | 9/10 [01:34<00:10, 10.48s/it]\n",
      "100%|██████████████████████████████████████████| 10/10 [01:44<00:00, 10.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 14:16:34 (running for 02:18:39.68)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m [KSpaceLoss] torch.Size([8, 2001191, 2, 1]) torch.Size([8, 2001191, 2, 1]) None\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - model initialization done -> loss fn initialization\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m [ImageSpaceLoss] torch.Size([156, 156, 156, 2, 1]) torch.Size([156, 156, 156, 2, 1]) None\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - Loss k-space: 1.606 - Loss image space: 0.037 - Loss Wavelet 0.000 - Loss Hankel 0.000 - Loss Casorati 0.000\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - loss fn initialization done -> compute backward pass\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:16:39 (running for 02:18:44.71)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   warnings.warn(  # warn only once\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 14:16:44 (running for 02:18:49.73)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:16:49 (running for 02:18:54.75)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:16:54 (running for 02:18:59.77)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:16:59 (running for 02:19:04.79)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:17:04 (running for 02:19:09.81)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:17:09 (running for 02:19:14.83)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:17:14 (running for 02:19:19.85)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:17:19 (running for 02:19:24.87)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:17:24 (running for 02:19:29.89)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:17:29 (running for 02:19:34.91)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:17:34 (running for 02:19:39.92)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:17:39 (running for 02:19:44.95)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:17:45 (running for 02:19:49.96)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:17:50 (running for 02:19:54.98)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:17:55 (running for 02:20:00.00)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:18:00 (running for 02:20:05.02)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:18:05 (running for 02:20:10.04)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:18:10 (running for 02:20:15.06)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:18:15 (running for 02:20:20.08)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:18:20 (running for 02:20:25.10)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:18:25 (running for 02:20:30.12)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:18:30 (running for 02:20:35.14)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:18:35 (running for 02:20:40.16)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:18:40 (running for 02:20:45.18)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:18:45 (running for 02:20:50.20)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:18:50 (running for 02:20:55.22)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:18:55 (running for 02:21:00.23)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:19:00 (running for 02:21:05.25)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:19:05 (running for 02:21:10.27)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:19:10 (running for 02:21:15.29)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:19:15 (running for 02:21:20.31)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:19:20 (running for 02:21:25.33)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:19:25 (running for 02:21:30.35)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:19:30 (running for 02:21:35.37)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:19:35 (running for 02:21:40.39)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:19:40 (running for 02:21:45.41)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:19:45 (running for 02:21:50.42)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:19:50 (running for 02:21:55.44)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:19:55 (running for 02:22:00.46)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:20:00 (running for 02:22:05.48)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:20:05 (running for 02:22:10.50)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:20:10 (running for 02:22:15.52)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:20:15 (running for 02:22:20.53)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:20:20 (running for 02:22:25.55)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - compute backward pass done -> compute accumulator\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m [KSpaceLoss] torch.Size([8, 2001191, 2, 1]) torch.Size([8, 2001191, 2, 1]) None\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m [ImageSpaceLoss] torch.Size([156, 156, 156, 2, 1]) torch.Size([156, 156, 156, 2, 1]) None\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - Loss k-space: 1.572 - Loss image space: 0.035 - Loss Wavelet 0.000 - Loss Hankel 0.000 - Loss Casorati 0.000\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - loss fn initialization done -> compute backward pass\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/autograd/graph.py:824: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   warnings.warn(  # warn only once\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - Index 0 - Gradient norm: 5.002\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Averaged gradient norm: 1.000\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Iteration: 23 - Elapsed time: 352 - Training loss: ['1.625'] - Validation loss: ['0.000']\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:20:25 (running for 02:22:30.57)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:20:30 (running for 02:22:35.59)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - reading data\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - compute backward pass done -> compute accumulator\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - Index 0 - Gradient norm: 5.162\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - reading data done -> model initialization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/autograd/graph.py:824: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   warnings.warn(  # warn only once\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 14:20:35 (running for 02:22:40.61)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:20:40 (running for 02:22:45.64)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                   | 0/10 [00:00<?, ?it/s]\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m   warnings.warn(  # warn only once\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 14:20:45 (running for 02:22:50.65)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:20:50 (running for 02:22:55.67)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████▎                                      | 1/10 [00:10<01:33, 10.42s/it]\n",
      "  0%|                                                   | 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 14:20:55 (running for 02:23:00.69)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:21:00 (running for 02:23:05.71)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████▌                                  | 2/10 [00:20<01:23, 10.42s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 14:21:05 (running for 02:23:10.73)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:21:10 (running for 02:23:15.75)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|████████████▉                              | 3/10 [00:31<01:12, 10.41s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 14:21:15 (running for 02:23:20.77)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:21:20 (running for 02:23:25.79)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|█████████████████▏                         | 4/10 [00:41<01:02, 10.42s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 14:21:25 (running for 02:23:30.81)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:21:30 (running for 02:23:35.83)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████████████████████▌                     | 5/10 [00:52<00:52, 10.43s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 14:21:35 (running for 02:23:40.85)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:21:40 (running for 02:23:45.87)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████████████████████████▊                 | 6/10 [01:02<00:41, 10.44s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 14:21:45 (running for 02:23:50.88)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:21:50 (running for 02:23:55.90)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████████████████████████████             | 7/10 [01:13<00:31, 10.44s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 14:21:55 (running for 02:24:00.92)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:22:00 (running for 02:24:05.94)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|██████████████████████████████████▍        | 8/10 [01:23<00:20, 10.43s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 14:22:06 (running for 02:24:10.96)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:22:11 (running for 02:24:15.98)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|██████████████████████████████████████▋    | 9/10 [01:33<00:10, 10.44s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 14:22:16 (running for 02:24:21.00)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:22:21 (running for 02:24:26.03)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - model initialization done -> loss fn initialization\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - reading data\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - reading data done -> model initialization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 10/10 [01:44<00:00, 10.43s/it]\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   warnings.warn(  # warn only once\n",
      " 90%|██████████████████████████████████████▋    | 9/10 [01:34<00:10, 10.47s/it]\n",
      "100%|██████████████████████████████████████████| 10/10 [01:44<00:00, 10.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 14:22:26 (running for 02:24:31.05)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:22:31 (running for 02:24:36.07)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m [KSpaceLoss] torch.Size([8, 2001191, 2, 1]) torch.Size([8, 2001191, 2, 1]) None\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - model initialization done -> loss fn initialization\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m [ImageSpaceLoss] torch.Size([156, 156, 156, 2, 1]) torch.Size([156, 156, 156, 2, 1]) None\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - Loss k-space: 1.636 - Loss image space: 0.035 - Loss Wavelet 0.000 - Loss Hankel 0.000 - Loss Casorati 0.000\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - loss fn initialization done -> compute backward pass\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   warnings.warn(  # warn only once\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 14:22:36 (running for 02:24:41.09)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:22:41 (running for 02:24:46.11)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:22:46 (running for 02:24:51.13)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:22:51 (running for 02:24:56.15)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:22:56 (running for 02:25:01.17)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:23:01 (running for 02:25:06.19)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:23:06 (running for 02:25:11.21)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:23:11 (running for 02:25:16.24)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:23:16 (running for 02:25:21.25)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:23:21 (running for 02:25:26.28)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:23:26 (running for 02:25:31.29)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:23:31 (running for 02:25:36.31)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:23:36 (running for 02:25:41.33)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:23:41 (running for 02:25:46.35)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:23:46 (running for 02:25:51.37)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:23:51 (running for 02:25:56.39)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:23:56 (running for 02:26:01.41)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:24:01 (running for 02:26:06.44)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:24:06 (running for 02:26:11.46)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:24:11 (running for 02:26:16.48)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:24:16 (running for 02:26:21.50)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:24:21 (running for 02:26:26.52)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:24:26 (running for 02:26:31.54)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:24:31 (running for 02:26:36.56)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:24:36 (running for 02:26:41.58)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:24:41 (running for 02:26:46.60)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:24:46 (running for 02:26:51.62)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:24:51 (running for 02:26:56.64)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:24:56 (running for 02:27:01.66)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:25:01 (running for 02:27:06.68)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:25:06 (running for 02:27:11.70)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:25:11 (running for 02:27:16.72)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:25:16 (running for 02:27:21.74)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:25:21 (running for 02:27:26.76)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:25:26 (running for 02:27:31.78)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:25:31 (running for 02:27:36.80)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:25:36 (running for 02:27:41.82)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:25:41 (running for 02:27:46.84)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:25:46 (running for 02:27:51.86)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:25:51 (running for 02:27:56.88)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:25:56 (running for 02:28:01.90)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:26:01 (running for 02:28:06.92)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:26:06 (running for 02:28:11.94)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:26:12 (running for 02:28:16.96)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:26:17 (running for 02:28:21.98)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - compute backward pass done -> compute accumulator\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m [KSpaceLoss] torch.Size([8, 2001191, 2, 1]) torch.Size([8, 2001191, 2, 1]) None\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m [ImageSpaceLoss] torch.Size([156, 156, 156, 2, 1]) torch.Size([156, 156, 156, 2, 1]) None\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - Loss k-space: 1.537 - Loss image space: 0.035 - Loss Wavelet 0.000 - Loss Hankel 0.000 - Loss Casorati 0.000\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - loss fn initialization done -> compute backward pass\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/autograd/graph.py:824: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   warnings.warn(  # warn only once\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - Index 0 - Gradient norm: 4.886\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Averaged gradient norm: 1.000\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Creating tagged checkpoint ...\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m 2025-09-29 14:26:18 Schedule checkpoint save with tag: _epoch_1 ...\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m 2025-09-29 14:26:18 Saved checkpoint to buffer 0.0 seconds\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Iteration: 24 - Elapsed time: 354 - Training loss: ['1.622'] - Validation loss: ['0.000']\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m 2025-09-29 14:26:18 Saved buffer to filesystem in 0.0 seconds\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m 2025-09-29 14:26:18 Completed saving checkpoint.\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:26:22 (running for 02:28:27.00)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - reading data\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - compute backward pass done -> compute accumulator\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - Index 0 - Gradient norm: 5.155\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - reading data done -> model initialization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/autograd/graph.py:824: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   warnings.warn(  # warn only once\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 14:26:27 (running for 02:28:32.03)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:26:32 (running for 02:28:37.05)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:26:37 (running for 02:28:42.07)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                   | 0/10 [00:00<?, ?it/s]\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m   warnings.warn(  # warn only once\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 14:26:42 (running for 02:28:47.10)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:26:47 (running for 02:28:52.11)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████▎                                      | 1/10 [00:10<01:33, 10.39s/it]\n",
      "  0%|                                                   | 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 14:26:52 (running for 02:28:57.14)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:26:57 (running for 02:29:02.15)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████▌                                  | 2/10 [00:20<01:23, 10.41s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 14:27:02 (running for 02:29:07.18)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:27:07 (running for 02:29:12.19)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|████████████▉                              | 3/10 [00:31<01:12, 10.40s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 14:27:12 (running for 02:29:17.22)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:27:17 (running for 02:29:22.24)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|█████████████████▏                         | 4/10 [00:41<01:02, 10.40s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 14:27:22 (running for 02:29:27.26)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:27:27 (running for 02:29:32.28)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████████████████████▌                     | 5/10 [00:52<00:52, 10.42s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 14:27:32 (running for 02:29:37.30)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:27:37 (running for 02:29:42.31)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████████████████████████▊                 | 6/10 [01:02<00:41, 10.42s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 14:27:42 (running for 02:29:47.34)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:27:47 (running for 02:29:52.35)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████████████████████████████             | 7/10 [01:12<00:31, 10.42s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 14:27:52 (running for 02:29:57.38)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:27:57 (running for 02:30:02.39)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|██████████████████████████████████▍        | 8/10 [01:23<00:20, 10.43s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 14:28:02 (running for 02:30:07.41)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:28:07 (running for 02:30:12.43)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|██████████████████████████████████████▋    | 9/10 [01:33<00:10, 10.43s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 14:28:12 (running for 02:30:17.45)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:28:17 (running for 02:30:22.47)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - model initialization done -> loss fn initialization\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - reading data\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - reading data done -> model initialization\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:28:22 (running for 02:30:27.49)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 10/10 [01:44<00:00, 10.43s/it]\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   warnings.warn(  # warn only once\n",
      " 90%|██████████████████████████████████████▋    | 9/10 [01:34<00:10, 10.48s/it]\n",
      "100%|██████████████████████████████████████████| 10/10 [01:44<00:00, 10.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 14:28:27 (running for 02:30:32.51)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m [KSpaceLoss] torch.Size([8, 2001191, 2, 1]) torch.Size([8, 2001191, 2, 1]) None\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - model initialization done -> loss fn initialization\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m [ImageSpaceLoss] torch.Size([156, 156, 156, 2, 1]) torch.Size([156, 156, 156, 2, 1]) None\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - Loss k-space: 1.628 - Loss image space: 0.036 - Loss Wavelet 0.000 - Loss Hankel 0.000 - Loss Casorati 0.000\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - loss fn initialization done -> compute backward pass\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   warnings.warn(  # warn only once\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 14:28:32 (running for 02:30:37.54)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:28:37 (running for 02:30:42.56)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:28:42 (running for 02:30:47.58)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:28:47 (running for 02:30:52.60)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:28:52 (running for 02:30:57.62)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:28:57 (running for 02:31:02.64)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:29:02 (running for 02:31:07.66)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:29:07 (running for 02:31:12.67)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:29:12 (running for 02:31:17.70)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:29:17 (running for 02:31:22.71)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:29:22 (running for 02:31:27.74)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:29:27 (running for 02:31:32.75)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:29:32 (running for 02:31:37.77)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:29:37 (running for 02:31:42.79)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:29:42 (running for 02:31:47.81)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:29:47 (running for 02:31:52.83)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:29:52 (running for 02:31:57.85)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:29:57 (running for 02:32:02.87)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:30:02 (running for 02:32:07.89)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:30:07 (running for 02:32:12.90)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:30:12 (running for 02:32:17.92)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:30:17 (running for 02:32:22.94)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:30:23 (running for 02:32:27.96)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:30:28 (running for 02:32:32.98)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:30:33 (running for 02:32:38.01)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:30:38 (running for 02:32:43.02)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:30:43 (running for 02:32:48.05)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:30:48 (running for 02:32:53.07)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:30:53 (running for 02:32:58.09)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:30:58 (running for 02:33:03.10)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:31:03 (running for 02:33:08.13)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:31:08 (running for 02:33:13.14)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:31:13 (running for 02:33:18.16)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:31:18 (running for 02:33:23.18)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:31:23 (running for 02:33:28.21)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:31:28 (running for 02:33:33.23)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:31:33 (running for 02:33:38.25)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:31:38 (running for 02:33:43.27)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:31:43 (running for 02:33:48.29)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:31:48 (running for 02:33:53.31)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:31:53 (running for 02:33:58.33)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:31:58 (running for 02:34:03.35)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:32:03 (running for 02:34:08.38)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:32:08 (running for 02:34:13.40)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:32:13 (running for 02:34:18.42)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - compute backward pass done -> compute accumulator\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m [KSpaceLoss] torch.Size([8, 2001191, 2, 1]) torch.Size([8, 2001191, 2, 1]) None\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m [ImageSpaceLoss] torch.Size([156, 156, 156, 2, 1]) torch.Size([156, 156, 156, 2, 1]) None\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - Loss k-space: 1.579 - Loss image space: 0.036 - Loss Wavelet 0.000 - Loss Hankel 0.000 - Loss Casorati 0.000\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - loss fn initialization done -> compute backward pass\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/autograd/graph.py:824: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   warnings.warn(  # warn only once\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - Index 0 - Gradient norm: 4.827\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Averaged gradient norm: 1.000\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Iteration: 25 - Elapsed time: 357 - Training loss: ['1.639'] - Validation loss: ['0.000']\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:32:18 (running for 02:34:23.44)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:32:23 (running for 02:34:28.47)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - reading data\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - compute backward pass done -> compute accumulator\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - Index 0 - Gradient norm: 4.969\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - reading data done -> model initialization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/autograd/graph.py:824: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   warnings.warn(  # warn only once\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 14:32:28 (running for 02:34:33.49)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                   | 0/10 [00:00<?, ?it/s]\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m   warnings.warn(  # warn only once\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 14:32:33 (running for 02:34:38.51)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:32:38 (running for 02:34:43.53)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████▎                                      | 1/10 [00:10<01:33, 10.39s/it]\n",
      "  0%|                                                   | 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 14:32:43 (running for 02:34:48.55)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:32:48 (running for 02:34:53.57)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████▌                                  | 2/10 [00:20<01:23, 10.39s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 14:32:53 (running for 02:34:58.60)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:32:58 (running for 02:35:03.62)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|████████████▉                              | 3/10 [00:31<01:12, 10.40s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 14:33:03 (running for 02:35:08.64)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:33:08 (running for 02:35:13.66)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|█████████████████▏                         | 4/10 [00:41<01:02, 10.41s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 14:33:13 (running for 02:35:18.68)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:33:18 (running for 02:35:23.70)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:33:23 (running for 02:35:28.72)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████████████████████▌                     | 5/10 [00:52<00:52, 10.43s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 14:33:28 (running for 02:35:33.73)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:33:33 (running for 02:35:38.75)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████████████████████████▊                 | 6/10 [01:02<00:41, 10.43s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 14:33:38 (running for 02:35:43.77)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:33:43 (running for 02:35:48.79)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████████████████████████████             | 7/10 [01:12<00:31, 10.43s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 14:33:48 (running for 02:35:53.81)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:33:53 (running for 02:35:58.83)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|██████████████████████████████████▍        | 8/10 [01:23<00:20, 10.44s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 14:33:58 (running for 02:36:03.85)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:34:03 (running for 02:36:08.87)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|██████████████████████████████████████▋    | 9/10 [01:33<00:10, 10.44s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 14:34:08 (running for 02:36:13.89)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:34:13 (running for 02:36:18.91)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - model initialization done -> loss fn initialization\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - reading data\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - reading data done -> model initialization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 10/10 [01:44<00:00, 10.43s/it]\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   warnings.warn(  # warn only once\n",
      " 90%|██████████████████████████████████████▋    | 9/10 [01:34<00:10, 10.48s/it]\n",
      "100%|██████████████████████████████████████████| 10/10 [01:44<00:00, 10.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 14:34:18 (running for 02:36:23.93)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m [KSpaceLoss] torch.Size([8, 2001191, 2, 1]) torch.Size([8, 2001191, 2, 1]) None\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - model initialization done -> loss fn initialization\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m [ImageSpaceLoss] torch.Size([156, 156, 156, 2, 1]) torch.Size([156, 156, 156, 2, 1]) None\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:34:23 (running for 02:36:28.95)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - Loss k-space: 1.653 - Loss image space: 0.034 - Loss Wavelet 0.000 - Loss Hankel 0.000 - Loss Casorati 0.000\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - loss fn initialization done -> compute backward pass\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   warnings.warn(  # warn only once\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 14:34:29 (running for 02:36:33.98)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:34:34 (running for 02:36:39.00)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:34:39 (running for 02:36:44.02)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:34:44 (running for 02:36:49.04)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:34:49 (running for 02:36:54.06)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:34:54 (running for 02:36:59.08)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:34:59 (running for 02:37:04.10)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:35:04 (running for 02:37:09.12)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:35:09 (running for 02:37:14.13)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:35:14 (running for 02:37:19.15)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:35:19 (running for 02:37:24.17)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:35:24 (running for 02:37:29.19)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:35:29 (running for 02:37:34.21)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:35:34 (running for 02:37:39.23)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:35:39 (running for 02:37:44.24)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:35:44 (running for 02:37:49.26)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:35:49 (running for 02:37:54.28)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:35:54 (running for 02:37:59.30)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:35:59 (running for 02:38:04.32)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:36:04 (running for 02:38:09.34)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:36:09 (running for 02:38:14.35)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:36:14 (running for 02:38:19.37)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:36:19 (running for 02:38:24.39)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:36:24 (running for 02:38:29.41)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:36:29 (running for 02:38:34.43)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:36:34 (running for 02:38:39.45)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:36:39 (running for 02:38:44.46)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:36:44 (running for 02:38:49.48)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:36:49 (running for 02:38:54.50)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:36:54 (running for 02:38:59.52)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:36:59 (running for 02:39:04.54)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:37:04 (running for 02:39:09.56)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:37:09 (running for 02:39:14.58)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:37:14 (running for 02:39:19.60)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:37:19 (running for 02:39:24.61)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:37:24 (running for 02:39:29.63)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:37:29 (running for 02:39:34.65)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:37:34 (running for 02:39:39.67)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:37:39 (running for 02:39:44.69)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:37:44 (running for 02:39:49.71)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:37:49 (running for 02:39:54.73)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:37:54 (running for 02:39:59.75)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:37:59 (running for 02:40:04.76)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:38:04 (running for 02:40:09.78)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - compute backward pass done -> compute accumulator\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m [KSpaceLoss] torch.Size([8, 2001191, 2, 1]) torch.Size([8, 2001191, 2, 1]) None\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m [ImageSpaceLoss] torch.Size([156, 156, 156, 2, 1]) torch.Size([156, 156, 156, 2, 1]) None\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - Loss k-space: 1.505 - Loss image space: 0.036 - Loss Wavelet 0.000 - Loss Hankel 0.000 - Loss Casorati 0.000\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - loss fn initialization done -> compute backward pass\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/autograd/graph.py:824: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   warnings.warn(  # warn only once\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 14:38:09 (running for 02:40:14.80)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - Index 0 - Gradient norm: 4.762\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Averaged gradient norm: 1.000\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Iteration: 26 - Elapsed time: 355 - Training loss: ['1.614'] - Validation loss: ['0.000']\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:38:14 (running for 02:40:19.82)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - reading data\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - compute backward pass done -> compute accumulator\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - Index 0 - Gradient norm: 5.065\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:38:19 (running for 02:40:24.85)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - reading data done -> model initialization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/autograd/graph.py:824: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   warnings.warn(  # warn only once\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 14:38:24 (running for 02:40:29.87)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                   | 0/10 [00:00<?, ?it/s]\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m   warnings.warn(  # warn only once\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 14:38:29 (running for 02:40:34.89)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:38:34 (running for 02:40:39.91)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████▎                                      | 1/10 [00:10<01:33, 10.40s/it]\n",
      "  0%|                                                   | 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 14:38:39 (running for 02:40:44.93)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:38:44 (running for 02:40:49.95)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████▌                                  | 2/10 [00:20<01:23, 10.41s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 14:38:50 (running for 02:40:54.96)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:38:55 (running for 02:40:59.98)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|████████████▉                              | 3/10 [00:31<01:12, 10.42s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 14:39:00 (running for 02:41:05.00)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:39:05 (running for 02:41:10.02)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:39:10 (running for 02:41:15.04)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|█████████████████▏                         | 4/10 [00:41<01:02, 10.42s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 14:39:15 (running for 02:41:20.06)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:39:20 (running for 02:41:25.08)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████████████████████▌                     | 5/10 [00:52<00:52, 10.42s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 14:39:25 (running for 02:41:30.10)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:39:30 (running for 02:41:35.12)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████████████████████████▊                 | 6/10 [01:02<00:41, 10.43s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 14:39:35 (running for 02:41:40.14)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:39:40 (running for 02:41:45.16)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████████████████████████████             | 7/10 [01:12<00:31, 10.44s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 14:39:45 (running for 02:41:50.18)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:39:50 (running for 02:41:55.20)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|██████████████████████████████████▍        | 8/10 [01:23<00:20, 10.43s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 14:39:55 (running for 02:42:00.22)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:40:00 (running for 02:42:05.24)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|██████████████████████████████████████▋    | 9/10 [01:33<00:10, 10.43s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 14:40:05 (running for 02:42:10.26)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:40:10 (running for 02:42:15.27)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - model initialization done -> loss fn initialization\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - reading data\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - reading data done -> model initialization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 10/10 [01:44<00:00, 10.43s/it]\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   warnings.warn(  # warn only once\n",
      " 90%|██████████████████████████████████████▋    | 9/10 [01:34<00:10, 10.48s/it]\n",
      "100%|██████████████████████████████████████████| 10/10 [01:44<00:00, 10.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 14:40:15 (running for 02:42:20.29)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m [KSpaceLoss] torch.Size([8, 2001191, 2, 1]) torch.Size([8, 2001191, 2, 1]) None\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - model initialization done -> loss fn initialization\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m [ImageSpaceLoss] torch.Size([156, 156, 156, 2, 1]) torch.Size([156, 156, 156, 2, 1]) None\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - Loss k-space: 1.614 - Loss image space: 0.036 - Loss Wavelet 0.000 - Loss Hankel 0.000 - Loss Casorati 0.000\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - loss fn initialization done -> compute backward pass\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:40:20 (running for 02:42:25.31)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   warnings.warn(  # warn only once\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 14:40:25 (running for 02:42:30.33)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:40:30 (running for 02:42:35.35)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:40:35 (running for 02:42:40.37)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:40:40 (running for 02:42:45.39)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:40:45 (running for 02:42:50.41)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:40:50 (running for 02:42:55.43)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:40:55 (running for 02:43:00.45)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:41:00 (running for 02:43:05.47)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:41:05 (running for 02:43:10.49)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:41:10 (running for 02:43:15.50)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:41:15 (running for 02:43:20.52)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:41:20 (running for 02:43:25.54)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:41:25 (running for 02:43:30.56)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:41:30 (running for 02:43:35.58)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:41:35 (running for 02:43:40.60)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:41:40 (running for 02:43:45.62)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:41:45 (running for 02:43:50.64)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:41:50 (running for 02:43:55.65)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:41:55 (running for 02:44:00.67)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:42:00 (running for 02:44:05.69)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:42:05 (running for 02:44:10.71)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:42:10 (running for 02:44:15.73)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:42:15 (running for 02:44:20.75)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:42:20 (running for 02:44:25.76)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:42:25 (running for 02:44:30.78)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:42:30 (running for 02:44:35.80)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:42:35 (running for 02:44:40.82)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:42:40 (running for 02:44:45.83)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:42:45 (running for 02:44:50.85)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:42:50 (running for 02:44:55.87)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:42:55 (running for 02:45:00.89)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:43:00 (running for 02:45:05.91)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:43:05 (running for 02:45:10.93)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:43:10 (running for 02:45:15.94)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:43:16 (running for 02:45:20.96)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:43:21 (running for 02:45:25.98)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:43:26 (running for 02:45:31.00)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:43:31 (running for 02:45:36.02)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:43:36 (running for 02:45:41.04)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:43:41 (running for 02:45:46.06)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:43:46 (running for 02:45:51.08)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:43:51 (running for 02:45:56.10)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:43:56 (running for 02:46:01.12)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:44:01 (running for 02:46:06.14)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - compute backward pass done -> compute accumulator\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m [KSpaceLoss] torch.Size([8, 2001191, 2, 1]) torch.Size([8, 2001191, 2, 1]) None\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m [ImageSpaceLoss] torch.Size([156, 156, 156, 2, 1]) torch.Size([156, 156, 156, 2, 1]) None\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - Loss k-space: 1.560 - Loss image space: 0.035 - Loss Wavelet 0.000 - Loss Hankel 0.000 - Loss Casorati 0.000\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - loss fn initialization done -> compute backward pass\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/autograd/graph.py:824: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   warnings.warn(  # warn only once\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - Index 0 - Gradient norm: 4.820\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Averaged gradient norm: 1.000\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Iteration: 27 - Elapsed time: 354 - Training loss: ['1.622'] - Validation loss: ['0.000']\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:44:06 (running for 02:46:11.16)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:44:11 (running for 02:46:16.18)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - reading data\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - compute backward pass done -> compute accumulator\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - Index 0 - Gradient norm: 5.005\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - reading data done -> model initialization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/autograd/graph.py:824: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m   warnings.warn(  # warn only once\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 14:44:16 (running for 02:46:21.20)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:44:21 (running for 02:46:26.22)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                   | 0/10 [00:00<?, ?it/s]\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   warnings.warn(  # warn only once\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 14:44:26 (running for 02:46:31.24)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:44:31 (running for 02:46:36.26)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████▎                                      | 1/10 [00:10<01:33, 10.43s/it]\n",
      "  0%|                                                   | 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 14:44:36 (running for 02:46:41.47)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:44:41 (running for 02:46:46.48)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████▌                                  | 2/10 [00:20<01:23, 10.42s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 14:44:46 (running for 02:46:51.51)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:44:51 (running for 02:46:56.52)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|████████████▉                              | 3/10 [00:31<01:12, 10.42s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 14:44:56 (running for 02:47:01.54)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:45:01 (running for 02:47:06.56)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|█████████████████▏                         | 4/10 [00:41<01:02, 10.41s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 14:45:06 (running for 02:47:11.58)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:45:11 (running for 02:47:16.60)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████████████████████▌                     | 5/10 [00:52<00:52, 10.41s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 14:45:16 (running for 02:47:21.62)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:45:21 (running for 02:47:26.64)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████████████████████████▊                 | 6/10 [01:02<00:41, 10.43s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 14:45:26 (running for 02:47:31.66)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:45:31 (running for 02:47:36.68)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████████████████████████████             | 7/10 [01:13<00:31, 10.43s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 14:45:36 (running for 02:47:41.70)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:45:41 (running for 02:47:46.72)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|██████████████████████████████████▍        | 8/10 [01:23<00:20, 10.43s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 14:45:46 (running for 02:47:51.74)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:45:51 (running for 02:47:56.75)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:45:56 (running for 02:48:01.78)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|██████████████████████████████████████▋    | 9/10 [01:33<00:10, 10.43s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 14:46:01 (running for 02:48:06.79)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:46:06 (running for 02:48:11.82)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - model initialization done -> loss fn initialization\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - reading data\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - reading data done -> model initialization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 10/10 [01:44<00:00, 10.43s/it]\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   warnings.warn(  # warn only once\n",
      " 90%|██████████████████████████████████████▋    | 9/10 [01:34<00:10, 10.47s/it]\n",
      "100%|██████████████████████████████████████████| 10/10 [01:44<00:00, 10.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 14:46:11 (running for 02:48:16.84)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m [KSpaceLoss] torch.Size([8, 2001191, 2, 1]) torch.Size([8, 2001191, 2, 1]) None\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - model initialization done -> loss fn initialization\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m [ImageSpaceLoss] torch.Size([156, 156, 156, 2, 1]) torch.Size([156, 156, 156, 2, 1]) None\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - Loss k-space: 1.709 - Loss image space: 0.034 - Loss Wavelet 0.000 - Loss Hankel 0.000 - Loss Casorati 0.000\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - loss fn initialization done -> compute backward pass\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   warnings.warn(  # warn only once\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 14:46:16 (running for 02:48:21.86)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:46:21 (running for 02:48:26.88)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:46:26 (running for 02:48:31.90)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:46:31 (running for 02:48:36.92)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:46:36 (running for 02:48:41.94)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:46:42 (running for 02:48:46.96)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:46:47 (running for 02:48:51.98)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:46:52 (running for 02:48:57.00)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:46:57 (running for 02:49:02.02)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:47:02 (running for 02:49:07.04)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:47:07 (running for 02:49:12.06)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:47:12 (running for 02:49:17.08)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:47:17 (running for 02:49:22.10)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:47:22 (running for 02:49:27.12)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:47:27 (running for 02:49:32.14)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:47:32 (running for 02:49:37.15)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:47:37 (running for 02:49:42.17)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:47:42 (running for 02:49:47.19)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:47:47 (running for 02:49:52.21)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:47:52 (running for 02:49:57.23)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:47:57 (running for 02:50:02.25)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:48:02 (running for 02:50:07.27)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:48:07 (running for 02:50:12.29)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:48:12 (running for 02:50:17.31)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:48:17 (running for 02:50:22.33)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:48:22 (running for 02:50:27.34)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:48:27 (running for 02:50:32.36)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:48:32 (running for 02:50:37.38)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:48:37 (running for 02:50:42.40)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:48:42 (running for 02:50:47.42)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:48:47 (running for 02:50:52.44)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:48:52 (running for 02:50:57.46)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:48:57 (running for 02:51:02.48)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:49:02 (running for 02:51:07.49)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:49:07 (running for 02:51:12.51)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:49:12 (running for 02:51:17.53)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:49:17 (running for 02:51:22.55)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:49:22 (running for 02:51:27.57)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:49:27 (running for 02:51:32.59)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:49:32 (running for 02:51:37.60)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:49:37 (running for 02:51:42.62)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:49:42 (running for 02:51:47.64)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:49:47 (running for 02:51:52.66)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:49:52 (running for 02:51:57.68)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:49:57 (running for 02:52:02.70)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - compute backward pass done -> compute accumulator\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m [KSpaceLoss] torch.Size([8, 2001191, 2, 1]) torch.Size([8, 2001191, 2, 1]) None\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m [ImageSpaceLoss] torch.Size([156, 156, 156, 2, 1]) torch.Size([156, 156, 156, 2, 1]) None\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - Loss k-space: 1.471 - Loss image space: 0.037 - Loss Wavelet 0.000 - Loss Hankel 0.000 - Loss Casorati 0.000\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - loss fn initialization done -> compute backward pass\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - Index 0 - Gradient norm: 4.627\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Averaged gradient norm: 1.000\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Iteration: 28 - Elapsed time: 356 - Training loss: ['1.625'] - Validation loss: ['0.000']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/autograd/graph.py:824: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m   warnings.warn(  # warn only once\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 14:50:02 (running for 02:52:07.72)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:50:07 (running for 02:52:12.74)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - reading data\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - compute backward pass done -> compute accumulator\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - Index 0 - Gradient norm: 5.212\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - reading data done -> model initialization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/autograd/graph.py:824: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   warnings.warn(  # warn only once\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 14:50:12 (running for 02:52:17.76)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:50:17 (running for 02:52:22.79)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                   | 0/10 [00:00<?, ?it/s]\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m   warnings.warn(  # warn only once\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 14:50:22 (running for 02:52:27.81)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:50:27 (running for 02:52:32.83)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████▎                                      | 1/10 [00:10<01:33, 10.39s/it]\n",
      "  0%|                                                   | 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 14:50:32 (running for 02:52:37.85)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:50:37 (running for 02:52:42.87)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████▌                                  | 2/10 [00:20<01:23, 10.42s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 14:50:42 (running for 02:52:47.89)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:50:47 (running for 02:52:52.91)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|████████████▉                              | 3/10 [00:31<01:12, 10.43s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 14:50:52 (running for 02:52:57.93)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:50:57 (running for 02:53:02.95)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|█████████████████▏                         | 4/10 [00:41<01:02, 10.43s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 14:51:03 (running for 02:53:07.96)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:51:08 (running for 02:53:12.99)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████████████████████▌                     | 5/10 [00:52<00:52, 10.42s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 14:51:13 (running for 02:53:18.00)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:51:18 (running for 02:53:23.03)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████████████████████████▊                 | 6/10 [01:02<00:41, 10.43s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 14:51:23 (running for 02:53:28.04)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:51:28 (running for 02:53:33.07)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████████████████████████████             | 7/10 [01:12<00:31, 10.43s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 14:51:33 (running for 02:53:38.08)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:51:38 (running for 02:53:43.10)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:51:43 (running for 02:53:48.12)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|██████████████████████████████████▍        | 8/10 [01:23<00:20, 10.43s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 14:51:48 (running for 02:53:53.14)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:51:53 (running for 02:53:58.16)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|██████████████████████████████████████▋    | 9/10 [01:33<00:10, 10.43s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 14:51:58 (running for 02:54:03.18)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:52:03 (running for 02:54:08.20)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - model initialization done -> loss fn initialization\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - reading data\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - reading data done -> model initialization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 10/10 [01:44<00:00, 10.43s/it]\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   warnings.warn(  # warn only once\n",
      " 90%|██████████████████████████████████████▋    | 9/10 [01:34<00:10, 10.47s/it]\n",
      "100%|██████████████████████████████████████████| 10/10 [01:44<00:00, 10.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 14:52:08 (running for 02:54:13.22)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m [KSpaceLoss] torch.Size([8, 2001191, 2, 1]) torch.Size([8, 2001191, 2, 1]) None\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - model initialization done -> loss fn initialization\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m [ImageSpaceLoss] torch.Size([156, 156, 156, 2, 1]) torch.Size([156, 156, 156, 2, 1]) None\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - Loss k-space: 1.581 - Loss image space: 0.035 - Loss Wavelet 0.000 - Loss Hankel 0.000 - Loss Casorati 0.000\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - loss fn initialization done -> compute backward pass\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   warnings.warn(  # warn only once\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 14:52:13 (running for 02:54:18.24)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:52:18 (running for 02:54:23.26)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:52:23 (running for 02:54:28.28)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:52:28 (running for 02:54:33.30)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:52:33 (running for 02:54:38.32)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:52:38 (running for 02:54:43.34)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:52:43 (running for 02:54:48.36)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:52:48 (running for 02:54:53.39)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:52:53 (running for 02:54:58.41)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:52:58 (running for 02:55:03.43)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:53:03 (running for 02:55:08.45)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:53:08 (running for 02:55:13.47)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:53:13 (running for 02:55:18.49)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:53:18 (running for 02:55:23.51)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:53:23 (running for 02:55:28.53)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:53:28 (running for 02:55:33.55)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:53:33 (running for 02:55:38.57)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:53:38 (running for 02:55:43.59)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:53:43 (running for 02:55:48.61)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:53:48 (running for 02:55:53.63)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:53:53 (running for 02:55:58.65)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:53:58 (running for 02:56:03.67)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:54:03 (running for 02:56:08.69)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:54:08 (running for 02:56:13.71)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:54:13 (running for 02:56:18.73)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:54:18 (running for 02:56:23.75)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:54:23 (running for 02:56:28.77)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:54:28 (running for 02:56:33.79)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:54:33 (running for 02:56:38.80)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:54:38 (running for 02:56:43.83)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:54:43 (running for 02:56:48.84)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:54:48 (running for 02:56:53.87)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:54:53 (running for 02:56:58.88)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:54:58 (running for 02:57:03.90)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:55:03 (running for 02:57:08.92)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:55:08 (running for 02:57:13.94)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:55:14 (running for 02:57:18.96)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:55:19 (running for 02:57:23.98)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:55:24 (running for 02:57:29.00)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:55:29 (running for 02:57:34.02)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:55:34 (running for 02:57:39.04)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:55:39 (running for 02:57:44.06)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:55:44 (running for 02:57:49.08)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:55:49 (running for 02:57:54.10)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:55:54 (running for 02:57:59.11)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - compute backward pass done -> compute accumulator\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m [KSpaceLoss] torch.Size([8, 2001191, 2, 1]) torch.Size([8, 2001191, 2, 1]) None\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m [ImageSpaceLoss] torch.Size([156, 156, 156, 2, 1]) torch.Size([156, 156, 156, 2, 1]) None\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - Loss k-space: 1.569 - Loss image space: 0.034 - Loss Wavelet 0.000 - Loss Hankel 0.000 - Loss Casorati 0.000\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - loss fn initialization done -> compute backward pass\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/autograd/graph.py:824: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   warnings.warn(  # warn only once\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - Index 0 - Gradient norm: 4.717\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Averaged gradient norm: 1.000\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Creating untagged checkpoint ...\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m 2025-09-29 14:55:56 Schedule checkpoint save with tag:  ...\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m 2025-09-29 14:55:56 Saved checkpoint to buffer 0.0 seconds\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Iteration: 29 - Elapsed time: 354 - Training loss: ['1.609'] - Validation loss: ['0.000']\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m 2025-09-29 14:55:56 Saved buffer to filesystem in 0.1 seconds\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m 2025-09-29 14:55:56 Completed saving checkpoint.\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:55:59 (running for 02:58:04.14)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:56:04 (running for 02:58:09.16)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - reading data\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - compute backward pass done -> compute accumulator\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - Index 0 - Gradient norm: 4.950\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - reading data done -> model initialization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/autograd/graph.py:824: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   warnings.warn(  # warn only once\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 14:56:09 (running for 02:58:14.18)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                   | 0/10 [00:00<?, ?it/s]\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m   warnings.warn(  # warn only once\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 14:56:14 (running for 02:58:19.20)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:56:19 (running for 02:58:24.23)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████▎                                      | 1/10 [00:10<01:33, 10.41s/it]\n",
      "  0%|                                                   | 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 14:56:24 (running for 02:58:29.24)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:56:29 (running for 02:58:34.26)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:56:34 (running for 02:58:39.28)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████▌                                  | 2/10 [00:20<01:23, 10.40s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 14:56:39 (running for 02:58:44.30)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:56:44 (running for 02:58:49.32)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|████████████▉                              | 3/10 [00:31<01:12, 10.40s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 14:56:49 (running for 02:58:54.34)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:56:54 (running for 02:58:59.36)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|█████████████████▏                         | 4/10 [00:41<01:02, 10.41s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 14:56:59 (running for 02:59:04.38)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:57:04 (running for 02:59:09.40)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████████████████████▌                     | 5/10 [00:52<00:52, 10.41s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 14:57:09 (running for 02:59:14.42)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:57:14 (running for 02:59:19.44)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████████████████████████▊                 | 6/10 [01:02<00:41, 10.43s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 14:57:19 (running for 02:59:24.46)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:57:24 (running for 02:59:29.47)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████████████████████████████             | 7/10 [01:12<00:31, 10.43s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 14:57:29 (running for 02:59:34.49)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:57:34 (running for 02:59:39.51)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|██████████████████████████████████▍        | 8/10 [01:23<00:20, 10.44s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 14:57:39 (running for 02:59:44.53)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:57:44 (running for 02:59:49.55)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|██████████████████████████████████████▋    | 9/10 [01:33<00:10, 10.45s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 14:57:49 (running for 02:59:54.61)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:57:54 (running for 02:59:59.63)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - model initialization done -> loss fn initialization\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - reading data\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - reading data done -> model initialization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 10/10 [01:44<00:00, 10.45s/it]\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   warnings.warn(  # warn only once\n",
      " 90%|██████████████████████████████████████▋    | 9/10 [01:33<00:10, 10.47s/it]\n",
      "100%|██████████████████████████████████████████| 10/10 [01:44<00:00, 10.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 14:57:59 (running for 03:00:04.65)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:58:04 (running for 03:00:09.68)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m [KSpaceLoss] torch.Size([8, 2001191, 2, 1]) torch.Size([8, 2001191, 2, 1]) None\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - model initialization done -> loss fn initialization\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m [ImageSpaceLoss] torch.Size([156, 156, 156, 2, 1]) torch.Size([156, 156, 156, 2, 1]) None\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - Loss k-space: 1.670 - Loss image space: 0.036 - Loss Wavelet 0.000 - Loss Hankel 0.000 - Loss Casorati 0.000\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - loss fn initialization done -> compute backward pass\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   warnings.warn(  # warn only once\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 14:58:09 (running for 03:00:14.70)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:58:14 (running for 03:00:19.72)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:58:19 (running for 03:00:24.74)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:58:24 (running for 03:00:29.76)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:58:29 (running for 03:00:34.78)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:58:34 (running for 03:00:39.80)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:58:39 (running for 03:00:44.82)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:58:44 (running for 03:00:49.84)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:58:49 (running for 03:00:54.86)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:58:54 (running for 03:00:59.87)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:58:59 (running for 03:01:04.92)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:59:04 (running for 03:01:09.93)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:59:09 (running for 03:01:14.95)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:59:15 (running for 03:01:19.97)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:59:20 (running for 03:01:24.99)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:59:25 (running for 03:01:30.00)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:59:30 (running for 03:01:35.02)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:59:35 (running for 03:01:40.04)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:59:40 (running for 03:01:45.06)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:59:45 (running for 03:01:50.08)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:59:50 (running for 03:01:55.10)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 14:59:55 (running for 03:02:00.11)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:00:00 (running for 03:02:05.13)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:00:05 (running for 03:02:10.15)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:00:10 (running for 03:02:15.17)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:00:15 (running for 03:02:20.19)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:00:20 (running for 03:02:25.21)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:00:25 (running for 03:02:30.22)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:00:30 (running for 03:02:35.24)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:00:35 (running for 03:02:40.26)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:00:40 (running for 03:02:45.28)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:00:45 (running for 03:02:50.30)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:00:50 (running for 03:02:55.32)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:00:55 (running for 03:03:00.34)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:01:00 (running for 03:03:05.36)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:01:05 (running for 03:03:10.38)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:01:10 (running for 03:03:15.40)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:01:15 (running for 03:03:20.41)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:01:20 (running for 03:03:25.43)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:01:25 (running for 03:03:30.45)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:01:30 (running for 03:03:35.47)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:01:35 (running for 03:03:40.49)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:01:40 (running for 03:03:45.51)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:01:45 (running for 03:03:50.53)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - compute backward pass done -> compute accumulator\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m [KSpaceLoss] torch.Size([8, 2001191, 2, 1]) torch.Size([8, 2001191, 2, 1]) None\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m [ImageSpaceLoss] torch.Size([156, 156, 156, 2, 1]) torch.Size([156, 156, 156, 2, 1]) None\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - Loss k-space: 1.519 - Loss image space: 0.037 - Loss Wavelet 0.000 - Loss Hankel 0.000 - Loss Casorati 0.000\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - loss fn initialization done -> compute backward pass\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/autograd/graph.py:824: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   warnings.warn(  # warn only once\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 15:01:50 (running for 03:03:55.55)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - Index 0 - Gradient norm: 4.665\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Averaged gradient norm: 1.000\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Iteration: 30 - Elapsed time: 354 - Training loss: ['1.631'] - Validation loss: ['0.000']\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:01:55 (running for 03:04:00.57)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - reading data\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - compute backward pass done -> compute accumulator\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - Index 0 - Gradient norm: 4.948\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - reading data done -> model initialization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/autograd/graph.py:824: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   warnings.warn(  # warn only once\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 15:02:00 (running for 03:04:05.60)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:02:05 (running for 03:04:10.62)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                   | 0/10 [00:00<?, ?it/s]\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m   warnings.warn(  # warn only once\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 15:02:10 (running for 03:04:15.64)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:02:15 (running for 03:04:20.66)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████▎                                      | 1/10 [00:10<01:33, 10.40s/it]\n",
      "  0%|                                                   | 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 15:02:20 (running for 03:04:25.68)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:02:25 (running for 03:04:30.69)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████▌                                  | 2/10 [00:20<01:23, 10.41s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 15:02:30 (running for 03:04:35.71)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:02:35 (running for 03:04:40.73)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|████████████▉                              | 3/10 [00:31<01:12, 10.42s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 15:02:40 (running for 03:04:45.75)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:02:45 (running for 03:04:50.77)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|█████████████████▏                         | 4/10 [00:41<01:02, 10.42s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 15:02:50 (running for 03:04:55.79)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:02:55 (running for 03:05:00.81)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████████████████████▌                     | 5/10 [00:52<00:52, 10.42s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 15:03:00 (running for 03:05:05.83)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:03:05 (running for 03:05:10.85)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████████████████████████▊                 | 6/10 [01:02<00:41, 10.43s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 15:03:10 (running for 03:05:15.87)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:03:15 (running for 03:05:20.89)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████████████████████████████             | 7/10 [01:12<00:31, 10.43s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 15:03:20 (running for 03:05:25.91)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:03:25 (running for 03:05:30.92)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:03:30 (running for 03:05:35.94)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|██████████████████████████████████▍        | 8/10 [01:23<00:20, 10.44s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 15:03:35 (running for 03:05:40.96)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:03:41 (running for 03:05:45.98)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|██████████████████████████████████████▋    | 9/10 [01:33<00:10, 10.43s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 15:03:46 (running for 03:05:51.00)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:03:51 (running for 03:05:56.02)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - model initialization done -> loss fn initialization\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - reading data\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - reading data done -> model initialization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 10/10 [01:44<00:00, 10.43s/it]\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   warnings.warn(  # warn only once\n",
      " 90%|██████████████████████████████████████▋    | 9/10 [01:34<00:10, 10.48s/it]\n",
      "100%|██████████████████████████████████████████| 10/10 [01:44<00:00, 10.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 15:03:56 (running for 03:06:01.04)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m [KSpaceLoss] torch.Size([8, 2001191, 2, 1]) torch.Size([8, 2001191, 2, 1]) None\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - model initialization done -> loss fn initialization\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m [ImageSpaceLoss] torch.Size([156, 156, 156, 2, 1]) torch.Size([156, 156, 156, 2, 1]) None\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - Loss k-space: 1.623 - Loss image space: 0.035 - Loss Wavelet 0.000 - Loss Hankel 0.000 - Loss Casorati 0.000\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - loss fn initialization done -> compute backward pass\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   warnings.warn(  # warn only once\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 15:04:01 (running for 03:06:06.06)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:04:06 (running for 03:06:11.08)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:04:11 (running for 03:06:16.10)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:04:16 (running for 03:06:21.12)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:04:21 (running for 03:06:26.14)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:04:26 (running for 03:06:31.16)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:04:31 (running for 03:06:36.18)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:04:36 (running for 03:06:41.20)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:04:41 (running for 03:06:46.22)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:04:46 (running for 03:06:51.23)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:04:51 (running for 03:06:56.25)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:04:56 (running for 03:07:01.27)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:05:01 (running for 03:07:06.29)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:05:06 (running for 03:07:11.31)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:05:11 (running for 03:07:16.33)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:05:16 (running for 03:07:21.35)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:05:21 (running for 03:07:26.37)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:05:26 (running for 03:07:31.39)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:05:31 (running for 03:07:36.41)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:05:36 (running for 03:07:41.42)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:05:41 (running for 03:07:46.44)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:05:46 (running for 03:07:51.46)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:05:51 (running for 03:07:56.48)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:05:56 (running for 03:08:01.50)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:06:01 (running for 03:08:06.52)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:06:06 (running for 03:08:11.53)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:06:11 (running for 03:08:16.55)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:06:16 (running for 03:08:21.57)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:06:21 (running for 03:08:26.59)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:06:26 (running for 03:08:31.61)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:06:31 (running for 03:08:36.63)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:06:36 (running for 03:08:41.65)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:06:41 (running for 03:08:46.67)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:06:46 (running for 03:08:51.69)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:06:51 (running for 03:08:56.71)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:06:56 (running for 03:09:01.72)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:07:01 (running for 03:09:06.74)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:07:06 (running for 03:09:11.76)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:07:11 (running for 03:09:16.78)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:07:16 (running for 03:09:21.80)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:07:21 (running for 03:09:26.82)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:07:26 (running for 03:09:31.83)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:07:31 (running for 03:09:36.85)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:07:36 (running for 03:09:41.87)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:07:41 (running for 03:09:46.89)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - compute backward pass done -> compute accumulator\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m [KSpaceLoss] torch.Size([8, 2001191, 2, 1]) torch.Size([8, 2001191, 2, 1]) None\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m [ImageSpaceLoss] torch.Size([156, 156, 156, 2, 1]) torch.Size([156, 156, 156, 2, 1]) None\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - Loss k-space: 1.569 - Loss image space: 0.035 - Loss Wavelet 0.000 - Loss Hankel 0.000 - Loss Casorati 0.000\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - loss fn initialization done -> compute backward pass\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/autograd/graph.py:824: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   warnings.warn(  # warn only once\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - Index 0 - Gradient norm: 4.759\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Averaged gradient norm: 1.000\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Iteration: 31 - Elapsed time: 353 - Training loss: ['1.631'] - Validation loss: ['0.000']\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:07:46 (running for 03:09:51.91)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:07:51 (running for 03:09:56.93)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - reading data\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - compute backward pass done -> compute accumulator\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - Index 0 - Gradient norm: 4.761\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - reading data done -> model initialization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/autograd/graph.py:824: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   warnings.warn(  # warn only once\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 15:07:56 (running for 03:10:01.95)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                   | 0/10 [00:00<?, ?it/s]\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m   warnings.warn(  # warn only once\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 15:08:02 (running for 03:10:06.97)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:08:07 (running for 03:10:11.99)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████▎                                      | 1/10 [00:10<01:33, 10.41s/it]\n",
      "  0%|                                                   | 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 15:08:12 (running for 03:10:17.01)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:08:17 (running for 03:10:22.03)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████▌                                  | 2/10 [00:20<01:23, 10.42s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 15:08:22 (running for 03:10:27.05)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:08:27 (running for 03:10:32.06)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:08:32 (running for 03:10:37.09)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|████████████▉                              | 3/10 [00:31<01:12, 10.40s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 15:08:37 (running for 03:10:42.10)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:08:42 (running for 03:10:47.12)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|█████████████████▏                         | 4/10 [00:41<01:02, 10.41s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 15:08:47 (running for 03:10:52.14)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:08:52 (running for 03:10:57.16)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████████████████████▌                     | 5/10 [00:52<00:52, 10.41s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 15:08:57 (running for 03:11:02.18)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:09:02 (running for 03:11:07.20)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████████████████████████▊                 | 6/10 [01:02<00:41, 10.44s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 15:09:07 (running for 03:11:12.22)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:09:12 (running for 03:11:17.24)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████████████████████████████             | 7/10 [01:13<00:31, 10.43s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 15:09:17 (running for 03:11:22.26)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:09:22 (running for 03:11:27.28)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|██████████████████████████████████▍        | 8/10 [01:23<00:20, 10.43s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 15:09:27 (running for 03:11:32.30)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:09:32 (running for 03:11:37.32)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|██████████████████████████████████████▋    | 9/10 [01:33<00:10, 10.44s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 15:09:37 (running for 03:11:42.34)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:09:42 (running for 03:11:47.36)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - model initialization done -> loss fn initialization\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - reading data\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - reading data done -> model initialization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 10/10 [01:44<00:00, 10.43s/it]\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   warnings.warn(  # warn only once\n",
      " 90%|██████████████████████████████████████▋    | 9/10 [01:33<00:10, 10.47s/it]\n",
      "100%|██████████████████████████████████████████| 10/10 [01:44<00:00, 10.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 15:09:47 (running for 03:11:52.37)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m [KSpaceLoss] torch.Size([8, 2001191, 2, 1]) torch.Size([8, 2001191, 2, 1]) None\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - model initialization done -> loss fn initialization\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m [ImageSpaceLoss] torch.Size([156, 156, 156, 2, 1]) torch.Size([156, 156, 156, 2, 1]) None\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:09:52 (running for 03:11:57.40)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - Loss k-space: 1.637 - Loss image space: 0.035 - Loss Wavelet 0.000 - Loss Hankel 0.000 - Loss Casorati 0.000\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - loss fn initialization done -> compute backward pass\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   warnings.warn(  # warn only once\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 15:09:57 (running for 03:12:02.42)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:10:02 (running for 03:12:07.44)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:10:07 (running for 03:12:12.46)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:10:12 (running for 03:12:17.48)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:10:17 (running for 03:12:22.50)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:10:22 (running for 03:12:27.52)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:10:27 (running for 03:12:32.54)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:10:32 (running for 03:12:37.56)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:10:37 (running for 03:12:42.58)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:10:42 (running for 03:12:47.60)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:10:47 (running for 03:12:52.62)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:10:52 (running for 03:12:57.64)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:10:57 (running for 03:13:02.66)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:11:02 (running for 03:13:07.68)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:11:07 (running for 03:13:12.69)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:11:12 (running for 03:13:17.72)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:11:17 (running for 03:13:22.73)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:11:22 (running for 03:13:27.75)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:11:27 (running for 03:13:32.77)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:11:32 (running for 03:13:37.79)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:11:37 (running for 03:13:42.81)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:11:42 (running for 03:13:47.83)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:11:47 (running for 03:13:52.85)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:11:52 (running for 03:13:57.87)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:11:57 (running for 03:14:02.88)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:12:02 (running for 03:14:07.90)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:12:07 (running for 03:14:12.92)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:12:12 (running for 03:14:17.94)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:12:17 (running for 03:14:22.96)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:12:23 (running for 03:14:27.98)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:12:28 (running for 03:14:33.00)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:12:33 (running for 03:14:38.02)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:12:38 (running for 03:14:43.03)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:12:43 (running for 03:14:48.05)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:12:48 (running for 03:14:53.07)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:12:53 (running for 03:14:58.09)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:12:58 (running for 03:15:03.10)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:13:03 (running for 03:15:08.13)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:13:08 (running for 03:15:13.14)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:13:13 (running for 03:15:18.16)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:13:18 (running for 03:15:23.18)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:13:23 (running for 03:15:28.20)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:13:28 (running for 03:15:33.22)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:13:33 (running for 03:15:38.24)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - compute backward pass done -> compute accumulator\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m [KSpaceLoss] torch.Size([8, 2001191, 2, 1]) torch.Size([8, 2001191, 2, 1]) None\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m [ImageSpaceLoss] torch.Size([156, 156, 156, 2, 1]) torch.Size([156, 156, 156, 2, 1]) None\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - Loss k-space: 1.546 - Loss image space: 0.035 - Loss Wavelet 0.000 - Loss Hankel 0.000 - Loss Casorati 0.000\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - loss fn initialization done -> compute backward pass\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/autograd/graph.py:824: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   warnings.warn(  # warn only once\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - Index 0 - Gradient norm: 4.583\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Averaged gradient norm: 1.000\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Iteration: 32 - Elapsed time: 354 - Training loss: ['1.626'] - Validation loss: ['0.000']\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:13:38 (running for 03:15:43.25)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:13:43 (running for 03:15:48.27)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - reading data\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - compute backward pass done -> compute accumulator\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - Index 0 - Gradient norm: 4.590\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - reading data done -> model initialization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/autograd/graph.py:824: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   warnings.warn(  # warn only once\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 15:13:48 (running for 03:15:53.29)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:13:53 (running for 03:15:58.32)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                   | 0/10 [00:00<?, ?it/s]\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m   warnings.warn(  # warn only once\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 15:13:58 (running for 03:16:03.34)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:14:03 (running for 03:16:08.36)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████▎                                      | 1/10 [00:10<01:33, 10.39s/it]\n",
      "  0%|                                                   | 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 15:14:08 (running for 03:16:13.37)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:14:13 (running for 03:16:18.39)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████▌                                  | 2/10 [00:20<01:23, 10.41s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 15:14:18 (running for 03:16:23.41)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:14:23 (running for 03:16:28.43)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|████████████▉                              | 3/10 [00:31<01:12, 10.42s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 15:14:28 (running for 03:16:33.45)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:14:33 (running for 03:16:38.47)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|█████████████████▏                         | 4/10 [00:41<01:02, 10.42s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 15:14:38 (running for 03:16:43.48)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:14:43 (running for 03:16:48.50)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████████████████████▌                     | 5/10 [00:52<00:52, 10.41s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 15:14:48 (running for 03:16:53.52)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:14:53 (running for 03:16:58.54)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████████████████████████▊                 | 6/10 [01:02<00:41, 10.43s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 15:14:58 (running for 03:17:03.56)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:15:03 (running for 03:17:08.58)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████████████████████████████             | 7/10 [01:12<00:31, 10.43s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 15:15:08 (running for 03:17:13.60)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:15:13 (running for 03:17:18.62)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|██████████████████████████████████▍        | 8/10 [01:23<00:20, 10.43s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 15:15:18 (running for 03:17:23.64)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:15:23 (running for 03:17:28.66)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|██████████████████████████████████████▋    | 9/10 [01:33<00:10, 10.43s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 15:15:28 (running for 03:17:33.68)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:15:33 (running for 03:17:38.70)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:15:38 (running for 03:17:43.71)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - model initialization done -> loss fn initialization\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - reading data\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - reading data done -> model initialization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 10/10 [01:44<00:00, 10.43s/it]\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   warnings.warn(  # warn only once\n",
      " 90%|██████████████████████████████████████▋    | 9/10 [01:34<00:10, 10.47s/it]\n",
      "100%|██████████████████████████████████████████| 10/10 [01:44<00:00, 10.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 15:15:43 (running for 03:17:48.74)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m [KSpaceLoss] torch.Size([8, 2001191, 2, 1]) torch.Size([8, 2001191, 2, 1]) None\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - model initialization done -> loss fn initialization\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m [ImageSpaceLoss] torch.Size([156, 156, 156, 2, 1]) torch.Size([156, 156, 156, 2, 1]) None\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - Loss k-space: 1.622 - Loss image space: 0.037 - Loss Wavelet 0.000 - Loss Hankel 0.000 - Loss Casorati 0.000\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - loss fn initialization done -> compute backward pass\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   warnings.warn(  # warn only once\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 15:15:48 (running for 03:17:53.76)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:15:53 (running for 03:17:58.78)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:15:58 (running for 03:18:03.80)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:16:03 (running for 03:18:08.82)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:16:08 (running for 03:18:13.84)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:16:13 (running for 03:18:18.86)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:16:18 (running for 03:18:23.88)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:16:23 (running for 03:18:28.90)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:16:28 (running for 03:18:33.92)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:16:33 (running for 03:18:38.94)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:16:38 (running for 03:18:43.95)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:16:44 (running for 03:18:48.98)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:16:49 (running for 03:18:53.99)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:16:54 (running for 03:18:59.01)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:16:59 (running for 03:19:04.03)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:17:04 (running for 03:19:09.05)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:17:09 (running for 03:19:14.07)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:17:14 (running for 03:19:19.09)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:17:19 (running for 03:19:24.10)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:17:24 (running for 03:19:29.12)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:17:29 (running for 03:19:34.14)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:17:34 (running for 03:19:39.16)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:17:39 (running for 03:19:44.18)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:17:44 (running for 03:19:49.20)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:17:49 (running for 03:19:54.21)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:17:54 (running for 03:19:59.24)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:17:59 (running for 03:20:04.25)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:18:04 (running for 03:20:09.27)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:18:09 (running for 03:20:14.29)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:18:14 (running for 03:20:19.31)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:18:19 (running for 03:20:24.33)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:18:24 (running for 03:20:29.35)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:18:29 (running for 03:20:34.37)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:18:34 (running for 03:20:39.39)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:18:39 (running for 03:20:44.41)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:18:44 (running for 03:20:49.43)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:18:49 (running for 03:20:54.45)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:18:54 (running for 03:20:59.47)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:18:59 (running for 03:21:04.49)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:19:04 (running for 03:21:09.51)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:19:09 (running for 03:21:14.53)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:19:14 (running for 03:21:19.55)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:19:19 (running for 03:21:24.57)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:19:24 (running for 03:21:29.59)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:19:29 (running for 03:21:34.61)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - compute backward pass done -> compute accumulator\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m [KSpaceLoss] torch.Size([8, 2001191, 2, 1]) torch.Size([8, 2001191, 2, 1]) None\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m [ImageSpaceLoss] torch.Size([156, 156, 156, 2, 1]) torch.Size([156, 156, 156, 2, 1]) None\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - Loss k-space: 1.576 - Loss image space: 0.035 - Loss Wavelet 0.000 - Loss Hankel 0.000 - Loss Casorati 0.000\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - loss fn initialization done -> compute backward pass\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/autograd/graph.py:824: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   warnings.warn(  # warn only once\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - Index 0 - Gradient norm: 4.646\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Averaged gradient norm: 1.000\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Iteration: 33 - Elapsed time: 353 - Training loss: ['1.635'] - Validation loss: ['0.000']\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:19:34 (running for 03:21:39.63)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - reading data\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - compute backward pass done -> compute accumulator\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - Index 0 - Gradient norm: 4.626\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:19:39 (running for 03:21:44.65)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - reading data done -> model initialization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/autograd/graph.py:824: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m   warnings.warn(  # warn only once\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 15:19:44 (running for 03:21:49.68)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                   | 0/10 [00:00<?, ?it/s]\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   warnings.warn(  # warn only once\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 15:19:49 (running for 03:21:54.70)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:19:54 (running for 03:21:59.72)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████▎                                      | 1/10 [00:10<01:33, 10.42s/it]\n",
      "  0%|                                                   | 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 15:19:59 (running for 03:22:04.74)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:20:04 (running for 03:22:09.76)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████▌                                  | 2/10 [00:20<01:23, 10.42s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 15:20:09 (running for 03:22:14.77)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:20:14 (running for 03:22:19.79)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|████████████▉                              | 3/10 [00:31<01:12, 10.41s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 15:20:19 (running for 03:22:24.81)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:20:24 (running for 03:22:29.83)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|█████████████████▏                         | 4/10 [00:41<01:02, 10.41s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 15:20:29 (running for 03:22:34.85)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:20:34 (running for 03:22:39.87)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:20:39 (running for 03:22:44.88)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████████████████████▌                     | 5/10 [00:52<00:52, 10.43s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 15:20:45 (running for 03:22:50.06)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:20:50 (running for 03:22:55.08)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████████████████████████▊                 | 6/10 [01:02<00:41, 10.43s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 15:20:55 (running for 03:23:00.10)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:21:00 (running for 03:23:05.12)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████████████████████████████             | 7/10 [01:12<00:31, 10.43s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 15:21:05 (running for 03:23:10.14)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:21:10 (running for 03:23:15.15)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|██████████████████████████████████▍        | 8/10 [01:23<00:20, 10.43s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 15:21:15 (running for 03:23:20.18)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:21:20 (running for 03:23:25.19)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|██████████████████████████████████████▋    | 9/10 [01:33<00:10, 10.44s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 15:21:25 (running for 03:23:30.21)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:21:30 (running for 03:23:35.23)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - model initialization done -> loss fn initialization\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - reading data\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - reading data done -> model initialization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 10/10 [01:44<00:00, 10.43s/it]\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   warnings.warn(  # warn only once\n",
      " 90%|██████████████████████████████████████▋    | 9/10 [01:34<00:10, 10.48s/it]\n",
      "100%|██████████████████████████████████████████| 10/10 [01:44<00:00, 10.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 15:21:35 (running for 03:23:40.25)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m [KSpaceLoss] torch.Size([8, 2001191, 2, 1]) torch.Size([8, 2001191, 2, 1]) None\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - model initialization done -> loss fn initialization\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m [ImageSpaceLoss] torch.Size([156, 156, 156, 2, 1]) torch.Size([156, 156, 156, 2, 1]) None\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - Loss k-space: 1.635 - Loss image space: 0.035 - Loss Wavelet 0.000 - Loss Hankel 0.000 - Loss Casorati 0.000\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - loss fn initialization done -> compute backward pass\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   warnings.warn(  # warn only once\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 15:21:40 (running for 03:23:45.27)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:21:45 (running for 03:23:50.29)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:21:50 (running for 03:23:55.32)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:21:55 (running for 03:24:00.34)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:22:00 (running for 03:24:05.36)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:22:05 (running for 03:24:10.38)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:22:10 (running for 03:24:15.40)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:22:15 (running for 03:24:20.42)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:22:20 (running for 03:24:25.43)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:22:25 (running for 03:24:30.45)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:22:30 (running for 03:24:35.47)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:22:35 (running for 03:24:40.49)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:22:40 (running for 03:24:45.51)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:22:45 (running for 03:24:50.53)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:22:50 (running for 03:24:55.55)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:22:55 (running for 03:25:00.57)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:23:00 (running for 03:25:05.58)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:23:05 (running for 03:25:10.60)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:23:10 (running for 03:25:15.62)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:23:15 (running for 03:25:20.64)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:23:20 (running for 03:25:25.66)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:23:25 (running for 03:25:30.68)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:23:30 (running for 03:25:35.70)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:23:35 (running for 03:25:40.72)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:23:40 (running for 03:25:45.74)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:23:45 (running for 03:25:50.76)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:23:50 (running for 03:25:55.78)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:23:56 (running for 03:26:00.98)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:24:01 (running for 03:26:06.00)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:24:06 (running for 03:26:11.02)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:24:11 (running for 03:26:16.03)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:24:16 (running for 03:26:21.06)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:24:21 (running for 03:26:26.07)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:24:26 (running for 03:26:31.09)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:24:31 (running for 03:26:36.11)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:24:36 (running for 03:26:41.13)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:24:41 (running for 03:26:46.15)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:24:46 (running for 03:26:51.17)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:24:51 (running for 03:26:56.19)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:24:56 (running for 03:27:01.21)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:25:01 (running for 03:27:06.23)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:25:06 (running for 03:27:11.25)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:25:11 (running for 03:27:16.26)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:25:16 (running for 03:27:21.29)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:25:21 (running for 03:27:26.31)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - compute backward pass done -> compute accumulator\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m [KSpaceLoss] torch.Size([8, 2001191, 2, 1]) torch.Size([8, 2001191, 2, 1]) None\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m [ImageSpaceLoss] torch.Size([156, 156, 156, 2, 1]) torch.Size([156, 156, 156, 2, 1]) None\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - Loss k-space: 1.509 - Loss image space: 0.035 - Loss Wavelet 0.000 - Loss Hankel 0.000 - Loss Casorati 0.000\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - loss fn initialization done -> compute backward pass\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/autograd/graph.py:824: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   warnings.warn(  # warn only once\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 15:25:26 (running for 03:27:31.33)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - Index 0 - Gradient norm: 4.638\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Averaged gradient norm: 1.000\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Creating untagged checkpoint ...\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m 2025-09-29 15:25:27 Schedule checkpoint save with tag:  ...\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m 2025-09-29 15:25:27 Saved checkpoint to buffer 0.0 seconds\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Iteration: 34 - Elapsed time: 356 - Training loss: ['1.607'] - Validation loss: ['0.000']\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m 2025-09-29 15:25:27 Saved buffer to filesystem in 0.2 seconds\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m 2025-09-29 15:25:27 Completed saving checkpoint.\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:25:31 (running for 03:27:36.35)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - reading data\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - compute backward pass done -> compute accumulator\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - Index 0 - Gradient norm: 4.689\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:25:36 (running for 03:27:41.38)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - reading data done -> model initialization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/autograd/graph.py:824: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   warnings.warn(  # warn only once\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 15:25:41 (running for 03:27:46.40)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                   | 0/10 [00:00<?, ?it/s]\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m   warnings.warn(  # warn only once\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 15:25:46 (running for 03:27:51.42)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:25:51 (running for 03:27:56.44)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████▎                                      | 1/10 [00:10<01:33, 10.41s/it]\n",
      "  0%|                                                   | 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 15:25:56 (running for 03:28:01.46)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:26:01 (running for 03:28:06.48)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████▌                                  | 2/10 [00:20<01:23, 10.41s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 15:26:06 (running for 03:28:11.50)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:26:11 (running for 03:28:16.52)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|████████████▉                              | 3/10 [00:31<01:12, 10.42s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 15:26:16 (running for 03:28:21.54)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:26:21 (running for 03:28:26.56)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|█████████████████▏                         | 4/10 [00:41<01:02, 10.42s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 15:26:26 (running for 03:28:31.58)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:26:31 (running for 03:28:36.60)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:26:36 (running for 03:28:41.62)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████████████████████▌                     | 5/10 [00:52<00:52, 10.42s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 15:26:41 (running for 03:28:46.64)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:26:46 (running for 03:28:51.67)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████████████████████████▊                 | 6/10 [01:02<00:41, 10.43s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 15:26:51 (running for 03:28:56.68)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:26:56 (running for 03:29:01.70)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████████████████████████████             | 7/10 [01:12<00:31, 10.43s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 15:27:01 (running for 03:29:06.72)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:27:06 (running for 03:29:11.74)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|██████████████████████████████████▍        | 8/10 [01:23<00:20, 10.44s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 15:27:11 (running for 03:29:16.76)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:27:16 (running for 03:29:21.79)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|██████████████████████████████████████▋    | 9/10 [01:33<00:10, 10.44s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 15:27:21 (running for 03:29:26.80)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:27:26 (running for 03:29:31.83)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - model initialization done -> loss fn initialization\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - reading data\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - reading data done -> model initialization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 10/10 [01:44<00:00, 10.43s/it]\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   warnings.warn(  # warn only once\n",
      " 90%|██████████████████████████████████████▋    | 9/10 [01:34<00:10, 10.48s/it]\n",
      "100%|██████████████████████████████████████████| 10/10 [01:44<00:00, 10.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 15:27:31 (running for 03:29:36.84)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m [KSpaceLoss] torch.Size([8, 2001191, 2, 1]) torch.Size([8, 2001191, 2, 1]) None\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - model initialization done -> loss fn initialization\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m [ImageSpaceLoss] torch.Size([156, 156, 156, 2, 1]) torch.Size([156, 156, 156, 2, 1]) None\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - Loss k-space: 1.691 - Loss image space: 0.036 - Loss Wavelet 0.000 - Loss Hankel 0.000 - Loss Casorati 0.000\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - loss fn initialization done -> compute backward pass\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   warnings.warn(  # warn only once\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 15:27:36 (running for 03:29:41.87)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:27:41 (running for 03:29:46.89)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:27:46 (running for 03:29:51.91)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:27:51 (running for 03:29:56.93)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:27:56 (running for 03:30:01.95)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:28:02 (running for 03:30:06.97)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:28:07 (running for 03:30:11.99)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:28:12 (running for 03:30:17.01)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:28:17 (running for 03:30:22.03)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:28:22 (running for 03:30:27.05)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:28:27 (running for 03:30:32.07)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:28:32 (running for 03:30:37.09)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:28:37 (running for 03:30:42.11)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:28:42 (running for 03:30:47.13)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:28:47 (running for 03:30:52.15)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:28:52 (running for 03:30:57.17)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:28:57 (running for 03:31:02.19)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:29:02 (running for 03:31:07.21)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:29:07 (running for 03:31:12.23)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:29:12 (running for 03:31:17.25)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:29:17 (running for 03:31:22.27)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:29:22 (running for 03:31:27.29)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:29:27 (running for 03:31:32.32)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:29:32 (running for 03:31:37.34)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:29:37 (running for 03:31:42.36)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:29:42 (running for 03:31:47.38)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:29:47 (running for 03:31:52.40)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:29:52 (running for 03:31:57.42)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:29:57 (running for 03:32:02.44)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:30:02 (running for 03:32:07.46)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:30:07 (running for 03:32:12.49)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:30:12 (running for 03:32:17.51)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:30:17 (running for 03:32:22.53)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:30:22 (running for 03:32:27.55)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:30:27 (running for 03:32:32.57)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:30:32 (running for 03:32:37.59)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:30:37 (running for 03:32:42.61)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:30:42 (running for 03:32:47.63)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:30:47 (running for 03:32:52.65)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:30:52 (running for 03:32:57.67)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:30:57 (running for 03:33:02.69)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:31:02 (running for 03:33:07.71)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:31:07 (running for 03:33:12.73)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:31:12 (running for 03:33:17.75)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:31:17 (running for 03:33:22.78)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - compute backward pass done -> compute accumulator\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m [KSpaceLoss] torch.Size([8, 2001191, 2, 1]) torch.Size([8, 2001191, 2, 1]) None\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m [ImageSpaceLoss] torch.Size([156, 156, 156, 2, 1]) torch.Size([156, 156, 156, 2, 1]) None\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - Loss k-space: 1.549 - Loss image space: 0.037 - Loss Wavelet 0.000 - Loss Hankel 0.000 - Loss Casorati 0.000\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - loss fn initialization done -> compute backward pass\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/autograd/graph.py:824: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   warnings.warn(  # warn only once\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - Index 0 - Gradient norm: 4.592\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Averaged gradient norm: 1.000\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Iteration: 35 - Elapsed time: 354 - Training loss: ['1.656'] - Validation loss: ['0.000']\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:31:22 (running for 03:33:27.79)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:31:27 (running for 03:33:32.82)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - reading data\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - compute backward pass done -> compute accumulator\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - Index 0 - Gradient norm: 4.517\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - reading data done -> model initialization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/autograd/graph.py:824: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   warnings.warn(  # warn only once\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 15:31:32 (running for 03:33:37.84)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:31:37 (running for 03:33:42.89)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                   | 0/10 [00:00<?, ?it/s]\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m   warnings.warn(  # warn only once\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 15:31:42 (running for 03:33:47.91)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:31:47 (running for 03:33:52.93)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████▎                                      | 1/10 [00:10<01:33, 10.42s/it]\n",
      "  0%|                                                   | 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 15:31:52 (running for 03:33:57.95)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:31:58 (running for 03:34:02.97)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████▌                                  | 2/10 [00:20<01:23, 10.42s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 15:32:03 (running for 03:34:07.98)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:32:08 (running for 03:34:13.01)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|████████████▉                              | 3/10 [00:31<01:12, 10.42s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 15:32:13 (running for 03:34:18.02)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:32:18 (running for 03:34:23.04)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|█████████████████▏                         | 4/10 [00:41<01:02, 10.42s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 15:32:23 (running for 03:34:28.06)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:32:28 (running for 03:34:33.08)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████████████████████▌                     | 5/10 [00:52<00:52, 10.42s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 15:32:33 (running for 03:34:38.10)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:32:38 (running for 03:34:43.12)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████████████████████████▊                 | 6/10 [01:02<00:41, 10.43s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 15:32:43 (running for 03:34:48.13)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:32:48 (running for 03:34:53.15)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████████████████████████████             | 7/10 [01:13<00:31, 10.44s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 15:32:53 (running for 03:34:58.17)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:32:58 (running for 03:35:03.19)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|██████████████████████████████████▍        | 8/10 [01:23<00:20, 10.44s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 15:33:03 (running for 03:35:08.21)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:33:08 (running for 03:35:13.23)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|██████████████████████████████████████▋    | 9/10 [01:33<00:10, 10.44s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 15:33:13 (running for 03:35:18.25)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:33:18 (running for 03:35:23.27)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:33:23 (running for 03:35:28.28)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - model initialization done -> loss fn initialization\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - reading data\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - reading data done -> model initialization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 10/10 [01:44<00:00, 10.43s/it]\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   warnings.warn(  # warn only once\n",
      " 90%|██████████████████████████████████████▋    | 9/10 [01:34<00:10, 10.48s/it]\n",
      "100%|██████████████████████████████████████████| 10/10 [01:44<00:00, 10.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 15:33:28 (running for 03:35:33.31)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m [KSpaceLoss] torch.Size([8, 2001191, 2, 1]) torch.Size([8, 2001191, 2, 1]) None\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - model initialization done -> loss fn initialization\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m [ImageSpaceLoss] torch.Size([156, 156, 156, 2, 1]) torch.Size([156, 156, 156, 2, 1]) None\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - Loss k-space: 1.685 - Loss image space: 0.034 - Loss Wavelet 0.000 - Loss Hankel 0.000 - Loss Casorati 0.000\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - loss fn initialization done -> compute backward pass\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   warnings.warn(  # warn only once\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 15:33:33 (running for 03:35:38.33)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:33:38 (running for 03:35:43.35)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:33:43 (running for 03:35:48.37)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:33:48 (running for 03:35:53.39)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:33:53 (running for 03:35:58.41)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:33:58 (running for 03:36:03.43)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:34:03 (running for 03:36:08.45)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:34:08 (running for 03:36:13.47)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:34:13 (running for 03:36:18.49)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:34:18 (running for 03:36:23.51)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:34:23 (running for 03:36:28.53)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:34:28 (running for 03:36:33.55)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:34:33 (running for 03:36:38.56)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:34:38 (running for 03:36:43.59)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:34:43 (running for 03:36:48.60)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:34:48 (running for 03:36:53.63)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:34:53 (running for 03:36:58.64)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:34:58 (running for 03:37:03.66)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:35:03 (running for 03:37:08.68)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:35:08 (running for 03:37:13.70)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:35:13 (running for 03:37:18.72)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:35:18 (running for 03:37:23.74)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:35:23 (running for 03:37:28.76)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:35:28 (running for 03:37:33.78)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:35:33 (running for 03:37:38.79)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:35:38 (running for 03:37:43.82)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:35:43 (running for 03:37:48.84)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:35:48 (running for 03:37:53.86)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:35:53 (running for 03:37:58.87)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:35:58 (running for 03:38:03.89)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:36:03 (running for 03:38:08.91)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:36:08 (running for 03:38:13.93)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:36:13 (running for 03:38:18.96)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:36:19 (running for 03:38:23.98)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:36:24 (running for 03:38:29.00)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:36:29 (running for 03:38:34.02)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:36:34 (running for 03:38:39.04)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:36:39 (running for 03:38:44.06)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:36:44 (running for 03:38:49.07)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:36:49 (running for 03:38:54.09)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:36:54 (running for 03:38:59.11)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:36:59 (running for 03:39:04.13)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:37:04 (running for 03:39:09.15)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:37:09 (running for 03:39:14.17)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:37:14 (running for 03:39:19.19)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - compute backward pass done -> compute accumulator\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m [KSpaceLoss] torch.Size([8, 2001191, 2, 1]) torch.Size([8, 2001191, 2, 1]) None\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m [ImageSpaceLoss] torch.Size([156, 156, 156, 2, 1]) torch.Size([156, 156, 156, 2, 1]) None\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - Loss k-space: 1.489 - Loss image space: 0.037 - Loss Wavelet 0.000 - Loss Hankel 0.000 - Loss Casorati 0.000\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - loss fn initialization done -> compute backward pass\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/autograd/graph.py:824: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   warnings.warn(  # warn only once\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - Index 0 - Gradient norm: 4.467\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Averaged gradient norm: 1.000\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Iteration: 36 - Elapsed time: 353 - Training loss: ['1.622'] - Validation loss: ['0.000']\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:37:19 (running for 03:39:24.21)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:37:24 (running for 03:39:29.23)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - reading data\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - compute backward pass done -> compute accumulator\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - Index 0 - Gradient norm: 4.628\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - reading data done -> model initialization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/autograd/graph.py:824: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   warnings.warn(  # warn only once\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 15:37:29 (running for 03:39:34.26)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                   | 0/10 [00:00<?, ?it/s]\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m   warnings.warn(  # warn only once\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 15:37:34 (running for 03:39:39.28)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:37:39 (running for 03:39:44.30)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████▎                                      | 1/10 [00:10<01:33, 10.39s/it]\n",
      "  0%|                                                   | 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 15:37:44 (running for 03:39:49.31)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:37:49 (running for 03:39:54.33)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████▌                                  | 2/10 [00:20<01:23, 10.41s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 15:37:54 (running for 03:39:59.35)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:37:59 (running for 03:40:04.37)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|████████████▉                              | 3/10 [00:31<01:12, 10.43s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 15:38:04 (running for 03:40:09.39)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:38:09 (running for 03:40:14.41)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|█████████████████▏                         | 4/10 [00:41<01:02, 10.43s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 15:38:14 (running for 03:40:19.43)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:38:19 (running for 03:40:24.45)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████████████████████▌                     | 5/10 [00:52<00:52, 10.43s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 15:38:24 (running for 03:40:29.46)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:38:29 (running for 03:40:34.48)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████████████████████████▊                 | 6/10 [01:02<00:41, 10.43s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 15:38:34 (running for 03:40:39.50)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:38:39 (running for 03:40:44.52)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:38:44 (running for 03:40:49.54)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████████████████████████████             | 7/10 [01:12<00:31, 10.43s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 15:38:49 (running for 03:40:54.56)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:38:54 (running for 03:40:59.58)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|██████████████████████████████████▍        | 8/10 [01:23<00:20, 10.43s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 15:38:59 (running for 03:41:04.60)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:39:04 (running for 03:41:09.62)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|██████████████████████████████████████▋    | 9/10 [01:33<00:10, 10.43s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 15:39:09 (running for 03:41:14.64)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:39:14 (running for 03:41:19.66)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - model initialization done -> loss fn initialization\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - reading data\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - reading data done -> model initialization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 10/10 [01:44<00:00, 10.43s/it]\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   warnings.warn(  # warn only once\n",
      " 90%|██████████████████████████████████████▋    | 9/10 [01:34<00:10, 10.48s/it]\n",
      "100%|██████████████████████████████████████████| 10/10 [01:44<00:00, 10.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 15:39:19 (running for 03:41:24.68)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m [KSpaceLoss] torch.Size([8, 2001191, 2, 1]) torch.Size([8, 2001191, 2, 1]) None\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - model initialization done -> loss fn initialization\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m [ImageSpaceLoss] torch.Size([156, 156, 156, 2, 1]) torch.Size([156, 156, 156, 2, 1]) None\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - Loss k-space: 1.660 - Loss image space: 0.036 - Loss Wavelet 0.000 - Loss Hankel 0.000 - Loss Casorati 0.000\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - loss fn initialization done -> compute backward pass\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   warnings.warn(  # warn only once\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 15:39:24 (running for 03:41:29.70)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:39:29 (running for 03:41:34.73)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:39:34 (running for 03:41:39.75)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:39:39 (running for 03:41:44.77)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:39:44 (running for 03:41:49.79)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:39:49 (running for 03:41:54.81)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:39:54 (running for 03:41:59.83)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:39:59 (running for 03:42:04.86)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:40:04 (running for 03:42:09.88)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:40:09 (running for 03:42:14.90)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:40:14 (running for 03:42:19.92)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:40:19 (running for 03:42:24.94)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:40:24 (running for 03:42:29.96)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:40:30 (running for 03:42:34.98)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:40:35 (running for 03:42:40.00)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:40:40 (running for 03:42:45.02)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:40:45 (running for 03:42:50.04)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:40:50 (running for 03:42:55.06)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:40:55 (running for 03:43:00.07)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:41:00 (running for 03:43:05.09)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:41:05 (running for 03:43:10.11)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:41:10 (running for 03:43:15.13)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:41:15 (running for 03:43:20.15)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:41:20 (running for 03:43:25.17)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:41:25 (running for 03:43:30.19)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:41:30 (running for 03:43:35.21)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:41:35 (running for 03:43:40.23)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:41:40 (running for 03:43:45.25)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:41:45 (running for 03:43:50.27)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:41:50 (running for 03:43:55.29)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:41:55 (running for 03:44:00.31)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:42:00 (running for 03:44:05.33)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:42:05 (running for 03:44:10.35)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:42:10 (running for 03:44:15.37)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:42:15 (running for 03:44:20.39)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:42:20 (running for 03:44:25.41)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:42:25 (running for 03:44:30.42)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:42:30 (running for 03:44:35.45)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:42:35 (running for 03:44:40.46)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:42:40 (running for 03:44:45.48)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:42:45 (running for 03:44:50.50)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:42:50 (running for 03:44:55.52)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:42:55 (running for 03:45:00.54)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:43:00 (running for 03:45:05.56)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:43:05 (running for 03:45:10.58)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:43:10 (running for 03:45:15.60)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - compute backward pass done -> compute accumulator\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m [KSpaceLoss] torch.Size([8, 2001191, 2, 1]) torch.Size([8, 2001191, 2, 1]) None\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m [ImageSpaceLoss] torch.Size([156, 156, 156, 2, 1]) torch.Size([156, 156, 156, 2, 1]) None\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - Loss k-space: 1.548 - Loss image space: 0.036 - Loss Wavelet 0.000 - Loss Hankel 0.000 - Loss Casorati 0.000\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - loss fn initialization done -> compute backward pass\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - Index 0 - Gradient norm: 4.536\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Averaged gradient norm: 1.000\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Iteration: 37 - Elapsed time: 355 - Training loss: ['1.640'] - Validation loss: ['0.000']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/autograd/graph.py:824: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   warnings.warn(  # warn only once\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 15:43:15 (running for 03:45:20.62)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - reading data\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - compute backward pass done -> compute accumulator\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - Index 0 - Gradient norm: 4.419\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:43:20 (running for 03:45:25.65)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - reading data done -> model initialization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/autograd/graph.py:824: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   warnings.warn(  # warn only once\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 15:43:25 (running for 03:45:30.67)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                   | 0/10 [00:00<?, ?it/s]\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m   warnings.warn(  # warn only once\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 15:43:30 (running for 03:45:35.69)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:43:35 (running for 03:45:40.71)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████▎                                      | 1/10 [00:10<01:33, 10.42s/it]\n",
      "  0%|                                                   | 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 15:43:40 (running for 03:45:45.73)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:43:45 (running for 03:45:50.75)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████▌                                  | 2/10 [00:20<01:23, 10.42s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 15:43:50 (running for 03:45:55.77)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:43:55 (running for 03:46:00.79)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|████████████▉                              | 3/10 [00:31<01:12, 10.41s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 15:44:00 (running for 03:46:05.81)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:44:05 (running for 03:46:10.83)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|█████████████████▏                         | 4/10 [00:41<01:02, 10.41s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 15:44:10 (running for 03:46:15.85)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:44:15 (running for 03:46:20.86)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:44:20 (running for 03:46:25.88)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████████████████████▌                     | 5/10 [00:52<00:52, 10.41s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 15:44:25 (running for 03:46:30.90)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:44:30 (running for 03:46:35.92)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████████████████████████▊                 | 6/10 [01:02<00:41, 10.42s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 15:44:35 (running for 03:46:40.94)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:44:40 (running for 03:46:45.96)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████████████████████████████             | 7/10 [01:12<00:31, 10.43s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 15:44:46 (running for 03:46:50.97)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:44:51 (running for 03:46:55.99)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|██████████████████████████████████▍        | 8/10 [01:23<00:20, 10.43s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 15:44:56 (running for 03:47:01.01)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:45:01 (running for 03:47:06.03)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|██████████████████████████████████████▋    | 9/10 [01:33<00:10, 10.44s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 15:45:06 (running for 03:47:11.05)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:45:11 (running for 03:47:16.07)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - model initialization done -> loss fn initialization\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - reading data\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - reading data done -> model initialization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 10/10 [01:44<00:00, 10.43s/it]\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   warnings.warn(  # warn only once\n",
      " 90%|██████████████████████████████████████▋    | 9/10 [01:33<00:10, 10.47s/it]\n",
      "100%|██████████████████████████████████████████| 10/10 [01:44<00:00, 10.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 15:45:16 (running for 03:47:21.09)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m [KSpaceLoss] torch.Size([8, 2001191, 2, 1]) torch.Size([8, 2001191, 2, 1]) None\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - model initialization done -> loss fn initialization\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m [ImageSpaceLoss] torch.Size([156, 156, 156, 2, 1]) torch.Size([156, 156, 156, 2, 1]) None\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - Loss k-space: 1.698 - Loss image space: 0.035 - Loss Wavelet 0.000 - Loss Hankel 0.000 - Loss Casorati 0.000\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - loss fn initialization done -> compute backward pass\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:45:21 (running for 03:47:26.11)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   warnings.warn(  # warn only once\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 15:45:26 (running for 03:47:31.14)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:45:31 (running for 03:47:36.16)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:45:36 (running for 03:47:41.18)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:45:41 (running for 03:47:46.20)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:45:46 (running for 03:47:51.22)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:45:51 (running for 03:47:56.24)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:45:56 (running for 03:48:01.25)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:46:01 (running for 03:48:06.27)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:46:06 (running for 03:48:11.29)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:46:11 (running for 03:48:16.31)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:46:16 (running for 03:48:21.33)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:46:21 (running for 03:48:26.35)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:46:26 (running for 03:48:31.37)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:46:31 (running for 03:48:36.39)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:46:36 (running for 03:48:41.41)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:46:41 (running for 03:48:46.43)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:46:46 (running for 03:48:51.45)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:46:51 (running for 03:48:56.47)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:46:56 (running for 03:49:01.48)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:47:01 (running for 03:49:06.50)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:47:06 (running for 03:49:11.52)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:47:11 (running for 03:49:16.55)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:47:16 (running for 03:49:21.57)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:47:21 (running for 03:49:26.59)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:47:26 (running for 03:49:31.61)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:47:31 (running for 03:49:36.63)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:47:36 (running for 03:49:41.66)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:47:41 (running for 03:49:46.68)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:47:46 (running for 03:49:51.70)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:47:51 (running for 03:49:56.72)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:47:56 (running for 03:50:01.73)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:48:01 (running for 03:50:06.75)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:48:06 (running for 03:50:11.77)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:48:11 (running for 03:50:16.79)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:48:16 (running for 03:50:21.81)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:48:21 (running for 03:50:26.83)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:48:26 (running for 03:50:31.85)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:48:31 (running for 03:50:36.87)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:48:36 (running for 03:50:41.89)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:48:41 (running for 03:50:46.91)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:48:46 (running for 03:50:51.93)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:48:51 (running for 03:50:56.95)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:48:57 (running for 03:51:01.97)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:49:02 (running for 03:51:06.99)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - compute backward pass done -> compute accumulator\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m [KSpaceLoss] torch.Size([8, 2001191, 2, 1]) torch.Size([8, 2001191, 2, 1]) None\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m [ImageSpaceLoss] torch.Size([156, 156, 156, 2, 1]) torch.Size([156, 156, 156, 2, 1]) None\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - Loss k-space: 1.548 - Loss image space: 0.037 - Loss Wavelet 0.000 - Loss Hankel 0.000 - Loss Casorati 0.000\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - loss fn initialization done -> compute backward pass\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/autograd/graph.py:824: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   warnings.warn(  # warn only once\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - Index 0 - Gradient norm: 4.421\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Averaged gradient norm: 1.000\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Iteration: 38 - Elapsed time: 354 - Training loss: ['1.659'] - Validation loss: ['0.000']\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:49:07 (running for 03:51:12.01)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:49:12 (running for 03:51:17.03)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - reading data\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - compute backward pass done -> compute accumulator\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - Index 0 - Gradient norm: 4.445\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - reading data done -> model initialization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/autograd/graph.py:824: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   warnings.warn(  # warn only once\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 15:49:17 (running for 03:51:22.05)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                   | 0/10 [00:00<?, ?it/s]\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m   warnings.warn(  # warn only once\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 15:49:22 (running for 03:51:27.08)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:49:27 (running for 03:51:32.09)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:49:32 (running for 03:51:37.12)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████▎                                      | 1/10 [00:10<01:33, 10.40s/it]\n",
      "  0%|                                                   | 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 15:49:37 (running for 03:51:42.13)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:49:42 (running for 03:51:47.15)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████▌                                  | 2/10 [00:20<01:23, 10.41s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 15:49:47 (running for 03:51:52.17)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:49:52 (running for 03:51:57.19)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|████████████▉                              | 3/10 [00:31<01:12, 10.41s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 15:49:57 (running for 03:52:02.21)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:50:02 (running for 03:52:07.23)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|█████████████████▏                         | 4/10 [00:41<01:02, 10.41s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 15:50:07 (running for 03:52:12.25)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:50:12 (running for 03:52:17.27)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████████████████████▌                     | 5/10 [00:52<00:52, 10.41s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 15:50:17 (running for 03:52:22.28)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:50:22 (running for 03:52:27.30)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████████████████████████▊                 | 6/10 [01:02<00:41, 10.43s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 15:50:27 (running for 03:52:32.32)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:50:32 (running for 03:52:37.34)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████████████████████████████             | 7/10 [01:13<00:31, 10.45s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 15:50:37 (running for 03:52:42.36)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:50:42 (running for 03:52:47.38)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|██████████████████████████████████▍        | 8/10 [01:23<00:20, 10.44s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 15:50:47 (running for 03:52:52.40)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:50:52 (running for 03:52:57.42)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|██████████████████████████████████████▋    | 9/10 [01:33<00:10, 10.44s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 15:50:57 (running for 03:53:02.44)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:51:02 (running for 03:53:07.46)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - model initialization done -> loss fn initialization\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - reading data\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - reading data done -> model initialization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 10/10 [01:44<00:00, 10.44s/it]\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   warnings.warn(  # warn only once\n",
      " 90%|██████████████████████████████████████▋    | 9/10 [01:33<00:10, 10.47s/it]\n",
      "100%|██████████████████████████████████████████| 10/10 [01:44<00:00, 10.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 15:51:07 (running for 03:53:12.47)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:51:12 (running for 03:53:17.50)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m [KSpaceLoss] torch.Size([8, 2001191, 2, 1]) torch.Size([8, 2001191, 2, 1]) None\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - model initialization done -> loss fn initialization\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m [ImageSpaceLoss] torch.Size([156, 156, 156, 2, 1]) torch.Size([156, 156, 156, 2, 1]) None\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - Loss k-space: 1.639 - Loss image space: 0.035 - Loss Wavelet 0.000 - Loss Hankel 0.000 - Loss Casorati 0.000\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - loss fn initialization done -> compute backward pass\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   warnings.warn(  # warn only once\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 15:51:17 (running for 03:53:22.51)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:51:22 (running for 03:53:27.54)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:51:27 (running for 03:53:32.56)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:51:32 (running for 03:53:37.58)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:51:37 (running for 03:53:42.59)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:51:42 (running for 03:53:47.62)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:51:47 (running for 03:53:52.63)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:51:52 (running for 03:53:57.65)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:51:57 (running for 03:54:02.67)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:52:02 (running for 03:54:07.70)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:52:07 (running for 03:54:12.71)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:52:12 (running for 03:54:17.73)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:52:17 (running for 03:54:22.75)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:52:22 (running for 03:54:27.77)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:52:27 (running for 03:54:32.79)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:52:32 (running for 03:54:37.81)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:52:37 (running for 03:54:42.83)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:52:42 (running for 03:54:47.85)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:52:47 (running for 03:54:52.87)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:52:52 (running for 03:54:57.89)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:52:57 (running for 03:55:02.91)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:53:02 (running for 03:55:07.93)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:53:07 (running for 03:55:12.95)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:53:13 (running for 03:55:17.97)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:53:18 (running for 03:55:22.99)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:53:23 (running for 03:55:28.01)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:53:28 (running for 03:55:33.03)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:53:33 (running for 03:55:38.05)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:53:38 (running for 03:55:43.07)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:53:43 (running for 03:55:48.09)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:53:48 (running for 03:55:53.11)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:53:53 (running for 03:55:58.13)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:53:58 (running for 03:56:03.15)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:54:03 (running for 03:56:08.17)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:54:08 (running for 03:56:13.19)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:54:13 (running for 03:56:18.21)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:54:18 (running for 03:56:23.23)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:54:23 (running for 03:56:28.25)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:54:28 (running for 03:56:33.27)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:54:33 (running for 03:56:38.29)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:54:38 (running for 03:56:43.31)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:54:43 (running for 03:56:48.33)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:54:48 (running for 03:56:53.35)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:54:53 (running for 03:56:58.37)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - compute backward pass done -> compute accumulator\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m [KSpaceLoss] torch.Size([8, 2001191, 2, 1]) torch.Size([8, 2001191, 2, 1]) None\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m [ImageSpaceLoss] torch.Size([156, 156, 156, 2, 1]) torch.Size([156, 156, 156, 2, 1]) None\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - Loss k-space: 1.516 - Loss image space: 0.035 - Loss Wavelet 0.000 - Loss Hankel 0.000 - Loss Casorati 0.000\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - loss fn initialization done -> compute backward pass\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/autograd/graph.py:824: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   warnings.warn(  # warn only once\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 15:54:58 (running for 03:57:03.39)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - Index 0 - Gradient norm: 4.449\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Averaged gradient norm: 1.000\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Creating untagged checkpoint ...\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m 2025-09-29 15:54:59 Schedule checkpoint save with tag:  ...\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m 2025-09-29 15:54:59 Saved checkpoint to buffer 0.0 seconds\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Iteration: 39 - Elapsed time: 353 - Training loss: ['1.612'] - Validation loss: ['0.000']\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m 2025-09-29 15:54:59 Saved buffer to filesystem in 0.1 seconds\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m 2025-09-29 15:54:59 Completed saving checkpoint.\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:55:03 (running for 03:57:08.41)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - reading data\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - compute backward pass done -> compute accumulator\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - Index 0 - Gradient norm: 4.571\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:55:08 (running for 03:57:13.43)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - reading data done -> model initialization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/autograd/graph.py:824: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   warnings.warn(  # warn only once\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 15:55:13 (running for 03:57:18.46)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                   | 0/10 [00:00<?, ?it/s]\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m   warnings.warn(  # warn only once\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 15:55:18 (running for 03:57:23.48)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:55:23 (running for 03:57:28.50)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████▎                                      | 1/10 [00:10<01:33, 10.43s/it]\n",
      "  0%|                                                   | 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 15:55:28 (running for 03:57:33.51)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:55:33 (running for 03:57:38.53)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████▌                                  | 2/10 [00:20<01:23, 10.43s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 15:55:38 (running for 03:57:43.55)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:55:43 (running for 03:57:48.57)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|████████████▉                              | 3/10 [00:31<01:12, 10.41s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 15:55:48 (running for 03:57:53.59)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:55:53 (running for 03:57:58.61)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|█████████████████▏                         | 4/10 [00:41<01:02, 10.41s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 15:55:58 (running for 03:58:03.62)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:56:03 (running for 03:58:08.64)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████████████████████▌                     | 5/10 [00:52<00:52, 10.42s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 15:56:08 (running for 03:58:13.66)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:56:13 (running for 03:58:18.68)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████████████████████████▊                 | 6/10 [01:02<00:41, 10.43s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 15:56:18 (running for 03:58:23.70)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:56:23 (running for 03:58:28.72)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████████████████████████████             | 7/10 [01:13<00:31, 10.44s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 15:56:28 (running for 03:58:33.74)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:56:33 (running for 03:58:38.76)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:56:38 (running for 03:58:43.77)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|██████████████████████████████████▍        | 8/10 [01:23<00:20, 10.44s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 15:56:43 (running for 03:58:48.79)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:56:48 (running for 03:58:53.81)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|██████████████████████████████████████▋    | 9/10 [01:33<00:10, 10.44s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 15:56:53 (running for 03:58:58.83)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:56:58 (running for 03:59:03.85)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - model initialization done -> loss fn initialization\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - reading data\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - reading data done -> model initialization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 10/10 [01:44<00:00, 10.44s/it]\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   warnings.warn(  # warn only once\n",
      " 90%|██████████████████████████████████████▋    | 9/10 [01:34<00:10, 10.48s/it]\n",
      "100%|██████████████████████████████████████████| 10/10 [01:44<00:00, 10.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 15:57:03 (running for 03:59:08.88)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m [KSpaceLoss] torch.Size([8, 2001191, 2, 1]) torch.Size([8, 2001191, 2, 1]) None\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - model initialization done -> loss fn initialization\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m [ImageSpaceLoss] torch.Size([156, 156, 156, 2, 1]) torch.Size([156, 156, 156, 2, 1]) None\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - Loss k-space: 1.624 - Loss image space: 0.037 - Loss Wavelet 0.000 - Loss Hankel 0.000 - Loss Casorati 0.000\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - loss fn initialization done -> compute backward pass\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   warnings.warn(  # warn only once\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 15:57:08 (running for 03:59:13.90)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:57:13 (running for 03:59:18.92)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:57:18 (running for 03:59:23.94)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:57:24 (running for 03:59:28.96)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:57:29 (running for 03:59:33.98)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:57:34 (running for 03:59:39.00)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:57:39 (running for 03:59:44.02)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:57:44 (running for 03:59:49.04)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:57:49 (running for 03:59:54.06)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:57:54 (running for 03:59:59.08)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:57:59 (running for 04:00:04.10)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:58:04 (running for 04:00:09.12)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:58:09 (running for 04:00:14.14)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:58:14 (running for 04:00:19.16)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:58:19 (running for 04:00:24.18)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:58:24 (running for 04:00:29.21)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:58:29 (running for 04:00:34.22)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:58:34 (running for 04:00:39.25)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:58:39 (running for 04:00:44.27)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:58:44 (running for 04:00:49.29)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:58:49 (running for 04:00:54.31)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:58:54 (running for 04:00:59.33)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:58:59 (running for 04:01:04.35)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:59:04 (running for 04:01:09.37)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:59:09 (running for 04:01:14.38)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:59:14 (running for 04:01:19.40)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:59:19 (running for 04:01:24.42)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:59:24 (running for 04:01:29.44)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:59:29 (running for 04:01:34.46)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:59:34 (running for 04:01:39.48)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:59:39 (running for 04:01:44.50)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:59:44 (running for 04:01:49.52)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:59:49 (running for 04:01:54.54)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:59:54 (running for 04:01:59.56)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 15:59:59 (running for 04:02:04.57)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 16:00:04 (running for 04:02:09.60)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 16:00:09 (running for 04:02:14.61)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 16:00:14 (running for 04:02:19.63)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 16:00:19 (running for 04:02:24.65)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 16:00:24 (running for 04:02:29.67)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 16:00:29 (running for 04:02:34.69)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 16:00:34 (running for 04:02:39.71)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 16:00:39 (running for 04:02:44.73)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 16:00:44 (running for 04:02:49.75)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 16:00:49 (running for 04:02:54.77)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - compute backward pass done -> compute accumulator\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m [KSpaceLoss] torch.Size([8, 2001191, 2, 1]) torch.Size([8, 2001191, 2, 1]) None\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m [ImageSpaceLoss] torch.Size([156, 156, 156, 2, 1]) torch.Size([156, 156, 156, 2, 1]) None\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - Loss k-space: 1.589 - Loss image space: 0.034 - Loss Wavelet 0.000 - Loss Hankel 0.000 - Loss Casorati 0.000\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - loss fn initialization done -> compute backward pass\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/autograd/graph.py:824: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   warnings.warn(  # warn only once\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - Index 0 - Gradient norm: 4.536\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Averaged gradient norm: 1.000\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Iteration: 40 - Elapsed time: 353 - Training loss: ['1.642'] - Validation loss: ['0.000']\n",
      "== Status ==\n",
      "Current time: 2025-09-29 16:00:54 (running for 04:02:59.79)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 16:00:59 (running for 04:03:04.81)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - reading data\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - compute backward pass done -> compute accumulator\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - Index 0 - Gradient norm: 4.215\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - reading data done -> model initialization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/autograd/graph.py:824: UserWarning: c10d::allreduce_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   warnings.warn(  # warn only once\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 16:01:04 (running for 04:03:09.84)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                   | 0/10 [00:00<?, ?it/s]\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m   warnings.warn(  # warn only once\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 16:01:09 (running for 04:03:14.85)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 16:01:14 (running for 04:03:19.87)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████▎                                      | 1/10 [00:10<01:33, 10.40s/it]\n",
      "  0%|                                                   | 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 16:01:19 (running for 04:03:24.89)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 16:01:25 (running for 04:03:30.07)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████▌                                  | 2/10 [00:20<01:23, 10.41s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 16:01:30 (running for 04:03:35.09)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 16:01:35 (running for 04:03:40.11)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 16:01:40 (running for 04:03:45.13)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|████████████▉                              | 3/10 [00:31<01:13, 10.43s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 16:01:45 (running for 04:03:50.15)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 16:01:50 (running for 04:03:55.17)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|█████████████████▏                         | 4/10 [00:41<01:02, 10.43s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 16:01:55 (running for 04:04:00.19)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 16:02:00 (running for 04:04:05.21)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████████████████████▌                     | 5/10 [00:52<00:52, 10.44s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 16:02:05 (running for 04:04:10.23)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 16:02:10 (running for 04:04:15.24)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████████████████████████▊                 | 6/10 [01:02<00:41, 10.44s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 16:02:15 (running for 04:04:20.27)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 16:02:20 (running for 04:04:25.28)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████████████████████████████             | 7/10 [01:13<00:31, 10.43s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 16:02:25 (running for 04:04:30.30)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 16:02:30 (running for 04:04:35.32)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|██████████████████████████████████▍        | 8/10 [01:23<00:20, 10.43s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 16:02:35 (running for 04:04:40.34)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 16:02:40 (running for 04:04:45.35)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|██████████████████████████████████████▋    | 9/10 [01:33<00:10, 10.43s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 16:02:45 (running for 04:04:50.37)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 16:02:50 (running for 04:04:55.39)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - model initialization done -> loss fn initialization\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - reading data\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - reading data done -> model initialization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 10/10 [01:44<00:00, 10.44s/it]\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   warnings.warn(  # warn only once\n",
      " 90%|██████████████████████████████████████▋    | 9/10 [01:34<00:10, 10.48s/it]\n",
      "100%|██████████████████████████████████████████| 10/10 [01:44<00:00, 10.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 16:02:55 (running for 04:05:00.41)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m [KSpaceLoss] torch.Size([8, 2001191, 2, 1]) torch.Size([8, 2001191, 2, 1]) None\n",
      "\u001b[36m(RayTrainWorker pid=569511)\u001b[0m Rank 0 - model initialization done -> loss fn initialization\n",
      "== Status ==\n",
      "Current time: 2025-09-29 16:03:00 (running for 04:05:05.43)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m [ImageSpaceLoss] torch.Size([156, 156, 156, 2, 1]) torch.Size([156, 156, 156, 2, 1]) None\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - Loss k-space: 1.617 - Loss image space: 0.035 - Loss Wavelet 0.000 - Loss Hankel 0.000 - Loss Casorati 0.000\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m Rank 1 - loss fn initialization done -> compute backward pass\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m /opt/conda/lib/python3.13/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=569510)\u001b[0m   warnings.warn(  # warn only once\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-09-29 16:03:05 (running for 04:05:10.46)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 16:03:10 (running for 04:05:15.48)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 16:03:15 (running for 04:05:20.50)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 16:03:20 (running for 04:05:25.51)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 16:03:25 (running for 04:05:30.53)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 16:03:30 (running for 04:05:35.55)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 16:03:35 (running for 04:05:40.57)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 16:03:40 (running for 04:05:45.59)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 16:03:45 (running for 04:05:50.61)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-09-29 16:03:50 (running for 04:05:55.63)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 49.0/128 CPUs, 2.0/2 GPUs (0.0/1.0 accelerator_type:A100)\n",
      "Result logdir: /tmp/ray/session_2025-09-29_11-57-43_511034_556628/artifacts/2025-09-29_11-57-55/torch_trainer_example/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import of all necessary functions and classes\n",
    "import os\n",
    "import torch\n",
    "import gc\n",
    "import time\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from ray.train.torch import TorchTrainer\n",
    "from ray.train import ScalingConfig\n",
    "from ray.air.config import RunConfig\n",
    "from typing import Tuple\n",
    "import numpy as np\n",
    "import torch.distributed as dist\n",
    "import ray\n",
    "import h5py\n",
    "import zarr as z\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2,3\"\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, \"../../src\")\n",
    "from juart.dl.loss.loss import JointLoss\n",
    "from juart.dl.operation.modules import training\n",
    "from juart.dl.utils.dist import GradientAccumulator\n",
    "from juart.dl.model.unrollnet import LookaheadModel, UnrolledNet\n",
    "from juart.dl.checkpoint.manager import CheckpointManager\n",
    "from juart.conopt.functional.fourier import (\n",
    "    fourier_transform_adjoint,\n",
    "    fourier_transform_forward,\n",
    "    nonuniform_fourier_transform_adjoint,\n",
    ")\n",
    "\n",
    "# activates the terminal output for print commands in ray\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# Training function that is later passed to the TorchTrainer\n",
    "def train_func():\n",
    "\n",
    "    # define variables\n",
    "    shape = (156,156,156,2,1)\n",
    "    nX, nY, nZ, nTI, nTE = shape\n",
    "    weight_kspace_loss = [0.5, 0.5] # weight the difference in k space\n",
    "    weight_ispace_loss = [0.1, 0.1] # weight the difference of the two images (dual domain) and average their gradients\n",
    "    weight_hankel_loss = [0.0, 0.0]\n",
    "    weight_casorati_loss = [0.0, 0.0]\n",
    "    weight_wavelet_loss = [0.0, 0.0] # weight the loss in wavelet domain\n",
    "    normalized_loss = True\n",
    "    \n",
    "    batch_size = 1 # number of datapoints used per batch iteration\n",
    "    nD = 1 # number of datasets\n",
    "    nP = 25 # number of permutations per epoch\n",
    "    cgiter = 50 # number of dc iterations\n",
    "    num_epochs = 20 # number of epochs\n",
    "    \n",
    "    global_rank = int(dist.get_rank())\n",
    "    world_size = int(dist.get_world_size())\n",
    "    group_size = 2\n",
    "    model_dir = f'corr_modelDD_01i_{nP}P_{cgiter}DC'\n",
    "    root_dir =\"/home/jovyan/models\"\n",
    "    endpoint_url = \"https://s3.fz-juelich.de\"\n",
    "    model_backend = 'local'\n",
    "\n",
    "    single_epoch = False # if its true the script will stop after 1 epoch\n",
    "    save_checkpoint = True # enables checkpoint saving\n",
    "    checkpoint_frequency = 5 # number of iterations between the save files\n",
    "    load_model_state = True # if true the latest model state will be loaded if available\n",
    "    load_averaged_model_state = True # latest averaged model state will be loaded\n",
    "    load_optim_state = True # latest optimizer state will be loaded\n",
    "    load_metrics = True # the latest metrics (lost, iterations) will be loaded\n",
    "\n",
    "    num_groups = 1\n",
    "    batch_size_local = batch_size // num_groups\n",
    "    num_iterations = nD * nP * num_epochs\n",
    "    \n",
    "    ################################################################\n",
    "    # Setting the rank for each worker\n",
    "    for rank in range(0, world_size, group_size):\n",
    "        ranks = list(range(rank, rank + group_size, 1))\n",
    "        device = f\"cuda:{global_rank}\"\n",
    "        if global_rank in ranks:\n",
    "            print(f\"Rank {global_rank} is in group {ranks} ...\")\n",
    "            group = dist.new_group(ranks, backend=\"gloo\")\n",
    "    \n",
    "    ################################################################\n",
    "    # reading and shaping data\n",
    "    data_path = \"/home/jovyan/juart/examples/data/3DLiss_vd_preproc.h5\"\n",
    "    with h5py.File(data_path, \"r\") as f:\n",
    "        \n",
    "        k = torch.from_numpy(f['k'][:])[...,None]\n",
    "        C = torch.from_numpy(f['coilsens'][:])\n",
    "        d = torch.from_numpy(f['d'][:])[...,None]\n",
    "    \n",
    "        print(f\"Coilsensitivity shape {C.shape}\")\n",
    "        print(f\"Trajectory shape {k.shape}\")\n",
    "        print(f\"Signal shape {d.shape}\")\n",
    "\n",
    "    k /= (2*k.max())\n",
    "\n",
    "    ################################################################\n",
    "    # Defining the neural network\n",
    "    \n",
    "    model = UnrolledNet(shape,\n",
    "                      CG_Iter = cgiter,\n",
    "                      num_unroll_blocks = 10,\n",
    "                      num_res_blocks = 15,\n",
    "                      features = 32,\n",
    "                      axes = (1,2,3),\n",
    "                      kernel_size = (3,3,3),\n",
    "                      activation = 'ReLU',\n",
    "                      ResNetCheckpoints = True).to(device)\n",
    "\n",
    "    loss_fn = JointLoss(\n",
    "        shape,\n",
    "        (3, 3),\n",
    "        weights_kspace_loss = weight_kspace_loss,\n",
    "        weights_ispace_loss = weight_ispace_loss,\n",
    "        weights_hankel_loss = weight_hankel_loss,\n",
    "        weights_casorati_loss = weight_casorati_loss,\n",
    "        weights_wavelet_loss = weight_wavelet_loss,\n",
    "        normalized_loss=normalized_loss,\n",
    "        group = group,\n",
    "        device=device,\n",
    "    )\n",
    "    \n",
    "    optimizer = torch.optim.Adam(\n",
    "        model.parameters(),\n",
    "        lr=0.0001,\n",
    "        betas=[0.9, 0.999],\n",
    "        eps=1.0e-8,\n",
    "        weight_decay=0.0,\n",
    "    )\n",
    "\n",
    "    accumulator = GradientAccumulator(\n",
    "        model,\n",
    "        accumulation_steps=batch_size_local,\n",
    "        max_norm=1.0,\n",
    "        normalized_gradient=False,\n",
    "    )\n",
    "\n",
    "    averaged_model = LookaheadModel(\n",
    "        model,\n",
    "        alpha=0.5,\n",
    "        k=5,\n",
    "    )\n",
    "\n",
    "    dist.barrier()\n",
    "    \n",
    "    checkpoint_manager = CheckpointManager(\n",
    "        model_dir,\n",
    "        root_dir=root_dir,\n",
    "        endpoint_url=endpoint_url,\n",
    "        backend=model_backend,\n",
    "    )\n",
    "\n",
    "    dist.barrier()\n",
    "\n",
    "    ################################################################\n",
    "    # LOADING CURRENT MODEL STATE\n",
    "    if load_model_state:\n",
    "        print(f\"Rank {global_rank} - Loading model state ...\")\n",
    "        checkpoint = checkpoint_manager.load([\"model_state\"], map_location=device)\n",
    "        if all(checkpoint.values()):\n",
    "            model.load_state_dict(checkpoint[\"model_state\"])\n",
    "        else:\n",
    "            print(f\"Rank {global_rank} - Could not load model state.\")\n",
    "    \n",
    "    if load_averaged_model_state:\n",
    "        print(f\"Rank {global_rank} - Loading averaged model state ...\")\n",
    "        checkpoint = checkpoint_manager.load(\n",
    "            [\"averaged_model_state\"], map_location=device\n",
    "        )\n",
    "        if all(checkpoint.values()):\n",
    "            averaged_model.load_state_dict(checkpoint[\"averaged_model_state\"])\n",
    "        else:\n",
    "            print(f\"Rank {global_rank} - Could not load averaged model state.\")\n",
    "    \n",
    "    if load_optim_state:\n",
    "        print(f\"Rank {global_rank} - Loading optim state ...\")\n",
    "        checkpoint = checkpoint_manager.load([\"optim_state\"], map_location=device)\n",
    "        if all(checkpoint.values()):\n",
    "            optimizer.load_state_dict(checkpoint[\"optim_state\"])\n",
    "        else:\n",
    "            print(f\"Rank {global_rank} - Could not load optim state.\")\n",
    "    \n",
    "        total_trn_loss = list()\n",
    "        total_val_loss = list()\n",
    "        iteration = 0\n",
    "    \n",
    "    if load_metrics:\n",
    "        print(f\"Rank {global_rank} - Loading metrics ...\")\n",
    "        checkpoint = checkpoint_manager.load([\"trn_loss\", \"val_loss\", \"iteration\"])\n",
    "        if all(checkpoint.values()):\n",
    "            total_trn_loss = list(checkpoint[\"trn_loss\"])\n",
    "            total_val_loss = list(checkpoint[\"val_loss\"])\n",
    "            iteration = checkpoint[\"iteration\"]\n",
    "        else:\n",
    "            print(f\"Rank {global_rank} - Could not load metrics.\")\n",
    "\n",
    "    print(f\"Rank {global_rank} - Continue with iteration {iteration} ...\")\n",
    "\n",
    "    dist.barrier()\n",
    "\n",
    "    ################################################################\n",
    "    # ACTUAL TRAINING LOOP\n",
    "    total_trn_loss = list()\n",
    "    total_val_loss = list()\n",
    "    iteration = 0\n",
    "\n",
    "    generator = torch.Generator()\n",
    "\n",
    "    while iteration < num_iterations:\n",
    "        tic = time.time()\n",
    "        generator.manual_seed(iteration%nP)\n",
    "    \n",
    "        kspace_mask_worker0 = torch.randint(0, 2, (1, d.shape[1], 2, 1), generator=generator)\n",
    "        kspace_mask_worker1 = 1 - kspace_mask_worker0\n",
    "\n",
    "        # Defining data for worker 0\n",
    "        if global_rank == 0:\n",
    "            d_masked = d * kspace_mask_worker0\n",
    "            AHd = nonuniform_fourier_transform_adjoint(k, d_masked, (nX, nY, nZ))\n",
    "            AHd = torch.sum(torch.conj(C[..., None, None]) * AHd, dim=0)\n",
    "        \n",
    "            data = [\n",
    "               {\n",
    "                   \"images_regridded\": AHd,\n",
    "                   \"kspace_trajectory\": k,\n",
    "                   \"sensitivity_maps\": C,\n",
    "                   \"kspace_mask_source\": kspace_mask_worker1,\n",
    "                   \"kspace_mask_target\": kspace_mask_worker0,\n",
    "                   \"kspace_data\": d,\n",
    "               }\n",
    "            ]\n",
    "\n",
    "        # Defining data for worker 1\n",
    "        elif global_rank == 1:\n",
    "            d_masked = d * kspace_mask_worker1\n",
    "            AHd = nonuniform_fourier_transform_adjoint(k, d_masked, (nX, nY, nZ))\n",
    "            AHd = torch.sum(torch.conj(C[..., None,None]) * AHd, dim=0)\n",
    "    \n",
    "            data = [\n",
    "               {\n",
    "                   \"images_regridded\": AHd,\n",
    "                   \"kspace_trajectory\": k,\n",
    "                   \"sensitivity_maps\": C,\n",
    "                   \"kspace_mask_source\": kspace_mask_worker0,\n",
    "                   \"kspace_mask_target\": kspace_mask_worker1,\n",
    "                   \"kspace_data\": d,\n",
    "               }\n",
    "            ]\n",
    "    \n",
    "        trn_loss = training(\n",
    "           [0],\n",
    "           data,\n",
    "           model,\n",
    "           loss_fn,\n",
    "           optimizer,\n",
    "           accumulator,\n",
    "           group=group,\n",
    "           device=device,\n",
    "        )\n",
    "\n",
    "        val_loss = [0] * batch_size\n",
    "        total_trn_loss.append(trn_loss)\n",
    "\n",
    "    ################################################################\n",
    "    # SAVING DATA\n",
    "        if global_rank == 0:\n",
    "            # Completed epoch\n",
    "            if (\n",
    "                save_checkpoint\n",
    "                and np.mod(iteration + batch_size, nD * nP) == 0\n",
    "            ):\n",
    "                print(\"Creating tagged checkpoint ...\")\n",
    "    \n",
    "                checkpoint = {\n",
    "                    \"iteration\": iteration + batch_size,\n",
    "                    \"model_state\": model.state_dict(),\n",
    "                    \"averaged_model_state\": averaged_model.state_dict(),\n",
    "                    \"optim_state\": optimizer.state_dict(),\n",
    "                    \"trn_loss\": total_trn_loss,\n",
    "                    \"val_loss\": total_val_loss,\n",
    "                }\n",
    "    \n",
    "                epoch = (iteration + batch_size) // (nD * nP)\n",
    "                checkpoint_manager.save(checkpoint, tag=f\"_epoch_{epoch}\")\n",
    "    \n",
    "                if single_epoch:\n",
    "                    # Also save the checkpoint as untagged checkpoint\n",
    "                    # Otherwise, training will be stuck in endless loop\n",
    "                    checkpoint_manager.save(checkpoint)\n",
    "                    checkpoint_manager.release()\n",
    "                    break\n",
    "    \n",
    "            # Intermediate checkpoint\n",
    "            elif (\n",
    "                save_checkpoint\n",
    "                and np.mod(iteration + batch_size, checkpoint_frequency) == 0\n",
    "            ):\n",
    "                print(\"Creating untagged checkpoint ...\")\n",
    "    \n",
    "                checkpoint = {\n",
    "                    \"iteration\": iteration + batch_size,\n",
    "                    \"model_state\": model.state_dict(),\n",
    "                    \"averaged_model_state\": averaged_model.state_dict(),\n",
    "                    \"optim_state\": optimizer.state_dict(),\n",
    "                    \"trn_loss\": total_trn_loss,\n",
    "                    \"val_loss\": total_val_loss,\n",
    "                }\n",
    "    \n",
    "                checkpoint_manager.save(checkpoint, block=False)\n",
    "    \n",
    "            toc = time.time() - tic\n",
    "    \n",
    "            print(\n",
    "                (\n",
    "                    f\"Iteration: {iteration} - \"\n",
    "                    + f\"Elapsed time: {toc:.0f} - \"\n",
    "                    + f\"Training loss: {[f'{loss:.3f}' for loss in trn_loss]} - \"\n",
    "                    + f\"Validation loss: {[f'{loss:.3f}' for loss in val_loss]}\"\n",
    "                )\n",
    "            )\n",
    "    \n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "    \n",
    "        iteration += batch_size\n",
    "\n",
    "    # Return the trained model\n",
    "    return {\"model\": model.parameters()}\n",
    "\n",
    "################################################################\n",
    "# main function that initializes needed classes and runs the train function\n",
    "def main():\n",
    "    \n",
    "    ray.init(runtime_env={\"working_dir\": \"/home/jovyan/juart/src\"})\n",
    "    scaling_config = ScalingConfig(\n",
    "        num_workers=2, # number of workers that should be initialized\n",
    "        use_gpu=True,  # should gpu be used?\n",
    "        resources_per_worker={\"CPU\": 24, \"GPU\": 1},\n",
    "    )\n",
    "\n",
    "    # Define the run configuration\n",
    "    run_config = RunConfig(\n",
    "        name=\"torch_trainer_example\", # name of the log file\n",
    "        verbose=1, # detail of the ouput\n",
    "    )\n",
    "\n",
    "    # Create the TorchTrainer\n",
    "    trainer = TorchTrainer(\n",
    "        train_func,\n",
    "        scaling_config=scaling_config,\n",
    "        run_config=run_config,\n",
    "    )\n",
    "\n",
    "    # Run the training\n",
    "    result = trainer.fit() # runs the function we passed to the trainer\n",
    "    print(\"Training complete!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
